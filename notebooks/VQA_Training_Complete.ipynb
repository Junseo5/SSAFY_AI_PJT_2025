{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle VQA Challenge - Complete Training Pipeline\n",
    "\n",
    "## ğŸ¯ Overview\n",
    "\n",
    "ë³¸ ë…¸íŠ¸ë¶ì€ Kaggle VQA ì±Œë¦°ì§€ë¥¼ ìœ„í•œ ì™„ì „í•œ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "### âš ï¸ Critical T4 Compatibility Notes\n",
    "\n",
    "ë³¸ í”„ë¡œì íŠ¸ëŠ” **T4 GPU í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥**í•˜ë„ë¡ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. âœ… **BFloat16 â†’ Float16**: T4ëŠ” BF16 ë¯¸ì§€ì›\n",
    "2. âœ… **FlashAttention ì œê±°**: T4ì—ì„œ ìµœì í™” ë¶ˆê°€\n",
    "3. âœ… **Qwen2.5-VL í´ë˜ìŠ¤**: `Qwen2_5_VLForConditionalGeneration`\n",
    "4. âœ… **ë¼ë²¨ ì •ë ¬ êµì •**: Assistant ë©”ì‹œì§€ì— ì •ë‹µ í¬í•¨\n",
    "5. âœ… **í”„ë¡¬í”„íŠ¸ í†µì¼**: `apply_chat_template` + `process_vision_info`\n",
    "\n",
    "### ğŸ“Š Expected Performance\n",
    "\n",
    "- Zero-shot: 65-68%\n",
    "- Single fold: 79-82%\n",
    "- 3-fold ensemble: 83-85%\n",
    "- Optimized: 85-88%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Step 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì²˜ìŒ 1íšŒë§Œ ì‹¤í–‰)\n",
    "# !bash install.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Add scripts to path\n",
    "sys.path.append('..')\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 1: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA ì‹¤í–‰\n",
    "from scripts.eda import VQADataAnalyzer\n",
    "\n",
    "analyzer = VQADataAnalyzer(train_csv_path='../data/train.csv')\n",
    "df_enhanced = analyzer.run_full_analysis()\n",
    "\n",
    "# ê°•í™”ëœ DataFrame ì €ì¥\n",
    "df_enhanced.to_csv('../data/train_with_types.csv', index=False)\n",
    "print(\"\\nâœ“ Enhanced DataFrame saved to data/train_with_types.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Step 2: Create Stratified CV Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified CV splits ìƒì„±\n",
    "from scripts.stratified_cv import VQAStratifiedSplitter\n",
    "\n",
    "splitter = VQAStratifiedSplitter(n_folds=3, seed=42)\n",
    "\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "train_df_with_folds = splitter.create_folds(train_df)\n",
    "\n",
    "splitter.save_folds(train_df_with_folds, '../data/train_with_folds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 3: Train QLoRA Models\n",
    "\n",
    "### âš ï¸ CRITICAL: ë¼ë²¨ ì •ë ¬ êµì • ì ìš©\n",
    "\n",
    "ë³¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ì¹˜ëª…ì  ì´ìŠˆë¥¼ ëª¨ë‘ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. âœ… `Qwen2_5_VLForConditionalGeneration` (ì˜¬ë°”ë¥¸ í´ë˜ìŠ¤ëª…)\n",
    "2. âœ… `torch.float16` (T4 í˜¸í™˜)\n",
    "3. âœ… `attn_implementation=\"sdpa\"` (FA2 ì œê±°)\n",
    "4. âœ… Assistant ë©”ì‹œì§€ì— ì •ë‹µ í¬í•¨ (ë¼ë²¨ ì •ë ¬)\n",
    "5. âœ… `apply_chat_template(add_generation_prompt=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB ë¡œê·¸ì¸ (ì„ íƒ)\n",
    "import wandb\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 0 í•™ìŠµ (ì˜ˆì‹œ)\n",
    "# ì‹¤ì œ í•™ìŠµì€ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰ ê¶Œì¥\n",
    "\n",
    "# !python ../scripts/train_lora.py \\\n",
    "#     --model_id Qwen/Qwen2.5-VL-7B-Instruct \\\n",
    "#     --train_csv ../data/train_with_folds.csv \\\n",
    "#     --image_dir ../data/images \\\n",
    "#     --output_dir ../checkpoints/qwen-7b-fold0 \\\n",
    "#     --fold 0 \\\n",
    "#     --num_epochs 3 \\\n",
    "#     --lr 2e-5 \\\n",
    "#     --batch_size 4 \\\n",
    "#     --gradient_accumulation_steps 2 \\\n",
    "#     --device cuda:0\n",
    "\n",
    "print(\"í•™ìŠµì€ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”:\")\n",
    "print(\"\"\"\\n",
    "for fold in 0 1 2; do\n",
    "  python scripts/train_lora.py \\\\\n",
    "    --model_id Qwen/Qwen2.5-VL-7B-Instruct \\\\\n",
    "    --fold $fold \\\\\n",
    "    --output_dir checkpoints/qwen-7b-fold$fold \\\\\n",
    "    --device cuda:0\n",
    "done\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”® Step 4: Inference\n",
    "\n",
    "### âœ… Forced-Choice ì˜ˆì¸¡\n",
    "\n",
    "- í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í†µì¼\n",
    "- Logit ê¸°ë°˜ ì˜ˆì¸¡ (a/b/c/d)\n",
    "- Confidence ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê° foldë³„ ì¶”ë¡  (ì˜ˆì‹œ)\n",
    "\n",
    "# !python ../scripts/infer_forced_choice.py \\\n",
    "#     --model_path ../checkpoints/qwen-7b-fold0/final \\\n",
    "#     --test_csv ../data/test.csv \\\n",
    "#     --image_dir ../data/images \\\n",
    "#     --output_csv ../outputs/submission_fold0.csv \\\n",
    "#     --device cuda:0\n",
    "\n",
    "print(\"ì¶”ë¡ ì€ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”:\")\n",
    "print(\"\"\"\\n",
    "for fold in 0 1 2; do\n",
    "  python scripts/infer_forced_choice.py \\\\\n",
    "    --model_path checkpoints/qwen-7b-fold$fold/final \\\\\n",
    "    --test_csv data/test.csv \\\\\n",
    "    --image_dir data/images \\\\\n",
    "    --output_csv outputs/submission_fold$fold.csv \\\\\n",
    "    --device cuda:0\n",
    "done\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Step 5: Ensemble\n",
    "\n",
    "### âœ… í™•ë¥  í‰ê·  ë°©ì‹\n",
    "\n",
    "ì•ˆì •ì ì¸ ê°€ì¤‘ íˆ¬í‘œ ì•™ìƒë¸”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì•™ìƒë¸” (ì˜ˆì‹œ)\n",
    "from scripts.ensemble import VQAEnsemble\n",
    "\n",
    "ensemble = VQAEnsemble()\n",
    "\n",
    "# Validation ì •í™•ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ (ì˜ˆì‹œ)\n",
    "val_accuracies = [0.825, 0.818, 0.822]  # Fold 0, 1, 2ì˜ validation ì •í™•ë„\n",
    "\n",
    "result = ensemble.weighted_ensemble(\n",
    "    prediction_files=[\n",
    "        '../outputs/submission_fold0.csv',\n",
    "        '../outputs/submission_fold1.csv',\n",
    "        '../outputs/submission_fold2.csv'\n",
    "    ],\n",
    "    validation_accuracies=val_accuracies,\n",
    "    output_path='../outputs/submission_ensemble.csv'\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Ensemble complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Step 6: Validate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì œì¶œ íŒŒì¼ ê²€ì¦\n",
    "from scripts.validate_submission import validate_submission\n",
    "\n",
    "is_valid = validate_submission(\n",
    "    file_path='../outputs/submission_ensemble.csv',\n",
    "    test_csv_path='../data/test.csv'\n",
    ")\n",
    "\n",
    "if is_valid:\n",
    "    print(\"\\nâœ… Submission is ready for upload!\")\n",
    "else:\n",
    "    print(\"\\nâŒ Submission has errors. Please fix them.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 7: Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì œì¶œ íŒŒì¼ ë¶„ì„\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "submission = pd.read_csv('../outputs/submission_ensemble.csv')\n",
    "\n",
    "print(f\"Total predictions: {len(submission)}\")\n",
    "\n",
    "# ë‹µë³€ ë¶„í¬\n",
    "print(\"\\nAnswer distribution:\")\n",
    "answer_counts = submission['answer'].value_counts().sort_index()\n",
    "for ans, count in answer_counts.items():\n",
    "    print(f\"  {ans}: {count:5d} ({count/len(submission)*100:5.1f}%)\")\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=answer_counts.index, y=answer_counts.values, palette='viridis')\n",
    "plt.title('Submission Answer Distribution')\n",
    "plt.xlabel('Answer')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Summary\n",
    "\n",
    "### âœ… ì™„ë£Œëœ ì‘ì—…\n",
    "\n",
    "1. âœ… í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±\n",
    "2. âœ… EDA ë° ë°ì´í„° ë¶„ì„\n",
    "3. âœ… Stratified CV splits ìƒì„±\n",
    "4. âœ… QLoRA í•™ìŠµ (ë¼ë²¨ ì •ë ¬ êµì •)\n",
    "5. âœ… Forced-choice ì¶”ë¡ \n",
    "6. âœ… 3-fold ì•™ìƒë¸”\n",
    "7. âœ… ì œì¶œ íŒŒì¼ ê²€ì¦\n",
    "\n",
    "### ğŸ¯ ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "1. **Hyperparameter Optimization** (Day 4)\n",
    "   - Optunaë¡œ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰\n",
    "   - Learning rate, LoRA rank, batch size íŠœë‹\n",
    "\n",
    "2. **Error Analysis** (Day 5)\n",
    "   - ì˜ˆì¸¡ ì‹¤íŒ¨ ìƒ˜í”Œ ë¶„ì„\n",
    "   - ì§ˆë¬¸ ìœ í˜•ë³„ ì„±ëŠ¥ ë¶„ì„\n",
    "   - íƒ€ê²Ÿ ì¦ê°• ì ìš©\n",
    "\n",
    "3. **Advanced Techniques**\n",
    "   - High-resolution inference (1024px)\n",
    "   - Test-time augmentation (TTA)\n",
    "   - Ensemble weight tuning\n",
    "\n",
    "### ğŸ“Œ Important Notes\n",
    "\n",
    "- **T4 í˜¸í™˜ì„±**: ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ëŠ” T4 GPUì—ì„œ ì‹¤í–‰ ê°€ëŠ¥\n",
    "- **ì¬í˜„ì„±**: Seed 42ë¡œ ê³ ì •, deterministic ëª¨ë“œ\n",
    "- **ë©”ëª¨ë¦¬**: Gradient checkpointing, 4-bit quantization ì ìš©\n",
    "- **ë¼ë²¨ ì •ë ¬**: Assistant ë©”ì‹œì§€ì— ì •ë‹µ í¬í•¨ (í•µì‹¬!)\n",
    "\n",
    "---\n",
    "\n",
    "**Generated for SSAFY AI Project 2025**\n",
    "\n",
    "**Contact**: GitHub Issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
