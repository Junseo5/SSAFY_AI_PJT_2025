# ğŸ“‹ Kaggle_AllInOne_Pro2 ê°œì„ ì‚¬í•­ ë° ìˆ˜ì • ê°€ì´ë“œ

## ğŸ” ë°œê²¬ëœ ì£¼ìš” ë¬¸ì œì 

### 1. **ì—ëŸ¬ í•¸ë“¤ë§ ë¶€ì¡±** âš ï¸
**ë¬¸ì œ**: ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨, ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë¨
**ì˜í–¥ë„**: ğŸ”´ High - ëŸ°íƒ€ì„ ì¤‘ í¬ë˜ì‹œ ê°€ëŠ¥

**í˜„ì¬ ì½”ë“œ (ë¬¸ì œ):**
```python
img = Image.open(img_path).convert("RGB")  # ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨
```

**ê°œì„  ì½”ë“œ:**
```python
def _load_image_safe(img_path, fallback_size=512):
    """ì•ˆì „í•œ ì´ë¯¸ì§€ ë¡œë“œ with fallback"""
    try:
        img = Image.open(img_path).convert("RGB")
        if img.size[0] < 10 or img.size[1] < 10:
            raise ValueError(f"Image too small: {img.size}")
        return img, True
    except Exception as e:
        logger.warning(f"âš ï¸ Image load failed ({img_path}): {e}")
        return Image.new('RGB', (fallback_size, fallback_size), color='white'), False
```

### 2. **Direct Logits ë¡œì§ ë¶€ì •í™•** ğŸ¯
**ë¬¸ì œ**: ë‹¨ì¼ í† í°ë§Œ ê³ ë ¤, ë©€í‹°-í† í° ë‹µë³€(ì˜ˆ: "a ", " a") ì²˜ë¦¬ ë¯¸í¡
**ì˜í–¥ë„**: ğŸŸ¡ Medium - ì¶”ë¡  ì •í™•ë„ ì €í•˜ ê°€ëŠ¥

**í˜„ì¬ ì½”ë“œ (ë¬¸ì œ):**
```python
# ê° choiceì˜ í† í° IDë§Œ ì¶”ì¶œ, ê³µë°±/ë³€í˜• ê³ ë ¤ ì•ˆí•¨
token_ids = processor.tokenizer.encode(choice, add_special_tokens=False)
```

**ê°œì„  ì½”ë“œ:**
```python
def get_choice_token_ids_robust(processor):
    """ê°•í™”ëœ í† í° ID ì¶”ì¶œ - ë³€í˜• ê³ ë ¤"""
    choice_tokens = {}
    for choice in ['a', 'b', 'c', 'd']:
        # ì—¬ëŸ¬ ë³€í˜• ê³ ë ¤
        variants = [
            choice,           # "a"
            f" {choice}",     # " a"
            f"{choice} ",     # "a "
            choice.upper(),   # "A"
        ]
        all_token_ids = set()
        for variant in variants:
            token_ids = processor.tokenizer.encode(variant, add_special_tokens=False)
            all_token_ids.update(token_ids)
        choice_tokens[choice] = list(all_token_ids)
    return choice_tokens
```

### 3. **Temperature Scaling ë¯¸êµ¬í˜„** ğŸŒ¡ï¸
**ë¬¸ì œ**: ì½”ë“œë§Œ ìˆê³  ì‹¤ì œë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
**ì˜í–¥ë„**: ğŸŸ¡ Medium - í™•ë¥  êµì • ë¯¸ì ìš©

**ê°œì„  ì½”ë“œ:**
```python
class TemperatureScaler:
    """Temperature Scaling for Calibration"""
    def __init__(self):
        self.temperature = 1.0

    def fit(self, logits, labels):
        """ê²€ì¦ ì„¸íŠ¸ë¡œ ìµœì  temperature í•™ìŠµ"""
        from scipy.optimize import minimize

        def nll_loss(temp):
            temp = max(temp[0], 0.01)  # ìµœì†Œê°’ ë°©ì§€
            scaled_probs = F.softmax(torch.tensor(logits) / temp, dim=1).numpy()
            # Negative log-likelihood
            nll = -np.log(scaled_probs[np.arange(len(labels)), labels] + 1e-10).mean()
            return nll

        result = minimize(nll_loss, x0=[1.0], bounds=[(0.1, 10.0)], method='L-BFGS-B')
        self.temperature = result.x[0]
        logger.info(f"âœ… Optimal Temperature: {self.temperature:.4f}")
        return self

    def transform(self, logits):
        """í•™ìŠµëœ temperatureë¡œ í™•ë¥  ìŠ¤ì¼€ì¼"""
        return F.softmax(torch.tensor(logits) / self.temperature, dim=1).numpy()

# ì‚¬ìš© ì˜ˆì‹œ:
# scaler = TemperatureScaler().fit(val_logits, val_labels)
# calibrated_probs = scaler.transform(test_logits)
```

### 4. **ë°°ì¹˜ ì¶”ë¡  ë¯¸êµ¬í˜„** ğŸš€
**ë¬¸ì œ**: Configì—ë§Œ ìˆê³  ì‹¤ì œ êµ¬í˜„ ì—†ìŒ
**ì˜í–¥ë„**: ğŸŸ¢ Low - ì„±ëŠ¥ ê°œì„  ê¸°íšŒ ì†ì‹¤

**ê°œì„  ì½”ë“œ:**
```python
def infer_batch(model, processor, test_df, batch_size=4, tta_scales=[1.0]):
    \"\"\"ë°°ì¹˜ ì¶”ë¡  êµ¬í˜„\"\"\"
    model.eval()
    all_predictions = []
    all_probs = []

    # DataLoader ìƒì„±
    test_ds = VQADataset(test_df, processor, cfg.DATA_DIR, train=False)
    test_loader = DataLoader(
        test_ds,
        batch_size=batch_size,
        shuffle=False,
        collate_fn=DataCollator(processor, train=False),
        num_workers=0
    )

    with torch.no_grad():
        for batch in tqdm(test_loader, desc=\"Batch Inference\"):
            batch = {k: v.to(device) for k, v in batch.items()}
            outputs = model(**batch)
            logits = outputs.logits[:, -1, :]  # [batch_size, vocab_size]

            # ê° ìƒ˜í”Œë³„ í™•ë¥  ê³„ì‚°
            for i in range(len(logits)):
                choice_probs = extract_choice_probs(logits[i], processor)
                pred = max(choice_probs, key=choice_probs.get)
                all_predictions.append(pred)
                all_probs.append(choice_probs)

    return all_predictions, all_probs
```

### 5. **ë¡œê¹… ì‹œìŠ¤í…œ ë¶€ì¬** ğŸ“
**ë¬¸ì œ**: printë§Œ ì‚¬ìš©, ë¡œê·¸ íŒŒì¼ ì €ì¥ ì•ˆë¨
**ì˜í–¥ë„**: ğŸŸ¡ Medium - ë””ë²„ê¹… ì–´ë ¤ì›€

**ê°œì„  ì½”ë“œ:**
```python
import logging
from datetime import datetime

def setup_logging(log_dir, level=logging.INFO):
    \"\"\"ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •\"\"\"
    logger = logging.getLogger('VQA')
    logger.setLevel(level)
    logger.handlers.clear()

    formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console = logging.StreamHandler()
    console.setFormatter(formatter)
    logger.addHandler(console)

    # íŒŒì¼ í•¸ë“¤ëŸ¬
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    file_handler = logging.FileHandler(f\"{log_dir}/training_{timestamp}.log\")
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    return logger

logger = setup_logging(cfg.LOG_DIR)
logger.info(\"âœ… Training started\")
```

### 6. **ë©”ëª¨ë¦¬ ìµœì í™” ë¶€ì¡±** ğŸ’¾
**ë¬¸ì œ**: ëª…ì‹œì  ë©”ëª¨ë¦¬ ì •ë¦¬ ì—†ìŒ
**ì˜í–¥ë„**: ğŸŸ¡ Medium - OOM ê°€ëŠ¥ì„±

**ê°œì„  ì½”ë“œ:**
```python
def clear_memory():
    \"\"\"ë©”ëª¨ë¦¬ ì •ë¦¬\"\"\"
    import gc
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

# Fold ê°„ ì‚¬ìš©
for fold in cfg.TRAIN_FOLDS:
    train_fold(...)
    clear_memory()
    logger.info(f\"ğŸ’¾ Memory cleared after fold {fold}\")
```

### 7. **ì²´í¬í¬ì¸íŠ¸ ì¬ê°œ ê¸°ëŠ¥ ì—†ìŒ** ğŸ’¿
**ë¬¸ì œ**: í•™ìŠµ ì¤‘ë‹¨ ì‹œ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘
**ì˜í–¥ë„**: ğŸŸ¡ Medium - ì‹œê°„ ë‚­ë¹„

**ê°œì„  ì½”ë“œ:**
```python
def save_checkpoint(model, optimizer, epoch, fold, metrics, path):
    \"\"\"ì²´í¬í¬ì¸íŠ¸ ì €ì¥\"\"\"
    checkpoint = {
        'epoch': epoch,
        'fold': fold,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'metrics': metrics,
    }
    torch.save(checkpoint, path)
    logger.info(f\"ğŸ’¾ Checkpoint saved: {path}\")

def load_checkpoint(model, optimizer, path):
    \"\"\"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\"\"\"
    checkpoint = torch.load(path)
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    logger.info(f\"âœ… Checkpoint loaded: epoch {checkpoint['epoch']}\")
    return checkpoint['epoch'], checkpoint['metrics']
```

### 8. **ê²€ì¦ ë°ì´í„° ì²˜ë¦¬ ì¼ê´€ì„± ë¬¸ì œ** âš–ï¸
**ë¬¸ì œ**: valid_loaderë„ train=True collator ì‚¬ìš©
**ì˜í–¥ë„**: ğŸŸ¢ Low - ì´ë¯¸ ìˆ˜ì •ë¨

**ìˆ˜ì • í™•ì¸:**
```python
# âœ… ì´ë¯¸ ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì •ë¨
valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False)
valid_loader = DataLoader(
    valid_ds, batch_size=cfg.BATCH_SIZE, shuffle=False,
    collate_fn=DataCollator(processor, train=False),  # âœ… train=False
    num_workers=0
)
```

## ğŸ¯ ìš°ì„ ìˆœìœ„ë³„ ì ìš© ê°€ì´ë“œ

### ìš°ì„ ìˆœìœ„ 1 (í•„ìˆ˜) - ì¦‰ì‹œ ì ìš©
1. âœ… **ì—ëŸ¬ í•¸ë“¤ë§** - Dataset/DataCollatorì— try-except ì¶”ê°€
2. âœ… **ë¡œê¹… ì‹œìŠ¤í…œ** - logger ì„¤ì • ë° ì‚¬ìš©
3. âœ… **ë©”ëª¨ë¦¬ ì •ë¦¬** - Fold ê°„ clear_memory() í˜¸ì¶œ

### ìš°ì„ ìˆœìœ„ 2 (ê¶Œì¥) - ì„±ëŠ¥ ê°œì„ 
4. âœ… **Direct Logits ê°œì„ ** - í† í° ë³€í˜• ê³ ë ¤
5. âœ… **Temperature Scaling** - TemperatureScaler í´ë˜ìŠ¤ ì¶”ê°€
6. âœ… **ë°°ì¹˜ ì¶”ë¡ ** - infer_batch í•¨ìˆ˜ êµ¬í˜„

### ìš°ì„ ìˆœìœ„ 3 (ì„ íƒ) - í¸ì˜ì„±
7. âœ… **ì²´í¬í¬ì¸íŠ¸** - save/load_checkpoint ì¶”ê°€
8. âœ… **Early Stopping** - patience ê¸°ë°˜ ì¡°ê¸° ì¢…ë£Œ

## ğŸ“¦ ë¹ ë¥¸ ì ìš© ê°€ì´ë“œ

### ë°©ë²• 1: ê¸°ì¡´ Pro2 íŒŒì¼ ìˆ˜ì •
ê¸°ì¡´ `Kaggle_AllInOne_Pro2.ipynb` íŒŒì¼ì˜ í•´ë‹¹ ì…€ì„ ìœ„ ê°œì„  ì½”ë“œë¡œ êµì²´

### ë°©ë²• 2: Enhanced ë²„ì „ ì‚¬ìš©
`Kaggle_AllInOne_Pro2_Enhanced.ipynb` íŒŒì¼ ì‚¬ìš© (ëª¨ë“  ê°œì„ ì‚¬í•­ í¬í•¨)

### ë°©ë²• 3: ì ì§„ì  ì ìš©
1. ë¨¼ì € ì—ëŸ¬ í•¸ë“¤ë§ë§Œ ì¶”ê°€
2. ë¡œê¹… ì‹œìŠ¤í…œ ì¶”ê°€
3. ë‚˜ë¨¸ì§€ ê¸°ëŠ¥ ìˆœì°¨ ì¶”ê°€

## ğŸ”§ ì£¼ìš” Config ë³€ê²½ ì‚¬í•­

```python
class Config:
    # ... ê¸°ì¡´ ì„¤ì • ...

    # ì¶”ê°€ëœ ì„¤ì •
    LOG_DIR = f\"{DATA_DIR}/logs\"  # ë¡œê·¸ ë””ë ‰í† ë¦¬
    LOG_LEVEL = logging.INFO  # ë¡œê·¸ ë ˆë²¨
    SAVE_EVERY_EPOCH = True  # ì—í­ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸
    USE_EARLY_STOPPING = False  # Early stopping ì‚¬ìš© ì—¬ë¶€
    EARLY_STOPPING_PATIENCE = 2  # Early stopping patience
    USE_BATCH_INFERENCE = True  # ë°°ì¹˜ ì¶”ë¡  ì‚¬ìš©
    FOLD_WEIGHTS = None  # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ [0.4, 0.3, 0.3] ë“±
```

## ğŸ“Š ì˜ˆìƒ ê°œì„  íš¨ê³¼

| ê°œì„ ì‚¬í•­ | ì •í™•ë„ í–¥ìƒ | ì†ë„ í–¥ìƒ | ì•ˆì •ì„± í–¥ìƒ |
|---------|------------|----------|-----------|
| ì—ëŸ¬ í•¸ë“¤ë§ | - | - | â­â­â­ |
| Direct Logits ê°œì„  | â­ | - | â­ |
| Temperature Scaling | â­â­ | - | â­ |
| ë°°ì¹˜ ì¶”ë¡  | - | â­â­ | - |
| ë¡œê¹… ì‹œìŠ¤í…œ | - | - | â­â­ |
| ë©”ëª¨ë¦¬ ìµœì í™” | - | â­ | â­â­ |

## ğŸš€ ê¶Œì¥ ì‹¤í–‰ ìˆœì„œ

1. **ê°œì„ ëœ Config ì„¤ì •** â†’ ë¡œê¹… í™œì„±í™”
2. **Dataset/DataCollator ì—…ë°ì´íŠ¸** â†’ ì—ëŸ¬ í•¸ë“¤ë§
3. **Training Loop ê°œì„ ** â†’ ì²´í¬í¬ì¸íŠ¸ + Early stopping
4. **Inference ê°œì„ ** â†’ Direct Logits ê°•í™” + ë°°ì¹˜ ì¶”ë¡ 
5. **Temperature Scaling ì ìš©** â†’ í™•ë¥  êµì •
6. **Ensemble ê°œì„ ** â†’ ê°€ì¤‘ ì•™ìƒë¸”

## ğŸ“ í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ì‹œ fallback ë™ì‘ í™•ì¸
- [ ] ë¡œê·¸ íŒŒì¼ ìƒì„± í™•ì¸
- [ ] ì²´í¬í¬ì¸íŠ¸ ì €ì¥/ë¡œë“œ í™•ì¸
- [ ] Temperature scaling ì ìš© í™•ì¸
- [ ] ë°°ì¹˜ ì¶”ë¡  ì •ìƒ ë™ì‘ í™•ì¸
- [ ] ë©”ëª¨ë¦¬ ì •ë¦¬ í™•ì¸
- [ ] ìµœì¢… ì œì¶œ íŒŒì¼ í¬ë§· í™•ì¸

---

**ğŸ¤– SSAFY AI Project 2025 - Pro2 Improvements**
**ğŸ“… Last Updated: 2025-10-24**
