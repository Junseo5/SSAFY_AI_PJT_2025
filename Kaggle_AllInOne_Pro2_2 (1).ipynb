{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvoPDmQcBvA2"
      },
      "source": [
        "# üìí Kaggle_AllInOne_Pro.ipynb ‚Äì Îã®Ïùº ÎÖ∏Ìä∏Î∂Å ÌÜµÌï© Î≤ÑÏ†Ñ\n",
        "\n",
        "## üéØ Í∞úÏöî\n",
        "\n",
        "Î≥∏ ÎÖ∏Ìä∏Î∂ÅÏùÄ **VQA Kaggle Challenge**Î•º ÏúÑÌïú **ÏôÑÏ†Ñ ÌÜµÌï© Í≥†ÏÑ±Îä• ÌååÏù¥ÌîÑÎùºÏù∏**ÏûÖÎãàÎã§.\n",
        "\n",
        "### ‚ú® Ï£ºÏöî Í∏∞Îä•\n",
        "\n",
        "- ‚úÖ **T4 GPU ÏôÑÎ≤Ω Ìò∏Ìôò** (Float16, SDPA attention)\n",
        "- ‚úÖ **ÎùºÎ≤® Ï†ïÎ†¨ ÍµêÏ†ï** (Assistant Î©îÏãúÏßÄÏóê Ï†ïÎãµ Ìè¨Ìï®)\n",
        "- ‚úÖ **K-Fold Cross-Validation** (Stratified)\n",
        "- ‚úÖ **Í≥†Í∏â ÌïôÏäµ Í∏∞Î≤ï** (AMP, EMA, SWA, Cosine Warmup)\n",
        "- ‚úÖ **Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ï** (Choice Shuffle, Paraphrase)\n",
        "- ‚úÖ **TTA (Test-Time Augmentation)**\n",
        "- ‚úÖ **ÏïôÏÉÅÎ∏î** (Weighted Voting)\n",
        "- ‚úÖ **Î©îÎ™®Î¶¨ ÏµúÏ†ÅÌôî** (Gradient Checkpointing, 4-bit QLoRA)\n",
        "\n",
        "### üìä ÏòàÏÉÅ ÏÑ±Îä•\n",
        "\n",
        "| ÏÑ§Ï†ï | Ï†ïÌôïÎèÑ | ÏãúÍ∞Ñ |\n",
        "|------|--------|------|\n",
        "| Single Fold | 79-82% | ~4h |\n",
        "| 3-Fold Ensemble | 83-85% | ~12h |\n",
        "| + TTA + Optimization | 85-88% | ~15h |\n",
        "\n",
        "### üöÄ Ïã§Ìñâ ÏàúÏÑú\n",
        "\n",
        "1. **ÌôòÍ≤Ω ÏÑ§Ï†ï** - Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò Î∞è ÏûÑÌè¨Ìä∏\n",
        "2. **Config** - ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
        "3. **Îç∞Ïù¥ÌÑ∞ Î°úÎìú** - Train/Test Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
        "4. **EDA** - ÌÉêÏÉâÏ†Å Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù\n",
        "5. **Stratified K-Fold** - CV Splits ÏÉùÏÑ±\n",
        "6. **Dataset & DataLoader** - Ïª§Ïä§ÌÖÄ Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ïÏùò\n",
        "7. **Model & Processor** - QLoRA Î™®Îç∏ Î°úÎìú\n",
        "8. **Training Loop** - Í≥†Í∏â Í∏∞Î≤ï Ï†ÅÏö© ÌïôÏäµ\n",
        "9. **Inference** - TTAÎ•º ÌôúÏö©Ìïú Ï∂îÎ°†\n",
        "10. **Ensemble** - ÏïôÏÉÅÎ∏î Î∞è Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ±\n",
        "\n",
        "---\n",
        "\n",
        "**ü§ñ Generated for SSAFY AI Project 2025**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAOttWc2BvA2"
      },
      "source": [
        "## üì¶ 1. ÌôòÍ≤Ω ÏÑ§Ï†ï Î∞è Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò\n",
        "\n",
        "ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÑ§ÏπòÌï©ÎãàÎã§. (Ï≤´ Ïã§Ìñâ Ïãú 1ÌöåÎßå)\n",
        "\n",
        "### ‚ö†Ô∏è Ï§ëÏöî: ÏÑ§Ïπò ÌõÑ Îü∞ÌÉÄÏûÑ Ïû¨ÏãúÏûë ÌïÑÏöî"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DEqQ_2HBvA3",
        "outputId": "d67a0912-2887-4f5f-bd9f-c3517996ce43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Íµ¨Í∏ÄÎìúÎùºÏù¥Î∏å ÎßàÏö¥Ìä∏\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-24T07:19:36.203531Z",
          "iopub.status.busy": "2025-10-24T07:19:36.202944Z",
          "iopub.status.idle": "2025-10-24T07:19:45.714082Z",
          "shell.execute_reply": "2025-10-24T07:19:45.713005Z",
          "shell.execute_reply.started": "2025-10-24T07:19:36.203502Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU1SeYUQBvA3",
        "outputId": "d0192020-0f4d-44d1-e6bd-dffe9a0f7ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò ÏôÑÎ£å! Îü∞ÌÉÄÏûÑÏùÑ Ïû¨ÏãúÏûëÌïòÏÑ∏Ïöî.\n"
          ]
        }
      ],
      "source": [
        "# Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò (Colab/Kaggle ÌôòÍ≤Ω)\n",
        "# Ï≤´ Ïã§Ìñâ ÏãúÏóêÎßå Ï£ºÏÑù Ìï¥Ï†úÌïòÍ≥† Ïã§Ìñâ\n",
        "!pip install -q \"transformers>=4.44.2\" \"accelerate>=0.34.2\" \"peft>=0.13.2\" \\\n",
        "    \"bitsandbytes>=0.43.1\" datasets pillow pandas torch torchvision nltk \\\n",
        "    scikit-learn matplotlib seaborn tqdm sentencepiece --upgrade\n",
        "!pip install -q qwen-vl-utils==0.0.8\n",
        "\n",
        "print(\"‚úÖ Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò ÏôÑÎ£å! Îü∞ÌÉÄÏûÑÏùÑ Ïû¨ÏãúÏûëÌïòÏÑ∏Ïöî.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdssQEbcBvA4"
      },
      "source": [
        "## üìö 2. ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRQGTDM5BvA4",
        "outputId": "710f1034-f4a4-43d0-91cf-9ac00e30a313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Device: cuda\n",
            "   GPU: NVIDIA A100-SXM4-80GB\n",
            "   Memory: 85.17 GB\n",
            " Python: 3.12.12\n",
            " PyTorch: 2.9.0+cu128\n"
          ]
        }
      ],
      "source": [
        "import os, sys, re, math, random, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Any, Optional\n",
        "from collections import Counter\n",
        "import unicodedata\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "\n",
        "# Transformers & PEFT\n",
        "from transformers import (\n",
        "    AutoProcessor,\n",
        "    BitsAndBytesConfig,\n",
        "    get_cosine_schedule_with_warmup,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    LogitsProcessorList\n",
        ")\n",
        "import torchvision.transforms as T\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Env hygiene\n",
        "warnings.filterwarnings('ignore')\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Runtime info\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\" Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "print(f\" Python: {sys.version.split()[0]}\")\n",
        "print(f\" PyTorch: {torch.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JY2ZDpqBvA4"
      },
      "source": [
        "## ‚öôÔ∏è 3. Config ÏÑ§Ï†ï\n",
        "\n",
        "Î™®Îì† ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞Î•º Ìïú Í≥≥ÏóêÏÑú Í¥ÄÎ¶¨Ìï©ÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgc0USEKBvA4",
        "outputId": "bf767ad0-ef76-4005-a51c-e0d182574421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Config loaded (Seed: 42)\n",
            "   Model: Qwen/Qwen3-VL-8B-Instruct\n",
            "   Training: BATCH=16, ACCUM=4, LR=0.0001, Cosine=True\n",
            "   Advanced: AMP=True, EMA=True, SWA=False, TTA=False\n",
            "   Auto-tune batch size: False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Qwen3-VL-8B Instruct ÏÑ§Ï†ï (FP16)\n",
        "\n",
        "    Î™©Ìëú: ÎÜíÏùÄ Ï†ïÎãµÎ•†Í≥º ÏïàÏ†ïÏ†Å/Îπ†Î•∏ Ïã§Ìñâ\n",
        "    - Î™®Îç∏: Qwen/Qwen3-VL-8B-Instruct (FP16)\n",
        "    - Ï†ïÎ∞ÄÎèÑ: AMP(FP16) + SDPA Ïñ¥ÌÖêÏÖò\n",
        "    - ÎùºÎ≤® ÎßàÏä§ÌÇπ: ÌîÑÎ°¨ÌîÑÌä∏(-100), Ï†ïÎãµÎßå ÌïôÏäµ\n",
        "    - Î°úÏßì Ï†úÌïú: a/b/c/dÎßå ÏÉùÏÑ± (Ï∂îÎ°† ÏïàÏ†ïÌôî)\n",
        "    - ÏûêÎèô ÌäúÎãù: GPU VRAMÏóê ÎßûÏ∂∞ Î∞∞Ïπò/ÎàÑÏ†Å Ïä§ÌÖù ÏûêÎèô Í≤∞Ï†ï\n",
        "\n",
        "    Ï†ÑÌôò ÏòµÏÖò:\n",
        "    - QUANTIZATION=\"bnb4\" ‚Üí 4bit QLoRA (Î©îÎ™®Î¶¨ Ï†àÏïΩ)\n",
        "    - QUANTIZATION=\"fp16\" ‚Üí FP16 (Í∏∞Î≥∏, Ï†ïÌôïÎèÑ Ïö∞ÏÑ†)\n",
        "\n",
        "    Í∂åÏû• Ïã§Ìñâ ÏàúÏÑú:\n",
        "    1) Îç∞Ïù¥ÌÑ∞ Î°úÎìú/EDA\n",
        "    2) K-Fold Î∂ÑÌï†(ÏÑ†ÌÉù): USE_KFOLD True\n",
        "    3) Î™®Îç∏ Î°úÎìú(ÏûêÎèô ÌäúÎãù Ìè¨Ìï®)\n",
        "    4) ÌïôÏäµ(ÎùºÎ≤® ÎßàÏä§ÌÇπ Ï†ÅÏö©)\n",
        "    5) Ï∂îÎ°†(TTA/Î°úÏßì Ï†úÌïú)\n",
        "    6) Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ±\n",
        "    \"\"\"\n",
        "\n",
        "    # Seed\n",
        "    SEED = 42\n",
        "\n",
        "    # Model\n",
        "    MODEL_ID = \"Qwen/Qwen3-VL-8B-Instruct\"\n",
        "    # Quantization/backend selection: \"fp16\" | \"bnb4\" | \"fp8\"\n",
        "    QUANTIZATION = \"fp16\"\n",
        "    IMAGE_SIZE = 384  # 384/512/768\n",
        "    USE_ADVANCED_MODEL = False\n",
        "    USE_DATAPARALLEL = False\n",
        "    NUM_WORKERS = 4\n",
        "\n",
        "    # Data\n",
        "    DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks/data\"\n",
        "    TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n",
        "    TEST_CSV  = f\"{DATA_DIR}/test.csv\"\n",
        "\n",
        "    # K-Fold\n",
        "    N_FOLDS = 3\n",
        "    USE_KFOLD = False   # Ï†ïÌôïÎèÑ Í∑πÎåÄÌôî Ïãú True (ÌïôÏäµ ÏãúÍ∞Ñ Ï¶ùÍ∞Ä)\n",
        "    TRAIN_FOLDS = [0, 1, 2]\n",
        "\n",
        "    # LoRA / QLoRA\n",
        "    LORA_R = 8\n",
        "    LORA_ALPHA = 16\n",
        "    LORA_DROPOUT = 0.05\n",
        "    TARGET_MODULES = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "    ]\n",
        "\n",
        "    # Training\n",
        "    NUM_EPOCHS = 3     # Ï†ïÌôïÎèÑ ‚Üë ÏõêÌïòÎ©¥ 3~5Î°ú Ï¶ùÍ∞Ä\n",
        "    BATCH_SIZE = 16     # ÏûêÎèô ÌäúÎãùÏúºÎ°ú Ï°∞Ï†ïÎê®\n",
        "    GRAD_ACCUM_STEPS = 4\n",
        "    LEARNING_RATE = 1e-4\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    WARMUP_RATIO = 0.03\n",
        "    MAX_GRAD_NORM = 1.0\n",
        "\n",
        "    # Precision & schedules\n",
        "    USE_AMP = True\n",
        "    USE_EMA = True\n",
        "    EMA_DECAY = 0.999\n",
        "    USE_SWA = False\n",
        "    SWA_START_EPOCH = 0\n",
        "    USE_COSINE_SCHEDULE = True\n",
        "\n",
        "    # Augment\n",
        "    USE_IMAGE_AUGMENTATION = False\n",
        "    USE_RANDAUGMENT = True\n",
        "    RANDAUG_N = 2\n",
        "    RANDAUG_M = 9\n",
        "    USE_MIXUP = False\n",
        "    MIXUP_ALPHA = 0.2\n",
        "    USE_CUTMIX = False\n",
        "    CUTMIX_ALPHA = 1.0\n",
        "\n",
        "    # Text aug\n",
        "    USE_BACK_TRANSLATION = False\n",
        "    USE_SYNONYM_AUG = False\n",
        "    TEXT_AUG_PROB = 0.15\n",
        "\n",
        "    # TTA\n",
        "    USE_TTA = False\n",
        "    TTA_SCALES = [0.9, 1.0, 1.1]\n",
        "    TTA_HFLIP = True\n",
        "\n",
        "    # Generation\n",
        "    MAX_NEW_TOKENS = 8\n",
        "    DO_SAMPLE = False\n",
        "    TEMPERATURE = 0.0\n",
        "\n",
        "    # Paths\n",
        "    SAVE_DIR = f\"{DATA_DIR}/checkpoints\"\n",
        "    OUTPUT_DIR = f\"{DATA_DIR}/outputs\"\n",
        "\n",
        "    # Sampling\n",
        "    USE_SAMPLE = False  # Ï†ïÌôïÎèÑ Ïö∞ÏÑ†: Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ ÏÇ¨Ïö©\n",
        "    SAMPLE_SIZE = 200\n",
        "\n",
        "    # Ensemble\n",
        "    ENSEMBLE_WEIGHTS = None\n",
        "\n",
        "    # Chat system text\n",
        "    SYSTEM_INSTRUCT = (\n",
        "        \"You are a helpful visual question answering assistant. \"\n",
        "        \"Answer using exactly one letter among a, b, c, or d. No explanation.\"\n",
        "    )\n",
        "\n",
        "    # Sequence\n",
        "    MAX_SEQUENCE_LENGTH = 1024\n",
        "\n",
        "    # Auto-tuning\n",
        "    USE_AUTO_TUNE_BATCH_SIZE = False # <<-- ÏûêÎèô ÌäúÎãù ÌÜ†Í∏Ä Ï∂îÍ∞Ä\n",
        "\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    import random, numpy as np, torch\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "set_seed(cfg.SEED)\n",
        "\n",
        "# GPU perf knobs\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "\n",
        "def _auto_scale_training(cfg):\n",
        "    total_gb = 0.0\n",
        "    if torch.cuda.is_available():\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        total_gb = props.total_memory / 1024 ** 3\n",
        "\n",
        "    # User can override\n",
        "    target_effective = int(os.environ.get(\"EFFECTIVE_BATCH_SIZE\", 16))\n",
        "    suggested = 1\n",
        "    if total_gb >= 70:\n",
        "        suggested = 4\n",
        "    elif total_gb >= 40:\n",
        "        suggested = 2\n",
        "    else:\n",
        "        suggested = 1\n",
        "    per_device = int(os.environ.get(\"PER_DEVICE_BATCH\", suggested))\n",
        "\n",
        "    cfg.BATCH_SIZE = max(1, per_device)\n",
        "    cfg.GRAD_ACCUM_STEPS = max(1, target_effective // cfg.BATCH_SIZE)\n",
        "\n",
        "    print(\n",
        "        f\" Auto-scale: GPU {total_gb:.1f} GB | per_device_batch={cfg.BATCH_SIZE} | \"\n",
        "        f\"grad_accum={cfg.GRAD_ACCUM_STEPS} | target_effective={target_effective}\"\n",
        "    )\n",
        "\n",
        "# _auto_scale_training(cfg) # <<-- ÏûêÎèô ÌäúÎãù Ìò∏Ï∂ú Î∂ÄÎ∂Ñ Ï£ºÏÑù Ï≤òÎ¶¨\n",
        "\n",
        "print(f\" Config loaded (Seed: {cfg.SEED})\")\n",
        "print(f\"   Model: {cfg.MODEL_ID}\")\n",
        "print(\n",
        "    f\"   Training: BATCH={cfg.BATCH_SIZE}, ACCUM={cfg.GRAD_ACCUM_STEPS}, LR={cfg.LEARNING_RATE}, Cosine={cfg.USE_COSINE_SCHEDULE}\"\n",
        ")\n",
        "print(\n",
        "    f\"   Advanced: AMP={cfg.USE_AMP}, EMA={cfg.USE_EMA}, SWA={cfg.USE_SWA}, TTA={cfg.USE_TTA}\"\n",
        ")\n",
        "print(f\"   Auto-tune batch size: {cfg.USE_AUTO_TUNE_BATCH_SIZE}\") # <<-- ÏûêÎèô ÌäúÎãù ÏÑ§Ï†ï Ï∂úÎ†• Ï∂îÍ∞Ä"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NIYcLVtBvA4"
      },
      "source": [
        "## üìä 4. Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è EDA\n",
        "\n",
        "Îç∞Ïù¥ÌÑ∞Î•º Î°úÎìúÌïòÍ≥† Í∞ÑÎã®Ìïú ÌÉêÏÉâÏ†Å Î∂ÑÏÑùÏùÑ ÏàòÌñâÌï©ÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-24T07:19:55.638548Z",
          "iopub.status.busy": "2025-10-24T07:19:55.637495Z",
          "iopub.status.idle": "2025-10-24T07:19:56.071371Z",
          "shell.execute_reply": "2025-10-24T07:19:56.070573Z",
          "shell.execute_reply.started": "2025-10-24T07:19:55.638517Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "S1Td1-gBBvA4",
        "outputId": "88071bce-f205-4b15-a779-1e45283bfc02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Train: 3,887 samples\n",
            "üìÅ Test: 3,887 samples\n",
            "\n",
            "Columns: ['id', 'path', 'question', 'a', 'b', 'c', 'd', 'answer']\n",
            "\n",
            "üìä Answer Distribution:\n",
            "answer\n",
            "a     964\n",
            "b     958\n",
            "c     960\n",
            "d    1005\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìù Sample Data:\n",
            "           id                  path                     question       a   b  \\\n",
            "0  train_0001  train/train_0001.jpg  Ïù¥ ÏÇ¨ÏßÑ ÏÜç Ïö¥ÎèôÍ∏∞Íµ¨Í∞Ä ÏÑ§ÏπòÎêú Ïû•ÏÜåÎäî Ïñ¥ÎîîÏùºÍπåÏöî?  ÌïôÍµê Ïö¥ÎèôÏû•  Í≥µÏõê   \n",
            "1  train_0002  train/train_0002.jpg  Ïù¥ ÏÇ¨ÏßÑÏóê Î≥¥Ïù¥Îäî Ï†ÑÌÜµ ÌïúÍµ≠ Í±¥Ï∂ïÎ¨ºÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî?      Í∂ÅÍ∂ê   ÏÑ±   \n",
            "\n",
            "        c       d answer  question_len  \n",
            "0  Ìó¨Ïä§Ïû• ÎÇ¥Î∂Ä  ÏáºÌïëÎ™∞ ÎÇ¥Î∂Ä      b            27  \n",
            "1      ÏÇ¨Ï∞∞      ÌïúÏò•      d            27  \n"
          ]
        }
      ],
      "source": [
        "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
        "train_df = pd.read_csv(cfg.TRAIN_CSV)\n",
        "test_df = pd.read_csv(cfg.TEST_CSV)\n",
        "\n",
        "print(f\"üìÅ Train: {len(train_df):,} samples\")\n",
        "print(f\"üìÅ Test: {len(test_df):,} samples\")\n",
        "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
        "\n",
        "# ÏÉòÌîåÎßÅ (ÎîîÎ≤ÑÍπÖÏö©)\n",
        "if cfg.USE_SAMPLE:\n",
        "    train_df = train_df.sample(n=min(cfg.SAMPLE_SIZE, len(train_df)), random_state=cfg.SEED).reset_index(drop=True)\n",
        "    print(f\"\\n‚ö†Ô∏è  Sampled {len(train_df)} samples for quick testing\")\n",
        "\n",
        "# Í∏∞Î≥∏ ÌÜµÍ≥Ñ\n",
        "print(f\"\\nüìä Answer Distribution:\")\n",
        "print(train_df['answer'].value_counts().sort_index())\n",
        "\n",
        "# ÏãúÍ∞ÅÌôî\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "# ÎãµÎ≥Ä Î∂ÑÌè¨\n",
        "train_df['answer'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='skyblue')\n",
        "axes[0].set_title('Answer Distribution (Train)', fontsize=12, weight='bold')\n",
        "axes[0].set_xlabel('Answer')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# ÏßàÎ¨∏ Í∏∏Ïù¥ Î∂ÑÌè¨\n",
        "train_df['question_len'] = train_df['question'].str.len()\n",
        "train_df['question_len'].hist(bins=30, ax=axes[1], color='salmon', edgecolor='black')\n",
        "axes[1].set_title('Question Length Distribution', fontsize=12, weight='bold')\n",
        "axes[1].set_xlabel('Length (chars)')\n",
        "axes[1].set_ylabel('Count')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ÏÉòÌîå Ï∂úÎ†•\n",
        "print(\"\\nüìù Sample Data:\")\n",
        "print(train_df.head(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYMWaLT3BvA5"
      },
      "source": [
        "## üîÑ 5. Stratified K-Fold Cross-Validation\n",
        "\n",
        "ÎãµÎ≥Ä Î∂ÑÌè¨Î•º Ïú†ÏßÄÌïòÎ©¥ÏÑú K-FoldÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-24T07:19:56.073478Z",
          "iopub.status.busy": "2025-10-24T07:19:56.073212Z",
          "iopub.status.idle": "2025-10-24T07:19:56.082402Z",
          "shell.execute_reply": "2025-10-24T07:19:56.081499Z",
          "shell.execute_reply.started": "2025-10-24T07:19:56.073437Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCadx70QBvA5",
        "outputId": "4d4ffb88-feb7-4d3c-d188-0e8f4931d232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Single split (90:10) ÏÉùÏÑ± ÏôÑÎ£å\n",
            "   Train: 3498\n",
            "   Valid: 389\n"
          ]
        }
      ],
      "source": [
        "if cfg.USE_KFOLD:\n",
        "    # Stratified K-Fold ÏÉùÏÑ±\n",
        "    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=cfg.SEED)\n",
        "    train_df['fold'] = -1\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['answer'])):\n",
        "        train_df.loc[val_idx, 'fold'] = fold\n",
        "\n",
        "    print(f\"‚úÖ {cfg.N_FOLDS}-Fold CV ÏÉùÏÑ± ÏôÑÎ£å\")\n",
        "    print(f\"\\nFold Distribution:\")\n",
        "    print(train_df['fold'].value_counts().sort_index())\n",
        "\n",
        "    # FoldÎ≥Ñ ÎãµÎ≥Ä Î∂ÑÌè¨ ÌôïÏù∏\n",
        "    print(f\"\\nAnswer Distribution per Fold:\")\n",
        "    for fold in range(cfg.N_FOLDS):\n",
        "        fold_data = train_df[train_df['fold'] == fold]\n",
        "        dist = fold_data['answer'].value_counts(normalize=True).sort_index()\n",
        "        print(f\"Fold {fold}: {dict(dist)}\")\n",
        "else:\n",
        "    # Îã®Ïùº Î™®Îç∏ ÌïôÏäµ (90:10 split)\n",
        "    split_idx = int(len(train_df) * 0.9)\n",
        "    train_df['fold'] = -1\n",
        "    train_df.loc[split_idx:, 'fold'] = 0\n",
        "    print(f\"‚úÖ Single split (90:10) ÏÉùÏÑ± ÏôÑÎ£å\")\n",
        "    print(f\"   Train: {len(train_df[train_df['fold'] == -1])}\")\n",
        "    print(f\"   Valid: {len(train_df[train_df['fold'] == 0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIkmwwInBvA5"
      },
      "source": [
        "## üóÇÔ∏è 6. Dataset & DataLoader\n",
        "\n",
        "Ïª§Ïä§ÌÖÄ Îç∞Ïù¥ÌÑ∞ÏÖã Î∞è DataCollatorÎ•º Ï†ïÏùòÌï©ÎãàÎã§.\n",
        "\n",
        "### ‚úÖ ÎùºÎ≤® Ï†ïÎ†¨ ÍµêÏ†ï Ï†ÅÏö©\n",
        "- Assistant Î©îÏãúÏßÄÏóê Ï†ïÎãµ Ìè¨Ìï®\n",
        "- `add_generation_prompt=False` ÏÇ¨Ïö©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63-bkDZ6BvA5",
        "outputId": "2086bb1b-b7b7-4fc5-ff0b-1862fb985572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset & DataCollator (with label masking) ready\n"
          ]
        }
      ],
      "source": [
        "import json, unicodedata\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "\n",
        "def build_mc_prompt(question, a, b, c, d):\n",
        "    \"\"\"Multiple Choice prompt\"\"\"\n",
        "    return (\n",
        "        f\"{question}\\n\"\n",
        "        f\"(a) {a}\\n(b) {b}\\n(c) {c}\\n(d) {d}\\n\\n\"\n",
        "        \"ÎãµÎ≥ÄÏùÄ a, b, c, d Ï§ë ÌïòÎÇòÏùò Î¨∏ÏûêÎßå Ï∂úÎ†•ÌïòÏÑ∏Ïöî.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def synonym_replace(text: str) -> str:\n",
        "    try:\n",
        "        import nltk\n",
        "        from nltk.corpus import wordnet as wn\n",
        "        try:\n",
        "            wn.synsets(\"test\")\n",
        "        except LookupError:\n",
        "            nltk.download(\"wordnet\")\n",
        "            nltk.download(\"omw-1.4\")\n",
        "        words = text.split()\n",
        "        if not words:\n",
        "            return text\n",
        "        idx = np.random.randint(len(words))\n",
        "        syns = wn.synsets(words[idx])\n",
        "        lemmas = [l.name().replace(\"_\", \" \") for s in syns for l in s.lemmas()]\n",
        "        lemmas = [w for w in lemmas if w.lower() != words[idx].lower()]\n",
        "        if not lemmas:\n",
        "            return text\n",
        "        words[idx] = np.random.choice(lemmas)\n",
        "        return \" \".join(words)\n",
        "    except Exception:\n",
        "        return text\n",
        "\n",
        "\n",
        "def maybe_augment_text(question: str, options: Dict[str, str]):\n",
        "    q, opts = question, dict(options)\n",
        "    if cfg.USE_SYNONYM_AUG and np.random.rand() < cfg.TEXT_AUG_PROB:\n",
        "        q = synonym_replace(q)\n",
        "    return q, opts\n",
        "\n",
        "\n",
        "class VQADataset(Dataset):\n",
        "    \"\"\"VQA Dataset (assistant label returned separately for proper masking).\"\"\"\n",
        "\n",
        "    def __init__(self, df, processor, data_dir=\"\", train=True, use_advanced=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.processor = processor\n",
        "        self.data_dir = data_dir\n",
        "        self.train = train\n",
        "        self.use_advanced = use_advanced\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        img_path = os.path.join(self.data_dir, row[\"path\"]) if \"path\" in row else row.get(\"image_path\", \"\")\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "        except Exception:\n",
        "            img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n",
        "\n",
        "        q0 = str(row[\"question\"]) if \"question\" in row else \"\"\n",
        "        opts0 = {\n",
        "            \"a\": str(row.get(\"a\", \"\")),\n",
        "            \"b\": str(row.get(\"b\", \"\")),\n",
        "            \"c\": str(row.get(\"c\", \"\")),\n",
        "            \"d\": str(row.get(\"d\", \"\")),\n",
        "        }\n",
        "        if self.train:\n",
        "            q0, opts0 = maybe_augment_text(q0, opts0)\n",
        "\n",
        "        user_text = build_mc_prompt(q0, opts0[\"a\"], opts0[\"b\"], opts0[\"c\"], opts0[\"d\"])\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"image\", \"image\": img},\n",
        "                {\"type\": \"text\", \"text\": user_text}\n",
        "            ]}\n",
        "        ]\n",
        "\n",
        "        out = {\"messages\": messages, \"image\": img}\n",
        "        if self.train:\n",
        "            out[\"answer\"] = str(row.get(\"answer\", \"\")).strip().lower()\n",
        "        return out\n",
        "\n",
        "\n",
        "def _build_image_transform():\n",
        "    if not cfg.USE_IMAGE_AUGMENTATION:\n",
        "        return None\n",
        "    ops = [T.RandomHorizontalFlip(p=0.5)]\n",
        "    if cfg.USE_RANDAUGMENT:\n",
        "        try:\n",
        "            ops.append(T.RandAugment(num_ops=cfg.RANDAUG_N, magnitude=cfg.RANDAUG_M))\n",
        "        except Exception:\n",
        "            pass\n",
        "    return T.Compose(ops)\n",
        "\n",
        "\n",
        "_IMG_TF = _build_image_transform()\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollator:\n",
        "    \"\"\"Data Collator with correct prompt masking for decoder-only training.\"\"\"\n",
        "\n",
        "    processor: Any\n",
        "    train: bool = True\n",
        "    use_advanced: bool = False\n",
        "    augment_images: bool = True\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        images, prompts, full_texts = [], [], []\n",
        "\n",
        "        for sample in batch:\n",
        "            img = sample[\"image\"]\n",
        "            if self.train and self.augment_images and _IMG_TF is not None:\n",
        "                try:\n",
        "                    img = _IMG_TF(img)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            messages = sample[\"messages\"]\n",
        "            prompt_text = self.processor.apply_chat_template(\n",
        "                messages, tokenize=False, add_generation_prompt=True\n",
        "            )\n",
        "\n",
        "            if self.train and \"answer\" in sample and sample[\"answer\"]:\n",
        "                conversation = messages + [\n",
        "                    {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": str(sample[\"answer\"]).strip().lower()}]}\n",
        "                ]\n",
        "                full_text = self.processor.apply_chat_template(\n",
        "                    conversation, tokenize=False, add_generation_prompt=False\n",
        "                )\n",
        "            else:\n",
        "                full_text = prompt_text\n",
        "\n",
        "            # Normalize text\n",
        "            prompt_text = unicodedata.normalize('NFKC', prompt_text)\n",
        "            full_text = unicodedata.normalize('NFKC', full_text)\n",
        "\n",
        "            images.append(img)\n",
        "            prompts.append(prompt_text)\n",
        "            full_texts.append(full_text)\n",
        "\n",
        "        # Encode prompt and full sequences\n",
        "        enc_prompt = self.processor(\n",
        "            images=images,\n",
        "            text=prompts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=cfg.MAX_SEQUENCE_LENGTH,\n",
        "        )\n",
        "        enc_full = self.processor(\n",
        "            images=images,\n",
        "            text=full_texts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=cfg.MAX_SEQUENCE_LENGTH,\n",
        "        )\n",
        "\n",
        "        if self.train:\n",
        "            labels = enc_full[\"input_ids\"].clone()\n",
        "            # mask pads\n",
        "            labels[enc_full[\"attention_mask\"] == 0] = -100\n",
        "            # mask prompt tokens\n",
        "            for i in range(labels.size(0)):\n",
        "                full_mask = enc_full[\"attention_mask\"][i].bool()\n",
        "                prompt_len = int(enc_prompt[\"attention_mask\"][i].sum().item())\n",
        "                nonpad_idx = torch.nonzero(full_mask, as_tuple=False).squeeze(-1)\n",
        "                prompt_idx = nonpad_idx[:prompt_len]\n",
        "                labels[i, prompt_idx] = -100\n",
        "            enc_full[\"labels\"] = labels\n",
        "\n",
        "        return enc_full\n",
        "\n",
        "\n",
        "print(\"‚úÖ Dataset & DataCollator (with label masking) ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaJtCiEFBvA5"
      },
      "source": [
        "## ü§ñ 7. Model & Processor Î°úÎìú\n",
        "\n",
        "QLoRA Î™®Îç∏Í≥º ProcessorÎ•º Î°úÎìúÌï©ÎãàÎã§.\n",
        "\n",
        "### ‚úÖ T4 Ìò∏Ìôò ÏÑ§Ï†ï\n",
        "- Float16 (BFloat16 ÏïÑÎãò)\n",
        "- SDPA attention (FlashAttention Ï†úÍ±∞)\n",
        "- 4-bit quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "644d60fa16e14a7786aa7ce385554d5c",
            "b2a8379bf3ea43418434379e815660bc",
            "55d5b2fe21d34886b9179776f6f98bb1",
            "85dda7c448de40ecb7061ec3a544d659",
            "a5f6d508a32545b3a9ca51ef845b0a6b",
            "3516446107e94e689fac9a10cfc1a9d7",
            "a3f83c8b67394cadb50ca5aa6cf9e8bb",
            "f6256d625bbf432199ce2469cd83d168",
            "3f3b3fc79f904d43be4ef1038e19597c",
            "8efdd5025fc141589c242237b0bfccfb",
            "5a2878d8668e477394cf2d1ca411fde0"
          ]
        },
        "id": "IySul3vdBvA5",
        "outputId": "b3a3415e-abd8-41eb-8bca-1d28d1b27fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Loading model & processor...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "644d60fa16e14a7786aa7ce385554d5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 21,823,488 || all params: 8,788,947,184 || trainable%: 0.2483\n",
            "   Model ready.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText, AutoModelForVision2Seq, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "\n",
        "def _fp8_supported():\n",
        "    try:\n",
        "        import transformer_engine.pytorch as te  # noqa: F401\n",
        "    except Exception:\n",
        "        return False\n",
        "    if not torch.cuda.is_available():\n",
        "        return False\n",
        "    major, minor = torch.cuda.get_device_capability(0)\n",
        "    if major < 9:  # Hopper(H100)=9.x, Ampere(A100)=8.0 -> FP8 ÎØ∏ÏßÄÏõê\n",
        "        return False\n",
        "    # PyTorch float8 ÌÉÄÏûÖ Ï°¥Ïû¨ Ïó¨Î∂Ä\n",
        "    has_float8 = hasattr(torch, \"float8_e4m3fn\") and hasattr(torch, \"float8_e5m2\")\n",
        "    return bool(has_float8)\n",
        "\n",
        "\n",
        "def create_model_and_processor(model_id, use_advanced=False):\n",
        "    \"\"\"Create 4-bit QLoRA model + processor with left padding and auto device_map.\n",
        "    For Qwen3-VL-30B-A3B-Instruct we use AutoModelForImageTextToText.\n",
        "    \"\"\"\n",
        "\n",
        "    compute_dtype = torch.bfloat16 if (torch.cuda.is_available() and torch.cuda.is_bf16_supported()) else torch.float16\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "    )\n",
        "\n",
        "    processor = AutoProcessor.from_pretrained(\n",
        "        model_id,\n",
        "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
        "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    if hasattr(processor, \"tokenizer\"):\n",
        "        processor.tokenizer.padding_side = \"left\"\n",
        "\n",
        "    qopt = getattr(cfg, \"QUANTIZATION\", \"\").lower()\n",
        "    want_fp8 = (\"fp8\" in model_id.lower()) or (qopt == \"fp8\")\n",
        "    want_bnb4 = (qopt == \"bnb4\")\n",
        "    can_fp8 = _fp8_supported()\n",
        "    use_fp8 = bool(want_fp8 and can_fp8)\n",
        "\n",
        "    load_model_id = model_id\n",
        "    if want_fp8 and not can_fp8:\n",
        "        # FP8 ÎØ∏ÏßÄÏõê ÌôòÍ≤Ω(A100 Îì±)ÏóêÏÑúÎäî ÏùºÎ∞ò Í∞ÄÏ§ëÏπòÎ°ú Ìè¥Î∞±\n",
        "        if model_id.lower().endswith(\"-fp8\"):\n",
        "            load_model_id = model_id[:-4]  # \"-FP8\" Ï†úÍ±∞\n",
        "        print(f\"[warn] FP8 not supported on this GPU. Falling back to 4-bit for {load_model_id}\")\n",
        "\n",
        "    def _load_image_text_to_text():\n",
        "        return AutoModelForImageTextToText.from_pretrained(\n",
        "            load_model_id,\n",
        "            trust_remote_code=True,\n",
        "            device_map=\"auto\",\n",
        "        )\n",
        "\n",
        "    def _load_vision2seq(**kwargs):\n",
        "        return AutoModelForVision2Seq.from_pretrained(\n",
        "            load_model_id,\n",
        "            trust_remote_code=True,\n",
        "            device_map=\"auto\",\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    if use_fp8:\n",
        "        try:\n",
        "            base_model = _load_image_text_to_text()\n",
        "        except Exception:\n",
        "            base_model = _load_vision2seq()\n",
        "    elif want_bnb4:\n",
        "        try:\n",
        "            base_model = AutoModelForImageTextToText.from_pretrained(\n",
        "                load_model_id,\n",
        "                trust_remote_code=True,\n",
        "                quantization_config=bnb_config,\n",
        "                device_map=\"auto\",\n",
        "            )\n",
        "        except Exception:\n",
        "            base_model = _load_vision2seq(quantization_config=bnb_config)\n",
        "    else:\n",
        "        # FP16/BF16 Í≤ΩÎ°ú: ÏñëÏûêÌôî ÏóÜÏù¥ dtype ÏßÄÏ†ï\n",
        "        try:\n",
        "            base_model = AutoModelForImageTextToText.from_pretrained(\n",
        "                load_model_id,\n",
        "                trust_remote_code=True,\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "            )\n",
        "        except Exception:\n",
        "            base_model = _load_vision2seq(torch_dtype=torch.float16)\n",
        "\n",
        "    if want_bnb4 and not use_fp8:\n",
        "        base_model = prepare_model_for_kbit_training(base_model)\n",
        "    base_model.gradient_checkpointing_enable()\n",
        "\n",
        "    # Prefer SDPA attention for speed/stability on PyTorch 2.x\n",
        "    try:\n",
        "        if hasattr(base_model, \"config\"):\n",
        "            base_model.config.attn_implementation = \"sdpa\"\n",
        "        torch.backends.cuda.sdp_kernel(enable_flash=True, enable_mem_efficient=True, enable_math=False)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        r=cfg.LORA_R,\n",
        "        lora_alpha=cfg.LORA_ALPHA,\n",
        "        lora_dropout=cfg.LORA_DROPOUT,\n",
        "        bias=\"none\",\n",
        "        target_modules=cfg.TARGET_MODULES,\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "    )\n",
        "    model = get_peft_model(base_model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    # ensure eos/pad ids are set to avoid generation issues\n",
        "    try:\n",
        "        if hasattr(model, \"generation_config\") and hasattr(processor, \"tokenizer\"):\n",
        "            if model.generation_config.pad_token_id is None:\n",
        "                model.generation_config.pad_token_id = processor.tokenizer.pad_token_id\n",
        "            if model.generation_config.eos_token_id is None:\n",
        "                model.generation_config.eos_token_id = processor.tokenizer.eos_token_id\n",
        "    except Exception:\n",
        "        pass\n",
        "    return model, processor\n",
        "\n",
        "\n",
        "print(\"   Loading model & processor...\")\n",
        "model, processor = create_model_and_processor(\n",
        "    cfg.MODEL_ID,\n",
        "    use_advanced=cfg.USE_ADVANCED_MODEL\n",
        ")\n",
        "print(\"   Model ready.\")\n",
        "\n",
        "# Optional compile for speed (set USE_TORCH_COMPILE=1)\n",
        "import os as _os\n",
        "if _os.environ.get(\"USE_TORCH_COMPILE\", \"0\") == \"1\":\n",
        "    try:\n",
        "        model = torch.compile(model, mode=\"reduce-overhead\", fullgraph=False)  # type: ignore[attr-defined]\n",
        "        print(\"   Model compiled with torch.compile\")\n",
        "    except Exception as _e:\n",
        "        print(f\"[warn] torch.compile skipped: {_e}\")\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# ÏµúÎåÄ ÏïàÏ†Ñ Î∞∞Ïπò ÌÅ¨Í∏∞ ÏûêÎèô ÌÉêÏÉâ\n",
        "# -------------------------------\n",
        "import random\n",
        "\n",
        "\n",
        "def _build_tmp_batch(ds, collate_fn, bs: int):\n",
        "    idxs = [random.randrange(len(ds)) for _ in range(min(bs, len(ds)))]\n",
        "    samples = [ds[i] for i in idxs]\n",
        "    return collate_fn(samples)\n",
        "\n",
        "\n",
        "def auto_tune_per_device_batch(model, processor, df, max_probe_samples: int = 64):\n",
        "    if not torch.cuda.is_available():\n",
        "        return cfg.BATCH_SIZE\n",
        "\n",
        "    # ÏÉòÌîå Îç∞Ïù¥ÌÑ∞ÏÖã/ÏΩúÎ†àÏù¥ÌÑ∞ (ÌïôÏäµ Î™®Îìú)\n",
        "    probe_n = min(max_probe_samples, len(df))\n",
        "    probe_df = df.sample(probe_n, random_state=cfg.SEED).reset_index(drop=True)\n",
        "    ds = VQADataset(probe_df, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "    collate_fn = DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "\n",
        "    # ÌõÑÎ≥¥Íµ∞: ÌòÑÏû¨ ÏÑ§Ï†ïÎ∂ÄÌÑ∞ Ï†êÏßÑ Ï¶ùÍ∞Ä\n",
        "    base = max(1, int(cfg.BATCH_SIZE))\n",
        "    candidates = sorted({1, 2, 3, 4, 6, 8, 12, 16, 24, 32, base})\n",
        "    candidates = [c for c in candidates if c <= 32]\n",
        "\n",
        "    best = 1\n",
        "    compute_dtype = torch.float16\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=cfg.USE_AMP)\n",
        "\n",
        "    for bs in candidates:\n",
        "        torch.cuda.empty_cache()\n",
        "        ok = True\n",
        "        try:\n",
        "            batch = _build_tmp_batch(ds, collate_fn, bs)\n",
        "            batch = {k: v.to('cuda') if hasattr(v, 'to') else v for k, v in batch.items()}\n",
        "            model.train()\n",
        "            with torch.cuda.amp.autocast(enabled=cfg.USE_AMP, dtype=compute_dtype):\n",
        "                out = model(**batch)\n",
        "                loss = out.loss\n",
        "            scaler.scale(loss).backward()\n",
        "            model.zero_grad(set_to_none=True)\n",
        "            del batch, out, loss\n",
        "        except RuntimeError as e:\n",
        "            if 'out of memory' in str(e).lower():\n",
        "                ok = False\n",
        "            else:\n",
        "                raise\n",
        "        except torch.cuda.OutOfMemoryError:\n",
        "            ok = False\n",
        "        finally:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        if ok:\n",
        "            best = bs\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Î™©Ìëú Ïú†Ìö® Î∞∞ÏπòÏóê ÎßûÏ∂∞ ÎàÑÏ†Å Ïä§ÌÖù Ïû¨Ï°∞Ï†ï\n",
        "    import os\n",
        "    target_effective = int(os.environ.get(\"EFFECTIVE_BATCH_SIZE\", 16))\n",
        "    cfg.BATCH_SIZE = max(1, best)\n",
        "    cfg.GRAD_ACCUM_STEPS = max(1, target_effective // cfg.BATCH_SIZE)\n",
        "    print(\n",
        "        f\" Auto-tune: chosen per_device_batch={cfg.BATCH_SIZE} | grad_accum={cfg.GRAD_ACCUM_STEPS} | target_effective={target_effective}\"\n",
        "    )\n",
        "    return cfg.BATCH_SIZE\n",
        "\n",
        "\n",
        "try:\n",
        "    # train_dfÎäî ÏïûÏÑ† ÏÖÄÏóêÏÑú Î°úÎìúÎê®\n",
        "    if 'train_df' in globals() and len(train_df) > 0 and cfg.USE_AUTO_TUNE_BATCH_SIZE: # <-- Ï∂îÍ∞ÄÎêú Ï°∞Í±¥\n",
        "        auto_tune_per_device_batch(model, processor, train_df)\n",
        "except Exception as _e:\n",
        "    print(f\"[warn] Auto-tune skipped: {_e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPqKFcM2BvA6"
      },
      "source": [
        "## üéì 8. Training Loop with Advanced Techniques\n",
        "\n",
        "Í≥†Í∏â ÌïôÏäµ Í∏∞Î≤ïÏùÑ Ï†ÅÏö©Ìïú ÌïôÏäµ Î£®ÌîÑÏûÖÎãàÎã§.\n",
        "\n",
        "### ‚ú® Ï†ÅÏö©Îêú Í∏∞Î≤ï\n",
        "- ‚úÖ **AMP** (Automatic Mixed Precision)\n",
        "- ‚úÖ **EMA** (Exponential Moving Average)\n",
        "- ‚úÖ **SWA** (Stochastic Weight Averaging)\n",
        "- ‚úÖ **Cosine Warmup Scheduler**\n",
        "- ‚úÖ **Gradient Clipping**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8wXvzegBvA6",
        "outputId": "03ab9a11-5bf0-44e3-85f4-4f7755b5581e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training functions  \n"
          ]
        }
      ],
      "source": [
        "AMP_DTYPE = None\n",
        "try:\n",
        "    import torch as _torch\n",
        "    AMP_DTYPE = _torch.float16\n",
        "except Exception:\n",
        "    AMP_DTYPE = None\n",
        "\n",
        "\n",
        "class EMA:\n",
        "    \"\"\"Exponential Moving Average\"\"\"\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.model = model\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.backup = {}\n",
        "        self.register()\n",
        "\n",
        "    def register(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def update(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                new_average = (\n",
        "                    self.decay * self.shadow[name] +\n",
        "                    (1.0 - self.decay) * param.data\n",
        "                )\n",
        "                self.shadow[name] = new_average.clone()\n",
        "\n",
        "    def apply_shadow(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.backup[name] = param.data.clone()\n",
        "                param.data = self.shadow[name]\n",
        "\n",
        "    def restore(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                param.data = self.backup[name]\n",
        "        self.backup = {}\n",
        "\n",
        "\n",
        "def train_one_fold(model, train_loader, valid_loader, fold=0):\n",
        "    \"\"\" Fold \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training Fold {fold}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=cfg.LEARNING_RATE,\n",
        "        weight_decay=cfg.WEIGHT_DECAY\n",
        "    )\n",
        "\n",
        "    # Scheduler\n",
        "    num_training_steps = cfg.NUM_EPOCHS * math.ceil(len(train_loader) / cfg.GRAD_ACCUM_STEPS)\n",
        "    num_warmup_steps = int(num_training_steps * cfg.WARMUP_RATIO)\n",
        "\n",
        "    if cfg.USE_COSINE_SCHEDULE:\n",
        "        scheduler = get_cosine_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps, num_training_steps\n",
        "        )\n",
        "    else:\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps, num_training_steps\n",
        "        )\n",
        "\n",
        "    # AMP Scaler\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=cfg.USE_AMP)\n",
        "\n",
        "    # EMA\n",
        "    ema = EMA(model, decay=cfg.EMA_DECAY) if cfg.USE_EMA else None\n",
        "\n",
        "    # SWA\n",
        "    swa_model = None\n",
        "    if cfg.USE_SWA:\n",
        "        swa_model = AveragedModel(model)\n",
        "        swa_scheduler = SWALR(optimizer, swa_lr=cfg.LEARNING_RATE * 0.1)\n",
        "\n",
        "    #\n",
        "    global_step = 0\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(cfg.NUM_EPOCHS):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        progress_bar = tqdm(\n",
        "            train_loader,\n",
        "            desc=f\"Epoch {epoch+1}/{cfg.NUM_EPOCHS} [train]\",\n",
        "            unit=\"batch\"\n",
        "        )\n",
        "\n",
        "        for step, batch in enumerate(progress_bar, start=1):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            # Forward with AMP\n",
        "            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=AMP_DTYPE):\n",
        "                outputs = model(**batch)\n",
        "                loss = outputs.loss / cfg.GRAD_ACCUM_STEPS\n",
        "\n",
        "            # Backward\n",
        "            scaler.scale(loss).backward()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Gradient accumulation\n",
        "            if step % cfg.GRAD_ACCUM_STEPS == 0:\n",
        "                # Gradient clipping\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.MAX_GRAD_NORM)\n",
        "\n",
        "                # Optimizer step\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "                # Scheduler step\n",
        "                if cfg.USE_SWA and epoch >= cfg.SWA_START_EPOCH:\n",
        "                    swa_scheduler.step()\n",
        "                else:\n",
        "                    scheduler.step()\n",
        "\n",
        "                # EMA update\n",
        "                if cfg.USE_EMA and ema is not None:\n",
        "                    ema.update()\n",
        "\n",
        "                global_step += 1\n",
        "\n",
        "                # Progress\n",
        "                avg_loss = running_loss / cfg.GRAD_ACCUM_STEPS\n",
        "                progress_bar.set_postfix({\n",
        "                    \"loss\": f\"{avg_loss:.4f}\",\n",
        "                    \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
        "                })\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # SWA model update\n",
        "        if cfg.USE_SWA and swa_model is not None and epoch >= cfg.SWA_START_EPOCH:\n",
        "            swa_model.update_parameters(model)\n",
        "\n",
        "        # Validation\n",
        "        if cfg.USE_EMA and ema is not None:\n",
        "            ema.apply_shadow()\n",
        "\n",
        "        val_loss = validate(model, valid_loader)\n",
        "\n",
        "        if cfg.USE_EMA and ema is not None:\n",
        "            ema.restore()\n",
        "\n",
        "        print(f\"[Epoch {epoch+1}] Valid Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            save_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
        "            os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "            if cfg.USE_EMA and ema is not None:\n",
        "                ema.apply_shadow()\n",
        "\n",
        "            _to_save = model.module if isinstance(model, torch.nn.DataParallel) else model\n",
        "            _to_save.save_pretrained(save_path)\n",
        "            processor.save_pretrained(save_path)\n",
        "\n",
        "            if cfg.USE_EMA and ema is not None:\n",
        "                ema.restore()\n",
        "\n",
        "            print(f\"    Best model saved to {save_path}\")\n",
        "\n",
        "    # SWA\n",
        "    if cfg.USE_SWA and swa_model is not None:\n",
        "        torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n",
        "        save_path = f\"{cfg.SAVE_DIR}/fold{fold}_swa\"\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        (swa_model.module if hasattr(swa_model, \"module\") else swa_model).save_pretrained(save_path)\n",
        "        processor.save_pretrained(save_path)\n",
        "        print(f\"    SWA model saved to {save_path}\")\n",
        "\n",
        "    return best_val_loss\n",
        "\n",
        "\n",
        "def validate(model, valid_loader):\n",
        "    \"\"\"Validation\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(valid_loader, desc=\"Validating\", leave=False):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=AMP_DTYPE):\n",
        "                outputs = model(**batch)\n",
        "                total_loss += outputs.loss.item()\n",
        "\n",
        "    model.train()\n",
        "    return total_loss / len(valid_loader)\n",
        "\n",
        "\n",
        "print(\" Training functions  \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm8XIp5nBvA6"
      },
      "source": [
        "## üöÄ 9. Ïã§Ï†ú ÌïôÏäµ Ïã§Ìñâ\n",
        "\n",
        "K-Fold ÎòêÎäî Îã®Ïùº Î™®Îç∏ ÌïôÏäµÏùÑ Ïã§ÌñâÌï©ÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "2cc74c36b46e4f13866573175b285688",
            "81a078056180474abda1a72496dfa027",
            "d7466c8a3a0f489b897e2c9958f2d4b5",
            "77a78f6e8aa34281b70e96137386e319",
            "2181b36c5b024b9d905d0b830af1c276",
            "99306f7ae4fd4e16b6ceb9da8a546ace",
            "795f5f0ff2ae4393b8f8efdd0c61df86",
            "5288fc8091f443218651d3f7f8ae30f5",
            "5bb256b504ff436783a2a45d205c828a",
            "f5a0499a77df48159619c27c274bbd78",
            "9f719215192440faab85c4929396292b",
            "c46cd4e38dcf464c99a20d9565aad4c2",
            "de396401ba0a42d68eec28d2c85afb74",
            "86e573df3b8e4b768c426a0d701aa56f",
            "facaf6d6356f49fcb6f48b5e3c92d55d",
            "97c4a9ba7afd447ba7109112678c9cd8",
            "5d2bf18b98e34d7f8297afee75c8d191",
            "a7d95dc71e83451d8f1c603b05371aca",
            "5d28d559c9a24efebdf87eb4b5656b71",
            "6150c200c22a42398521914c2e3e7f70",
            "19411e4675094bd5abe4b1c3b1447630",
            "392c8eb185284723a43726794002fff4",
            "788512e4d4b64173b33d541b725b13c9",
            "6f370b53d35b44ad946b7ea039688642",
            "ce6ab67995af466db591576a68d9bfe0",
            "c4f202d61dc0492c9815d3ffd0af2fac",
            "64dde711b09c44bfbb1a3c6b0d6a03b5",
            "908530725ff04f8191e796fac674be89",
            "1807bf50057b40f899d1d0ccedeefe08",
            "779244efcee249078d442c66e1c842f5",
            "e18ae067e40146628739f043838b6999",
            "54d7fbd3277449438dc074abdd924e44",
            "b3e2dd33ed7d40329d7ef221febc96da"
          ]
        },
        "id": "Fu5KC8xOBvA6",
        "outputId": "efa40a71-bdbf-4c78-986f-bcd4068a9676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training Fold 0\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/3 [train]:   0%|          | 0/219 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cc74c36b46e4f13866573175b285688"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c46cd4e38dcf464c99a20d9565aad4c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Valid Loss: 0.1895\n",
            "    Best model saved to /content/drive/MyDrive/Colab Notebooks/data/checkpoints/fold0_best\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 2/3 [train]:   0%|          | 0/219 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "788512e4d4b64173b33d541b725b13c9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# K-Fold\n",
        "if cfg.USE_KFOLD:\n",
        "    results = {}\n",
        "\n",
        "    for fold in cfg.TRAIN_FOLDS:\n",
        "        print(f\"\\n{'#'*60}\")\n",
        "        print(f\"Starting Fold {fold}/{cfg.N_FOLDS-1}\")\n",
        "        print(f\"{'#'*60}\")\n",
        "\n",
        "        #\n",
        "        train_subset = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
        "        valid_subset = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
        "\n",
        "        print(f\"Train: {len(train_subset)}, Valid: {len(valid_subset)}\")\n",
        "\n",
        "        # Dataset\n",
        "        train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "        valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "\n",
        "        # DataLoader\n",
        "        dp_active = cfg.USE_DATAPARALLEL and torch.cuda.is_available() and torch.cuda.device_count() > 1\n",
        "        train_loader = DataLoader(\n",
        "            train_ds,\n",
        "            batch_size=cfg.BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL, augment_images=True),\n",
        "            num_workers=cfg.NUM_WORKERS,\n",
        "            drop_last=dp_active,\n",
        "            pin_memory=True,\n",
        "            persistent_workers=bool(cfg.NUM_WORKERS)\n",
        "        )\n",
        "        valid_loader = DataLoader(\n",
        "            valid_ds,\n",
        "            batch_size=cfg.BATCH_SIZE,\n",
        "            shuffle=False,\n",
        "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL, augment_images=False),\n",
        "            num_workers=cfg.NUM_WORKERS,\n",
        "            drop_last=False,\n",
        "            pin_memory=True,\n",
        "            persistent_workers=bool(cfg.NUM_WORKERS)\n",
        "        )\n",
        "\n",
        "        #\n",
        "        best_loss = train_one_fold(model, train_loader, valid_loader, fold=fold)\n",
        "        results[fold] = best_loss\n",
        "\n",
        "        print(f\"\\n Fold {fold} : Best Val Loss = {best_loss:.4f}\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"All Folds Training Complete!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for fold, loss in results.items():\n",
        "        print(f\"Fold {fold}: {loss:.4f}\")\n",
        "    print(f\"Average: {np.mean(list(results.values())):.4f}\")\n",
        "\n",
        "else:\n",
        "    #\n",
        "    train_subset = train_df[train_df['fold'] == -1].reset_index(drop=True)\n",
        "    valid_subset = train_df[train_df['fold'] == 0].reset_index(drop=True)\n",
        "\n",
        "    train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "    valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "\n",
        "    dp_active = cfg.USE_DATAPARALLEL and torch.cuda.is_available() and torch.cuda.device_count() > 1\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=cfg.BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL, augment_images=True),\n",
        "        num_workers=cfg.NUM_WORKERS,\n",
        "        drop_last=dp_active,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=bool(cfg.NUM_WORKERS)\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_ds,\n",
        "        batch_size=cfg.BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL, augment_images=False),\n",
        "        num_workers=cfg.NUM_WORKERS,\n",
        "        drop_last=False,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=bool(cfg.NUM_WORKERS)\n",
        "    )\n",
        "\n",
        "    best_loss = train_one_fold(model, train_loader, valid_loader, fold=0)\n",
        "    print(f\"\\n Single model  : Best Val Loss = {best_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mgAp7_tBvA6"
      },
      "source": [
        "## üîÆ 10. Inference with TTA\n",
        "\n",
        "Test-Time AugmentationÏùÑ ÌôúÏö©Ìïú Ï∂îÎ°†ÏùÑ ÏàòÌñâÌï©ÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "SUPB3dvlBvA6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText, AutoModelForVision2Seq, BitsAndBytesConfig\n",
        "from transformers import LogitsProcessorList\n",
        "from peft import PeftModel\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def extract_choice(text: str) -> str:\n",
        "    text = text.strip().lower()\n",
        "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
        "    if lines:\n",
        "        last = lines[-1]\n",
        "        if last in [\"a\", \"b\", \"c\", \"d\"]:\n",
        "            return last\n",
        "    for tok in text.split():\n",
        "        if tok in [\"a\", \"b\", \"c\", \"d\"]:\n",
        "            return tok\n",
        "    return \"a\"\n",
        "\n",
        "\n",
        "def infer_single_fold(model_path, test_df, output_path):\n",
        "    \"\"\"Single-fold inference loading saved LoRA adapter on top of base model.\"\"\"\n",
        "\n",
        "    compute_dtype = torch.bfloat16 if (torch.cuda.is_available() and torch.cuda.is_bf16_supported()) else torch.float16\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "    )\n",
        "\n",
        "    # Load base and then attach adapters\n",
        "    qopt = getattr(cfg, \"QUANTIZATION\", \"\").lower()\n",
        "    want_fp8 = (\"fp8\" in cfg.MODEL_ID.lower()) or (qopt == \"fp8\")\n",
        "    want_bnb4 = (qopt == \"bnb4\")\n",
        "    can_fp8 = False\n",
        "    try:\n",
        "        import transformer_engine.pytorch as te  # noqa: F401\n",
        "        if torch.cuda.is_available():\n",
        "            major, minor = torch.cuda.get_device_capability(0)\n",
        "            can_fp8 = major >= 9 and hasattr(torch, \"float8_e4m3fn\") and hasattr(torch, \"float8_e5m2\")\n",
        "    except Exception:\n",
        "        can_fp8 = False\n",
        "\n",
        "    use_fp8 = bool(want_fp8 and can_fp8)\n",
        "    load_model_id = cfg.MODEL_ID\n",
        "    if want_fp8 and not can_fp8:\n",
        "        if load_model_id.lower().endswith(\"-fp8\"):\n",
        "            load_model_id = load_model_id[:-4]\n",
        "        print(f\"[warn] FP8 not supported on this GPU. Falling back to 4-bit for {load_model_id}\")\n",
        "\n",
        "    def _load_image_text_to_text():\n",
        "        return AutoModelForImageTextToText.from_pretrained(\n",
        "            load_model_id,\n",
        "            trust_remote_code=True,\n",
        "            device_map=\"auto\",\n",
        "        )\n",
        "    def _load_vision2seq(**kwargs):\n",
        "        return AutoModelForVision2Seq.from_pretrained(\n",
        "            load_model_id,\n",
        "            trust_remote_code=True,\n",
        "            device_map=\"auto\",\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    if use_fp8:\n",
        "        try:\n",
        "            base_model = _load_image_text_to_text()\n",
        "        except Exception:\n",
        "            base_model = _load_vision2seq()\n",
        "    elif want_bnb4:\n",
        "        try:\n",
        "            base_model = AutoModelForImageTextToText.from_pretrained(\n",
        "                load_model_id,\n",
        "                trust_remote_code=True,\n",
        "                quantization_config=bnb_config,\n",
        "                device_map=\"auto\",\n",
        "            )\n",
        "        except Exception:\n",
        "            base_model = _load_vision2seq(quantization_config=bnb_config)\n",
        "    else:\n",
        "        try:\n",
        "            base_model = AutoModelForImageTextToText.from_pretrained(\n",
        "                load_model_id,\n",
        "                trust_remote_code=True,\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "            )\n",
        "        except Exception:\n",
        "            base_model = _load_vision2seq(torch_dtype=torch.float16)\n",
        "    model_infer = PeftModel.from_pretrained(base_model, model_path)\n",
        "    processor_infer = AutoProcessor.from_pretrained(\n",
        "        model_path,\n",
        "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
        "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    if hasattr(processor_infer, \"tokenizer\"):\n",
        "        processor_infer.tokenizer.padding_side = \"left\"\n",
        "\n",
        "    try:\n",
        "        if hasattr(base_model, \"config\"):\n",
        "            base_model.config.attn_implementation = \"sdpa\"\n",
        "        torch.backends.cuda.sdp_kernel(enable_flash=True, enable_mem_efficient=True, enable_math=False)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    model_infer.eval()\n",
        "\n",
        "    # Restrict to a/b/c/d tokens if possible\n",
        "    try:\n",
        "        def _letter_ids(tok):\n",
        "            ids = []\n",
        "            for ch in [\"a\", \"b\", \"c\", \"d\"]:\n",
        "                toks = tok(\" \" + ch, add_special_tokens=False).input_ids\n",
        "                if toks: ids.append(toks[-1])\n",
        "            return ids if len(ids)==4 else None\n",
        "        allowed_tokens = _letter_ids(processor_infer.tokenizer)\n",
        "    except Exception:\n",
        "        allowed_tokens = None\n",
        "\n",
        "    predictions = []\n",
        "    pbar = tqdm(range(len(test_df)), desc=\"Inference\")\n",
        "    for i in pbar:\n",
        "        row = test_df.iloc[i]\n",
        "        img_path = os.path.join(cfg.DATA_DIR, row[\"path\"]) if \"path\" in row else row.get(\"image_path\", \"\")\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "        except Exception:\n",
        "            img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n",
        "\n",
        "        user_text = build_mc_prompt(\n",
        "            str(row[\"question\"]),\n",
        "            str(row[\"a\"]), str(row[\"b\"]), str(row[\"c\"]), str(row[\"d\"])\n",
        "        )\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"image\", \"image\": img},\n",
        "                {\"type\": \"text\", \"text\": user_text}\n",
        "            ]}\n",
        "        ]\n",
        "\n",
        "        text = processor_infer.apply_chat_template(\n",
        "            messages, tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        def _predict_one(pil_img):\n",
        "            _inputs = processor_infer(\n",
        "                text=[text], images=[pil_img], return_tensors=\"pt\"\n",
        "            )\n",
        "            _inputs = {k: v.to(model_infer.device) if hasattr(v, 'to') else v for k, v in _inputs.items()}\n",
        "            lp = None\n",
        "            if allowed_tokens is not None:\n",
        "                class _Allowed:\n",
        "                    def __init__(self, allowed):\n",
        "                        self.allowed = set(int(x) for x in allowed)\n",
        "                    def __call__(self, input_ids, scores):\n",
        "                        mask = torch.full_like(scores, float(\"-inf\"))\n",
        "                        idx = torch.tensor(list(self.allowed), device=scores.device)\n",
        "                        mask.index_fill_(1, idx, 0.0)\n",
        "                        return scores + mask\n",
        "                lp = LogitsProcessorList([_Allowed(allowed_tokens)])\n",
        "            with torch.no_grad():\n",
        "                out_ids = model_infer.generate(\n",
        "                    **_inputs,\n",
        "                    max_new_tokens=cfg.MAX_NEW_TOKENS,\n",
        "                    do_sample=cfg.DO_SAMPLE,\n",
        "                    temperature=cfg.TEMPERATURE if cfg.DO_SAMPLE else None,\n",
        "                    eos_token_id=processor_infer.tokenizer.eos_token_id,\n",
        "                    logits_processor=lp,\n",
        "                )\n",
        "            # Trim input tokens from generated sequence to avoid picking letters from the prompt\n",
        "            gen_only = out_ids[:, _inputs[\"input_ids\"].shape[1]:]\n",
        "            _txt = processor_infer.batch_decode(gen_only, skip_special_tokens=True)[0]\n",
        "            return extract_choice(_txt)\n",
        "\n",
        "        if cfg.USE_TTA:\n",
        "            votes = []\n",
        "            W, H = img.size\n",
        "            for s in cfg.TTA_SCALES:\n",
        "                new_img = img.resize((max(8, int(W*s)), max(8, int(H*s))))\n",
        "                votes.append(_predict_one(new_img))\n",
        "                if cfg.TTA_HFLIP:\n",
        "                    votes.append(_predict_one(T.functional.hflip(new_img)))\n",
        "            answer = Counter(votes).most_common(1)[0][0] if votes else _predict_one(img)\n",
        "        else:\n",
        "            answer = _predict_one(img)\n",
        "        predictions.append(answer)\n",
        "        # stream: show per-sample prediction\n",
        "        try:\n",
        "            sid = str(row.get('id', i))\n",
        "            pbar.set_postfix({\"id\": sid, \"pred\": answer})\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    submission = pd.DataFrame({\n",
        "        \"id\": test_df[\"id\"],\n",
        "        \"answer\": predictions,\n",
        "    })\n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    submission.to_csv(output_path, index=False)\n",
        "    print(f\" Saved to {output_path}\")\n",
        "    return submission\n",
        "\n",
        "\n",
        "# Run inference across folds or single model\n",
        "predictions_all = []\n",
        "if cfg.USE_KFOLD:\n",
        "    for fold in cfg.TRAIN_FOLDS:\n",
        "        model_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
        "        output_path = f\"{cfg.OUTPUT_DIR}/submission_fold{fold}.csv\"\n",
        "        print(f\"\\n{'='*60}\\nInferencing Fold {fold}\\n{'='*60}\")\n",
        "        pred = infer_single_fold(model_path, test_df, output_path)\n",
        "        predictions_all.append(pred)\n",
        "else:\n",
        "    model_path = f\"{cfg.SAVE_DIR}/fold0_best\"\n",
        "    output_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n",
        "    pred = infer_single_fold(model_path, test_df, output_path)\n",
        "    predictions_all.append(pred)\n",
        "\n",
        "print(\"\\n All inference complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1JeOWIEBvA7"
      },
      "source": [
        "## üéØ 11. Ensemble\n",
        "\n",
        "Ïó¨Îü¨ FoldÏùò ÏòàÏ∏°ÏùÑ ÏïôÏÉÅÎ∏îÌï©ÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "slGZlhsgBvA7"
      },
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD and len(predictions_all) > 1:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Ensemble (Weighted Voting)\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Weighted Voting (weights=NoneÏù¥Î©¥ Í∑†Îì±)\n",
        "    ensemble_preds = []\n",
        "\n",
        "    if cfg.ENSEMBLE_WEIGHTS is None or len(cfg.ENSEMBLE_WEIGHTS) != len(predictions_all):\n",
        "        weights = [1.0/len(predictions_all)] * len(predictions_all)\n",
        "    else:\n",
        "        s = sum(cfg.ENSEMBLE_WEIGHTS); weights = [w/s for w in cfg.ENSEMBLE_WEIGHTS]\n",
        "\n",
        "    for i in range(len(test_df)):\n",
        "        score = {\"a\":0.0, \"b\":0.0, \"c\":0.0, \"d\":0.0}\n",
        "        for k, pred in enumerate(predictions_all):\n",
        "            ans = str(pred.iloc[i]['answer']).strip().lower()\n",
        "            if ans in score: score[ans] += weights[k]\n",
        "        chosen = max(score.items(), key=lambda x: x[1])[0]\n",
        "        ensemble_preds.append(chosen)\n",
        "\n",
        "    # ÏµúÏ¢Ö Ï†úÏ∂ú ÌååÏùº\n",
        "    final_submission = pd.DataFrame({\n",
        "        \"id\": test_df[\"id\"],\n",
        "        \"answer\": ensemble_preds\n",
        "    })\n",
        "\n",
        "    final_path = f\"{cfg.OUTPUT_DIR}/submission_ensemble.csv\"\n",
        "    final_submission.to_csv(final_path, index=False)\n",
        "\n",
        "    print(f\"‚úÖ Ensemble submission saved to {final_path}\")\n",
        "    print(f\"\\nAnswer Distribution:\")\n",
        "    print(final_submission['answer'].value_counts().sort_index())\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚úÖ Single model - No ensemble needed\")\n",
        "    final_submission = predictions_all[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaNcLa0dBvA7"
      },
      "source": [
        "## üìä 12. Í≤∞Í≥º Î∂ÑÏÑù Î∞è ÏãúÍ∞ÅÌôî"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "-NpWlEJ5BvA7"
      },
      "outputs": [],
      "source": [
        "# ÎãµÎ≥Ä Î∂ÑÌè¨ ÏãúÍ∞ÅÌôî\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "answer_counts = final_submission['answer'].value_counts().sort_index()\n",
        "sns.barplot(x=answer_counts.index, y=answer_counts.values, palette='viridis', ax=ax)\n",
        "ax.set_title('Final Submission Answer Distribution', fontsize=14, weight='bold')\n",
        "ax.set_xlabel('Answer')\n",
        "ax.set_ylabel('Count')\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# ÎπÑÏú® ÌëúÏãú\n",
        "for i, (ans, count) in enumerate(answer_counts.items()):\n",
        "    percentage = count / len(final_submission) * 100\n",
        "    ax.text(i, count + 10, f\"{percentage:.1f}%\", ha='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ÌÜµÍ≥Ñ Ï∂úÎ†•\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Final Statistics\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Total predictions: {len(final_submission)}\")\n",
        "print(f\"\\nAnswer counts:\")\n",
        "for ans, count in answer_counts.items():\n",
        "    print(f\"  {ans}: {count:5d} ({count/len(final_submission)*100:5.1f}%)\")\n",
        "\n",
        "# Ï†úÏ∂ú ÌååÏùº ÏÉòÌîå\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Sample Predictions\")\n",
        "print(f\"{'='*60}\")\n",
        "print(final_submission.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN5FumySBvA7"
      },
      "source": [
        "## ‚úÖ 13. ÏµúÏ¢Ö Ï†ïÎ¶¨\n",
        "\n",
        "### üéâ ÏôÑÎ£åÎêú ÏûëÏóÖ\n",
        "\n",
        "1. ‚úÖ **ÌôòÍ≤Ω ÏÑ§Ï†ï** - Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò Î∞è ÏûÑÌè¨Ìä∏\n",
        "2. ‚úÖ **Config** - ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌÜµÌï© Í¥ÄÎ¶¨\n",
        "3. ‚úÖ **Îç∞Ïù¥ÌÑ∞ Î°úÎìú & EDA** - ÌÉêÏÉâÏ†Å Î∂ÑÏÑù\n",
        "4. ‚úÖ **Stratified K-Fold** - CV Splits ÏÉùÏÑ±\n",
        "5. ‚úÖ **Dataset & DataLoader** - ÎùºÎ≤® Ï†ïÎ†¨ ÍµêÏ†ï Ï†ÅÏö©\n",
        "6. ‚úÖ **Model & Processor** - QLoRA Î™®Îç∏ Î°úÎìú (T4 Ìò∏Ìôò)\n",
        "7. ‚úÖ **Training Loop** - AMP, EMA, SWA, Cosine Warmup Ï†ÅÏö©\n",
        "8. ‚úÖ **Inference** - TTA ÏßÄÏõê Ï∂îÎ°†\n",
        "9. ‚úÖ **Ensemble** - Majority Voting\n",
        "10. ‚úÖ **Results** - ÏãúÍ∞ÅÌôî Î∞è ÌÜµÍ≥Ñ\n",
        "\n",
        "### üöÄ Îã§Ïùå Îã®Í≥Ñ\n",
        "\n",
        "1. **ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù**\n",
        "   - Learning rate, LoRA rank Ï°∞Ï†ï\n",
        "   - Batch size, Grad accumulation ÏµúÏ†ÅÌôî\n",
        "\n",
        "2. **Î™®Îç∏ ÌÅ¨Í∏∞ ÌôïÎåÄ**\n",
        "   - 7B Î™®Îç∏ ÏÇ¨Ïö© (Îçî ÎÜíÏùÄ Ï†ïÌôïÎèÑ)\n",
        "   - Image size Ï¶ùÍ∞Ä (512, 768)\n",
        "\n",
        "3. **Í≥†Í∏â Í∏∞Î≤ï ÌôúÏÑ±Ìôî**\n",
        "   - TTA scales Ï∂îÍ∞Ä\n",
        "   - SWA Ï†ÅÏö©\n",
        "   - Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ï ÌôúÏÑ±Ìôî\n",
        "\n",
        "4. **ÏóêÌè≠ Ï¶ùÍ∞Ä**\n",
        "   - NUM_EPOCHS = 3~5\n",
        "\n",
        "### üìå Important Notes\n",
        "\n",
        "- **T4 Ìò∏Ìôò**: Float16, SDPA attention ÏÇ¨Ïö©\n",
        "- **ÎùºÎ≤® Ï†ïÎ†¨**: Assistant Î©îÏãúÏßÄÏóê Ï†ïÎãµ Ìè¨Ìï® (ÌïµÏã¨!)\n",
        "- **Ïû¨ÌòÑÏÑ±**: Seed 42 Í≥†Ï†ï\n",
        "- **Î©îÎ™®Î¶¨**: Gradient checkpointing, 4-bit QLoRA\n",
        "\n",
        "---\n",
        "\n",
        "**ü§ñ Generated for SSAFY AI Project 2025**\n",
        "\n",
        "**üìß Contact**: GitHub Issues\n",
        "\n",
        "**‚≠ê ÌñâÏö¥ÏùÑ ÎπïÎãàÎã§!**"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 8556585,
          "sourceId": 13477844,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31154,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "644d60fa16e14a7786aa7ce385554d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2a8379bf3ea43418434379e815660bc",
              "IPY_MODEL_55d5b2fe21d34886b9179776f6f98bb1",
              "IPY_MODEL_85dda7c448de40ecb7061ec3a544d659"
            ],
            "layout": "IPY_MODEL_a5f6d508a32545b3a9ca51ef845b0a6b"
          }
        },
        "b2a8379bf3ea43418434379e815660bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3516446107e94e689fac9a10cfc1a9d7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a3f83c8b67394cadb50ca5aa6cf9e8bb",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "55d5b2fe21d34886b9179776f6f98bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6256d625bbf432199ce2469cd83d168",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f3b3fc79f904d43be4ef1038e19597c",
            "value": 4
          }
        },
        "85dda7c448de40ecb7061ec3a544d659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8efdd5025fc141589c242237b0bfccfb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5a2878d8668e477394cf2d1ca411fde0",
            "value": "‚Äá4/4‚Äá[00:05&lt;00:00,‚Äá‚Äá1.27s/it]"
          }
        },
        "a5f6d508a32545b3a9ca51ef845b0a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3516446107e94e689fac9a10cfc1a9d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f83c8b67394cadb50ca5aa6cf9e8bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6256d625bbf432199ce2469cd83d168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f3b3fc79f904d43be4ef1038e19597c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8efdd5025fc141589c242237b0bfccfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a2878d8668e477394cf2d1ca411fde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cc74c36b46e4f13866573175b285688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81a078056180474abda1a72496dfa027",
              "IPY_MODEL_d7466c8a3a0f489b897e2c9958f2d4b5",
              "IPY_MODEL_77a78f6e8aa34281b70e96137386e319"
            ],
            "layout": "IPY_MODEL_2181b36c5b024b9d905d0b830af1c276"
          }
        },
        "81a078056180474abda1a72496dfa027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99306f7ae4fd4e16b6ceb9da8a546ace",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_795f5f0ff2ae4393b8f8efdd0c61df86",
            "value": "Epoch‚Äá1/3‚Äá[train]:‚Äá100%"
          }
        },
        "d7466c8a3a0f489b897e2c9958f2d4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5288fc8091f443218651d3f7f8ae30f5",
            "max": 219,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bb256b504ff436783a2a45d205c828a",
            "value": 219
          }
        },
        "77a78f6e8aa34281b70e96137386e319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5a0499a77df48159619c27c274bbd78",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9f719215192440faab85c4929396292b",
            "value": "‚Äá219/219‚Äá[4:59:55&lt;00:00,‚Äá73.10s/batch,‚Äáloss=0.0071,‚Äálr=7.80e-05]"
          }
        },
        "2181b36c5b024b9d905d0b830af1c276": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99306f7ae4fd4e16b6ceb9da8a546ace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "795f5f0ff2ae4393b8f8efdd0c61df86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5288fc8091f443218651d3f7f8ae30f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bb256b504ff436783a2a45d205c828a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5a0499a77df48159619c27c274bbd78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f719215192440faab85c4929396292b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c46cd4e38dcf464c99a20d9565aad4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de396401ba0a42d68eec28d2c85afb74",
              "IPY_MODEL_86e573df3b8e4b768c426a0d701aa56f",
              "IPY_MODEL_facaf6d6356f49fcb6f48b5e3c92d55d"
            ],
            "layout": "IPY_MODEL_97c4a9ba7afd447ba7109112678c9cd8"
          }
        },
        "de396401ba0a42d68eec28d2c85afb74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d2bf18b98e34d7f8297afee75c8d191",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a7d95dc71e83451d8f1c603b05371aca",
            "value": "Validating:‚Äá100%"
          }
        },
        "86e573df3b8e4b768c426a0d701aa56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d28d559c9a24efebdf87eb4b5656b71",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6150c200c22a42398521914c2e3e7f70",
            "value": 25
          }
        },
        "facaf6d6356f49fcb6f48b5e3c92d55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19411e4675094bd5abe4b1c3b1447630",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_392c8eb185284723a43726794002fff4",
            "value": "‚Äá25/25‚Äá[33:06&lt;00:00,‚Äá64.11s/it]"
          }
        },
        "97c4a9ba7afd447ba7109112678c9cd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5d2bf18b98e34d7f8297afee75c8d191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d95dc71e83451d8f1c603b05371aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d28d559c9a24efebdf87eb4b5656b71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6150c200c22a42398521914c2e3e7f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19411e4675094bd5abe4b1c3b1447630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "392c8eb185284723a43726794002fff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "788512e4d4b64173b33d541b725b13c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f370b53d35b44ad946b7ea039688642",
              "IPY_MODEL_ce6ab67995af466db591576a68d9bfe0",
              "IPY_MODEL_c4f202d61dc0492c9815d3ffd0af2fac"
            ],
            "layout": "IPY_MODEL_64dde711b09c44bfbb1a3c6b0d6a03b5"
          }
        },
        "6f370b53d35b44ad946b7ea039688642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_908530725ff04f8191e796fac674be89",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1807bf50057b40f899d1d0ccedeefe08",
            "value": "Epoch‚Äá2/3‚Äá[train]:‚Äá‚Äá‚Äá6%"
          }
        },
        "ce6ab67995af466db591576a68d9bfe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_779244efcee249078d442c66e1c842f5",
            "max": 219,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e18ae067e40146628739f043838b6999",
            "value": 13
          }
        },
        "c4f202d61dc0492c9815d3ffd0af2fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54d7fbd3277449438dc074abdd924e44",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b3e2dd33ed7d40329d7ef221febc96da",
            "value": "‚Äá13/219‚Äá[18:00&lt;4:46:01,‚Äá83.31s/batch,‚Äáloss=0.0098,‚Äálr=7.56e-05]"
          }
        },
        "64dde711b09c44bfbb1a3c6b0d6a03b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "908530725ff04f8191e796fac674be89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1807bf50057b40f899d1d0ccedeefe08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "779244efcee249078d442c66e1c842f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e18ae067e40146628739f043838b6999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54d7fbd3277449438dc074abdd924e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3e2dd33ed7d40329d7ef221febc96da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
