# β΅ Qwen3-30B Multi-GPU λΉ λ¥Έ μ‹μ‘

## π― 1λ¶„ μ”μ•½

T4 * 2 (32GB)μ—μ„ Qwen3-VL-30B (30B νλΌλ―Έν„°) λ¨λΈμ„ μ•μ „ν•κ² μ‹¤ν–‰ν•©λ‹λ‹¤.

## π“¦ νμΌ

1. **qwen3_30b_multigpu_core.py** - ν•µμ‹¬ λ΅μ§
2. **Kaggle_Qwen3_30B_MultiGPU.ipynb** - μ‹¤ν–‰ λ…ΈνΈλ¶
3. **QWEN3_30B_GUIDE.md** - μ™„μ „ κ°€μ΄λ“
4. **QWEN3_30B_QUICK_START.md** - μ΄ νμΌ

## π€ 30μ΄ μ‹μ‘

```python
# 1. λ¨λΈ λ΅λ“
from qwen3_30b_multigpu_core import create_model_and_processor_multigpu

model, processor = create_model_and_processor_multigpu(
    model_id="Qwen/Qwen2.5-VL-30B-A3B-Instruct",
    image_size=384,
    lora_r=8,
    max_memory_per_gpu={0: "14GB", 1: "14GB"}
)

# 2. λ°μ΄ν„° μ¤€λΉ„ (κΈ°μ΅΄ μ½”λ“ μ¬μ‚¬μ©)
# train_loader, valid_loader μƒμ„±

# 3. ν•™μµ
from qwen3_30b_multigpu_core import train_one_epoch_memory_efficient

avg_loss = train_one_epoch_memory_efficient(
    model, train_loader, optimizer, scheduler, scaler,
    grad_accum_steps=16, max_grad_norm=0.5, device="cuda:0"
)

# 4. μ¶”λ΅ 
from qwen3_30b_multigpu_core import infer_parallel

predictions = infer_parallel(model, processor, test_df, "/content")
```

## β™οΈ ν•µμ‹¬ μ„¤μ •

```python
# μ•μ „ν• κΈ°λ³Έ μ„¤μ • (T4 * 2)
IMAGE_SIZE = 384
LORA_R = 8
BATCH_SIZE = 1
GRAD_ACCUM_STEPS = 16
NUM_EPOCHS = 2
MAX_MEMORY_PER_GPU = {0: "14GB", 1: "14GB"}
```

## π”¥ μ°¨μ΄μ  (3B vs 30B)

| ν•­λ© | Qwen2.5-VL-3B | Qwen2.5-VL-30B |
|------|---------------|----------------|
| νλΌλ―Έν„° | 3B | 30B (10λ°°) |
| λ©”λ¨λ¦¬ (4-bit) | ~2GB | ~15GB |
| GPU ν•„μ” | T4 * 1 | T4 * 2 |
| λ°°μΉ ν¬κΈ° | 1-2 | 1 (ν•„μ) |
| Grad Accum | 4-8 | 16-32 |
| LoRA R | 16 | 8 |
| ν•™μµ μ†λ„ | 1x | ~2x λλ¦Ό |
| **μ •ν™•λ„** | 85-87% | **88-91%** β­ |

## π“ μ£Όμ” κΈ°μ 

### 1. Model Parallelism
λ¨λΈμ„ 2κ° GPUμ— μλ™ λ¶„μ‚°:
```python
device_map="auto",
max_memory={0: "14GB", 1: "14GB"}
```

### 2. 4-bit Quantization
λ©”λ¨λ¦¬ 75% μ κ°:
```python
load_in_4bit=True,
bnb_4bit_use_double_quant=True
```

### 3. Gradient Checkpointing
ν™μ„±ν™” λ©”λ¨λ¦¬ 40% μ κ°:
```python
model.gradient_checkpointing_enable()
```

### 4. High Gradient Accumulation
μ‘μ€ λ°°μΉ λ³΄μ™„:
```python
GRAD_ACCUM_STEPS = 16  # ν¨κ³Όμ  λ°°μΉ: 16
```

## π› λ¬Έμ  ν•΄κ²°

### OOM λ°μƒ
```python
IMAGE_SIZE = 320  # 384 β†’ 320
LORA_R = 4  # 8 β†’ 4
MAX_MEMORY_PER_GPU = {0: "12GB", 1: "12GB"}
```

### ν•™μµ λ„λ¬΄ λλ¦Ό
```python
# μ •μƒμ…λ‹λ‹¤. 30Bλ” 3B λ€λΉ„ 2-3λ°° λλ¦½λ‹λ‹¤.
# μ„±λ¥μ„ μ„ν• trade-offμ…λ‹λ‹¤.
```

### GPU λ¶κ· ν•
```python
# μλ™ κ· ν• μ΅°μ •λ©λ‹λ‹¤.
# device_map="auto"κ°€ μλ™ μ²λ¦¬ν•©λ‹λ‹¤.
```

## π“ μμƒ μ„±λ¥

### T4 * 2 ν™κ²½
- **ν•™μµ**: ~2λ¶„/epoch (IMAGE_SIZE=384)
- **λ©”λ¨λ¦¬**: GPU0 13GB, GPU1 13GB
- **μ •ν™•λ„**: **88-90%** (3B λ€λΉ„ +3~5%)

### κ¶μ¥ λ¦¬μ†μ¤λ³„

| λ¦¬μ†μ¤ | IMAGE_SIZE | LORA_R | μμƒ μ •ν™•λ„ |
|--------|-----------|--------|------------|
| T4 * 2 | 384 | 8 | 88-90% β­ |
| V100 * 2 | 448 | 12 | 89-91% |
| A100 * 2 | 512 | 16 | 90-92% |

## β… λΉ λ¥Έ μ²΄ν¬λ¦¬μ¤νΈ

- [ ] GPU 2κ° ν™•μΈ
- [ ] qwen3_30b_multigpu_core.py μ„ν¬νΈ
- [ ] MAX_MEMORY_PER_GPU μ„¤μ •
- [ ] λ¨λΈ λ΅λ“ μ„±κ³µ
- [ ] GPU λ©”λ¨λ¦¬ < 14GB κ°κ°
- [ ] ν•™μµ μ‹μ‘
- [ ] Loss κ°μ† ν™•μΈ

## π”— μƒμ„Έ μ •λ³΄

- **μ™„μ „ κ°€μ΄λ“**: QWEN3_30B_GUIDE.md
- **ν•µμ‹¬ μ½”λ“**: qwen3_30b_multigpu_core.py
- **μ‹¤ν–‰ λ…ΈνΈλ¶**: Kaggle_Qwen3_30B_MultiGPU.ipynb

---

**π― κ¶μ¥**: IMAGE_SIZE=384, LORA_R=8, GRAD_ACCUM=16
**π“ μ„±λ¥**: 88-90% μ •ν™•λ„ (3B λ€λΉ„ +3~5%)
**π’Ύ λ©”λ¨λ¦¬**: μ•μ „ (κ° GPU ~13GB)

**π¤– SSAFY AI Project 2025**
