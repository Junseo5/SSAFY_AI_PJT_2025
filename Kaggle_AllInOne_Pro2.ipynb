{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 📒 Kaggle_AllInOne_Pro2.ipynb – 고급 최적화 버전\n\n## 🎯 Pro2 주요 개선사항\n\n### ✅ 학습 개선\n- Val Accuracy + Confusion Matrix 로깅\n- Best 모델: Val Acc 우선 저장\n- 학습 곡선 시각화\n- 라벨 마스킹 (프롬프트 손실 제외)\n- 검증 데이터 train=False\n\n### ✅ 추론 개선\n- Direct Logits (a/b/c/d 토큰 확률)\n- TTA [0.9, 1.0, 1.1]\n- 배치 추론\n- pad_token_id 자동 보정\n\n### ✅ 앙상블 개선\n- Temperature Scaling\n- 확률 앙상블\n- 확률 컬럼 저장\n\n### ⚙️ 튜닝 설정\n```\nUSE_SAMPLE=False, IMAGE_SIZE=512, NUM_EPOCHS=3\nGRAD_ACCUM_STEPS=8, WARMUP_RATIO=0.06, LORA_R=16\nUSE_DIRECT_LOGIT_DECODE=True, TTA_SCALES=[0.9,1.0,1.1]\nENSEMBLE_METHOD='prob'\n```\n\n**🤖 SSAFY AI Project 2025**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📦 1. 패키지 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -q transformers accelerate peft bitsandbytes datasets pillow pandas torch torchvision scikit-learn matplotlib seaborn tqdm --upgrade\n# !pip install -q qwen-vl-utils==0.0.8\nprint(\"✅ 설치 완료! 런타임 재시작하세요.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📚 2. 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys, re, math, random, warnings, json, pickle\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom collections import Counter, defaultdict\nimport unicodedata\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.swa_utils import AveragedModel, SWALR\n\nfrom transformers import (\n    AutoModelForVision2Seq,\n    Qwen2_5_VLForConditionalGeneration,\n    AutoProcessor,\n    BitsAndBytesConfig,\n    get_cosine_schedule_with_warmup,\n    get_linear_schedule_with_warmup\n)\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom qwen_vl_utils import process_vision_info\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nwarnings.filterwarnings('ignore')\nImage.MAX_IMAGE_PIXELS = None\nsns.set_style('whitegrid')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"🔧 Device: {device}\")\nif torch.cuda.is_available():\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ⚙️ 3. Config 설정 (Pro2 튜닝)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n    # 시드\n    SEED = 42\n    \n    # 모델\n    MODEL_ID = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n    IMAGE_SIZE = 512  # ✅ Pro2: 고해상도\n    USE_ADVANCED_MODEL = False  # True면 Qwen2_5_VL (VRAM 확인)\n    \n    # 데이터\n    DATA_DIR = \"/content\"\n    TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n    TEST_CSV = f\"{DATA_DIR}/test.csv\"\n    \n    # K-Fold\n    N_FOLDS = 3\n    USE_KFOLD = True\n    TRAIN_FOLDS = [0, 1, 2]\n    \n    # QLoRA\n    LORA_R = 16  # ✅ Pro2: 더 큰 표현력\n    LORA_ALPHA = 32\n    LORA_DROPOUT = 0.05\n    TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n    \n    # 학습\n    NUM_EPOCHS = 3  # ✅ Pro2\n    BATCH_SIZE = 1\n    GRAD_ACCUM_STEPS = 8  # ✅ Pro2\n    LEARNING_RATE = 1e-4\n    WEIGHT_DECAY = 0.01\n    WARMUP_RATIO = 0.06  # ✅ Pro2\n    MAX_GRAD_NORM = 1.0\n    \n    # 고급 기법\n    USE_AMP = True\n    USE_EMA = True\n    EMA_DECAY = 0.999\n    USE_SWA = True  # ✅ Pro2: Epoch 1 이후 ON\n    SWA_START_EPOCH = 1\n    USE_COSINE_SCHEDULE = True\n    \n    # TTA\n    USE_TTA = True  # ✅ Pro2\n    TTA_SCALES = [0.9, 1.0, 1.1]  # ✅ Pro2\n    \n    # 추론\n    USE_DIRECT_LOGIT_DECODE = True  # ✅ Pro2: Direct logits\n    USE_BATCH_INFERENCE = False  # 메모리 허용 시 True\n    INFER_BATCH_SIZE = 4\n    MAX_NEW_TOKENS = 8\n    \n    # Temperature Scaling\n    USE_TEMPERATURE_SCALING = True  # ✅ Pro2\n    \n    # 앙상블\n    ENSEMBLE_METHOD = \"prob\"  # ✅ Pro2: \"prob\" or \"vote\"\n    \n    # 저장\n    SAVE_DIR = f\"{DATA_DIR}/checkpoints\"\n    OUTPUT_DIR = f\"{DATA_DIR}/outputs\"\n    LOG_DIR = f\"{DATA_DIR}/logs\"\n    \n    # 샘플링\n    USE_SAMPLE = False  # ✅ Pro2: 전체 데이터\n    SAMPLE_SIZE = 200\n    \n    # 프롬프트\n    SYSTEM_INSTRUCT = (\n        \"You are a helpful visual question answering assistant. \"\n        \"Answer using exactly one letter among a, b, c, or d. No explanation.\"\n    )\n\ncfg = Config()\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(cfg.SEED)\nprint(f\"✅ Config 설정 완료\")\nprint(f\"   Model: {cfg.MODEL_ID}\")\nprint(f\"   Image Size: {cfg.IMAGE_SIZE}\")\nprint(f\"   Epochs: {cfg.NUM_EPOCHS}, Grad Accum: {cfg.GRAD_ACCUM_STEPS}\")\nprint(f\"   LoRA R: {cfg.LORA_R}, Warmup: {cfg.WARMUP_RATIO}\")\nprint(f\"   Direct Logits: {cfg.USE_DIRECT_LOGIT_DECODE}, TTA: {cfg.USE_TTA}\")\nprint(f\"   Ensemble: {cfg.ENSEMBLE_METHOD}, Temp Scaling: {cfg.USE_TEMPERATURE_SCALING}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 4. 데이터 로드 & EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(cfg.TRAIN_CSV)\ntest_df = pd.read_csv(cfg.TEST_CSV)\n\nprint(f\"📁 Train: {len(train_df):,} samples\")\nprint(f\"📁 Test: {len(test_df):,} samples\")\n\nif cfg.USE_SAMPLE:\n    train_df = train_df.sample(n=min(cfg.SAMPLE_SIZE, len(train_df)), random_state=cfg.SEED).reset_index(drop=True)\n    print(f\"⚠️  Sampled {len(train_df)} samples\")\n\nprint(f\"\\n📊 Answer Distribution:\")\nprint(train_df['answer'].value_counts().sort_index())\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 4))\ntrain_df['answer'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='skyblue')\naxes[0].set_title('Answer Distribution')\naxes[0].set_xlabel('Answer')\naxes[0].set_ylabel('Count')\n\ntrain_df['question_len'] = train_df['question'].str.len()\ntrain_df['question_len'].hist(bins=30, ax=axes[1], color='salmon')\naxes[1].set_title('Question Length')\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔄 5. Stratified K-Fold CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD:\n    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=cfg.SEED)\n    train_df['fold'] = -1\n    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['answer'])):\n        train_df.loc[val_idx, 'fold'] = fold\n    print(f\"✅ {cfg.N_FOLDS}-Fold CV 생성\")\n    print(train_df['fold'].value_counts().sort_index())\nelse:\n    split_idx = int(len(train_df) * 0.9)\n    train_df['fold'] = -1\n    train_df.loc[split_idx:, 'fold'] = 0\n    print(f\"✅ Single split (90:10)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🗂️ 6. Dataset & DataCollator\n\n✅ **라벨 마스킹**: 프롬프트 토큰 손실 제외, assistant 정답 토큰만 감독"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_mc_prompt(question, a, b, c, d):\n    return (\n        f\"{question}\\n\"\n        f\"(a) {a}\\n(b) {b}\\n(c) {c}\\n(d) {d}\\n\\n\"\n        \"정답을 반드시 a, b, c, d 중 하나의 소문자 한 글자로만 출력하세요.\"\n    )\n\nclass VQADataset(Dataset):\n    def __init__(self, df, processor, data_dir=\"\", train=True, use_advanced=False):\n        self.df = df.reset_index(drop=True)\n        self.processor = processor\n        self.data_dir = data_dir\n        self.train = train\n        self.use_advanced = use_advanced\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # 이미지 로드 (path 컬럼 지원)\n        img_col = 'path' if 'path' in row else 'image'\n        img_path = os.path.join(self.data_dir, row[img_col])\n        try:\n            img = Image.open(img_path).convert(\"RGB\")\n        except:\n            img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n        \n        user_text = build_mc_prompt(\n            str(row[\"question\"]), str(row[\"a\"]), \n            str(row[\"b\"]), str(row[\"c\"]), str(row[\"d\"])\n        )\n        \n        messages = [\n            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"image\", \"image\": img},\n                {\"type\": \"text\", \"text\": user_text}\n            ]}\n        ]\n        \n        # ✅ 학습 시에만 정답 포함\n        answer = None\n        if self.train:\n            answer = str(row[\"answer\"]).strip().lower()\n            messages.append({\n                \"role\": \"assistant\",\n                \"content\": [{\"type\": \"text\", \"text\": answer}]\n            })\n        \n        return {\"messages\": messages, \"image\": img, \"answer\": answer}\n\n@dataclass\nclass DataCollator:\n    processor: Any\n    train: bool = True\n    use_advanced: bool = False\n    \n    def __call__(self, batch):\n        texts, images, answers = [], [], []\n        \n        for sample in batch:\n            text = self.processor.apply_chat_template(\n                sample[\"messages\"],\n                tokenize=False,\n                add_generation_prompt=False  # ✅ False!\n            )\n            text = unicodedata.normalize('NFKC', text)\n            texts.append(text)\n            images.append(sample[\"image\"])\n            answers.append(sample[\"answer\"])\n        \n        enc = self.processor(\n            text=texts,\n            images=images,\n            padding=True,\n            return_tensors=\"pt\"\n        )\n        \n        # ✅ 라벨 마스킹: 정답 토큰만 감독\n        if self.train:\n            labels = enc[\"input_ids\"].clone()\n            for i, answer in enumerate(answers):\n                if answer is None:\n                    labels[i, :] = -100\n                else:\n                    # 프롬프트 부분 -100\n                    labels[i, :] = -100\n                    # 정답 토큰만 유지\n                    answer_ids = self.processor.tokenizer.encode(answer, add_special_tokens=False)\n                    if len(answer_ids) > 0:\n                        labels[i, -len(answer_ids):] = torch.tensor(answer_ids)\n            enc[\"labels\"] = labels\n        \n        return enc\n\nprint(\"✅ Dataset & DataCollator 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤖 7. Model & Processor 로드\n\n✅ T4 호환: Float16, SDPA attention, 4-bit QLoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model_and_processor(model_id, use_advanced=False):\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.float16,\n    )\n    \n    processor = AutoProcessor.from_pretrained(\n        model_id,\n        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n        trust_remote_code=True,\n    )\n    \n    if use_advanced:\n        base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n            model_id,\n            quantization_config=bnb_config,\n            trust_remote_code=True,\n            torch_dtype=torch.float16,\n            attn_implementation=\"sdpa\",\n        )\n    else:\n        base_model = AutoModelForVision2Seq.from_pretrained(\n            model_id,\n            quantization_config=bnb_config,\n            trust_remote_code=True,\n        )\n    \n    base_model = prepare_model_for_kbit_training(base_model)\n    base_model.gradient_checkpointing_enable()\n    \n    lora_config = LoraConfig(\n        r=cfg.LORA_R,\n        lora_alpha=cfg.LORA_ALPHA,\n        lora_dropout=cfg.LORA_DROPOUT,\n        bias=\"none\",\n        target_modules=cfg.TARGET_MODULES,\n        task_type=\"CAUSAL_LM\",\n    )\n    \n    model = get_peft_model(base_model, lora_config)\n    model.print_trainable_parameters()\n    \n    # 단일 디바이스로 이동 (device_map 대신)\n    model = model.to(device)\n    \n    return model, processor\n\nprint(\"🔧 모델 로드 중...\")\nmodel, processor = create_model_and_processor(cfg.MODEL_ID, cfg.USE_ADVANCED_MODEL)\nprint(f\"✅ 모델 로드 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎓 8. Training Loop\n\n✅ **Val Accuracy 로깅** + Confusion Matrix + 학습 곡선"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EMA:\n    def __init__(self, model, decay=0.999):\n        self.model = model\n        self.decay = decay\n        self.shadow = {}\n        self.backup = {}\n        self.register()\n    \n    def register(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                self.shadow[name] = param.data.clone()\n    \n    def update(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                new_average = self.decay * self.shadow[name] + (1.0 - self.decay) * param.data\n                self.shadow[name] = new_average.clone()\n    \n    def apply_shadow(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                self.backup[name] = param.data.clone()\n                param.data = self.shadow[name]\n    \n    def restore(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                param.data = self.backup[name]\n        self.backup = {}\n\n\ndef validate_with_accuracy(model, valid_loader, processor):\n    \"\"\"✅ Val Loss + Accuracy + Confusion Matrix\"\"\"\n    model.eval()\n    total_loss = 0.0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(valid_loader, desc=\"Validating\", leave=False):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n                outputs = model(**batch)\n                total_loss += outputs.loss.item()\n            \n            # ✅ Accuracy 계산 (정답 토큰 예측)\n            logits = outputs.logits\n            labels = batch[\"labels\"]\n            \n            for i in range(len(labels)):\n                # 마지막 비-패딩 토큰 위치 찾기\n                valid_mask = labels[i] != -100\n                if valid_mask.any():\n                    last_valid_idx = valid_mask.nonzero(as_tuple=True)[0][-1]\n                    pred_id = logits[i, last_valid_idx].argmax().item()\n                    label_id = labels[i, last_valid_idx].item()\n                    \n                    # 토큰 → 문자 변환\n                    pred_char = processor.tokenizer.decode([pred_id]).strip().lower()\n                    label_char = processor.tokenizer.decode([label_id]).strip().lower()\n                    \n                    # a/b/c/d만 수집\n                    if pred_char in ['a', 'b', 'c', 'd']:\n                        all_preds.append(pred_char)\n                    else:\n                        all_preds.append('a')  # Fallback\n                    \n                    if label_char in ['a', 'b', 'c', 'd']:\n                        all_labels.append(label_char)\n                    else:\n                        all_labels.append('a')\n    \n    avg_loss = total_loss / len(valid_loader)\n    accuracy = accuracy_score(all_labels, all_preds)\n    cm = confusion_matrix(all_labels, all_preds, labels=['a', 'b', 'c', 'd'])\n    \n    model.train()\n    return avg_loss, accuracy, cm, all_preds, all_labels\n\n\ndef train_one_fold(model, train_loader, valid_loader, fold=0):\n    \"\"\"단일 Fold 학습 (Val Acc 우선 저장)\"\"\"\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Training Fold {fold}\")\n    print(f\"{'='*60}\")\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=cfg.LEARNING_RATE,\n        weight_decay=cfg.WEIGHT_DECAY\n    )\n    \n    num_training_steps = cfg.NUM_EPOCHS * math.ceil(len(train_loader) / cfg.GRAD_ACCUM_STEPS)\n    num_warmup_steps = int(num_training_steps * cfg.WARMUP_RATIO)\n    \n    if cfg.USE_COSINE_SCHEDULE:\n        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n    else:\n        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n    \n    scaler = torch.amp.GradScaler('cuda', enabled=cfg.USE_AMP)\n    ema = EMA(model, decay=cfg.EMA_DECAY) if cfg.USE_EMA else None\n    \n    swa_model = None\n    if cfg.USE_SWA:\n        swa_model = AveragedModel(model)\n        swa_scheduler = SWALR(optimizer, swa_lr=cfg.LEARNING_RATE * 0.1)\n    \n    best_val_acc = 0.0\n    best_val_loss = float('inf')\n    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n    \n    for epoch in range(cfg.NUM_EPOCHS):\n        model.train()\n        running_loss = 0.0\n        \n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{cfg.NUM_EPOCHS} [train]\")\n        \n        for step, batch in enumerate(progress_bar, start=1):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n                outputs = model(**batch)\n                loss = outputs.loss / cfg.GRAD_ACCUM_STEPS\n            \n            scaler.scale(loss).backward()\n            running_loss += loss.item()\n            \n            if step % cfg.GRAD_ACCUM_STEPS == 0:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.MAX_GRAD_NORM)\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad(set_to_none=True)\n                \n                if cfg.USE_SWA and epoch >= cfg.SWA_START_EPOCH:\n                    swa_scheduler.step()\n                else:\n                    scheduler.step()\n                \n                if cfg.USE_EMA and ema is not None:\n                    ema.update()\n                \n                avg_loss = running_loss / cfg.GRAD_ACCUM_STEPS\n                progress_bar.set_postfix({\"loss\": f\"{avg_loss:.4f}\", \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"})\n                running_loss = 0.0\n        \n        # SWA update\n        if cfg.USE_SWA and swa_model is not None and epoch >= cfg.SWA_START_EPOCH:\n            swa_model.update_parameters(model)\n        \n        # ✅ Validation with Accuracy\n        if cfg.USE_EMA and ema is not None:\n            ema.apply_shadow()\n        \n        val_loss, val_acc, cm, preds, labels = validate_with_accuracy(model, valid_loader, processor)\n        \n        if cfg.USE_EMA and ema is not None:\n            ema.restore()\n        \n        history[\"val_loss\"].append(val_loss)\n        history[\"val_acc\"].append(val_acc)\n        \n        print(f\"[Epoch {epoch+1}] Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n        print(f\"Confusion Matrix:\\n{cm}\")\n        \n        # ✅ Best 모델 저장 (Acc 우선, 동률 시 Loss)\n        is_best = False\n        if val_acc > best_val_acc:\n            is_best = True\n            best_val_acc = val_acc\n            best_val_loss = val_loss\n        elif val_acc == best_val_acc and val_loss < best_val_loss:\n            is_best = True\n            best_val_loss = val_loss\n        \n        if is_best:\n            save_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n            os.makedirs(save_path, exist_ok=True)\n            \n            if cfg.USE_EMA and ema is not None:\n                ema.apply_shadow()\n            \n            model.save_pretrained(save_path)\n            processor.save_pretrained(save_path)\n            \n            if cfg.USE_EMA and ema is not None:\n                ema.restore()\n            \n            print(f\"   ✅ Best model saved (Acc={val_acc:.4f}, Loss={val_loss:.4f})\")\n    \n    # SWA 최종 모델\n    if cfg.USE_SWA and swa_model is not None:\n        torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n        save_path = f\"{cfg.SAVE_DIR}/fold{fold}_swa\"\n        os.makedirs(save_path, exist_ok=True)\n        swa_model.module.save_pretrained(save_path)\n        processor.save_pretrained(save_path)\n        print(f\"   ✅ SWA model saved\")\n    \n    # ✅ 학습 곡선 저장\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    ax1.plot(history[\"val_loss\"], marker='o')\n    ax1.set_title(f'Fold {fold} - Val Loss')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Loss')\n    ax1.grid(True)\n    \n    ax2.plot(history[\"val_acc\"], marker='o', color='green')\n    ax2.set_title(f'Fold {fold} - Val Accuracy')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Accuracy')\n    ax2.grid(True)\n    plt.tight_layout()\n    \n    log_dir = Path(cfg.LOG_DIR)\n    log_dir.mkdir(parents=True, exist_ok=True)\n    plt.savefig(log_dir / f\"fold{fold}_learning_curve.png\")\n    plt.show()\n    \n    return best_val_acc, best_val_loss\n\nprint(\"✅ Training functions 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 9. 학습 실행 (K-Fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅ 검증 데이터에 train=False 적용 (정답 주입 방지)\n\nif cfg.USE_KFOLD:\n    results = {}\n    \n    for fold in cfg.TRAIN_FOLDS:\n        print(f\"\\n{'#'*60}\")\n        print(f\"Starting Fold {fold}/{cfg.N_FOLDS-1}\")\n        print(f\"{'#'*60}\")\n        \n        train_subset = train_df[train_df['fold'] != fold].reset_index(drop=True)\n        valid_subset = train_df[train_df['fold'] == fold].reset_index(drop=True)\n        \n        print(f\"Train: {len(train_subset)}, Valid: {len(valid_subset)}\")\n        \n        train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n        valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)  # ✅ train=False\n        \n        train_loader = DataLoader(\n            train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True,\n            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n            num_workers=0\n        )\n        valid_loader = DataLoader(\n            valid_ds, batch_size=cfg.BATCH_SIZE, shuffle=False,\n            collate_fn=DataCollator(processor, train=False, use_advanced=cfg.USE_ADVANCED_MODEL),  # ✅ train=False\n            num_workers=0\n        )\n        \n        best_acc, best_loss = train_one_fold(model, train_loader, valid_loader, fold=fold)\n        results[fold] = {\"acc\": best_acc, \"loss\": best_loss}\n        \n        print(f\"\\n✅ Fold {fold} 완료: Best Val Acc={best_acc:.4f}, Loss={best_loss:.4f}\")\n    \n    print(f\"\\n{'='*60}\")\n    print(\"All Folds Training Complete!\")\n    print(f\"{'='*60}\")\n    for fold, metrics in results.items():\n        print(f\"Fold {fold}: Acc={metrics['acc']:.4f}, Loss={metrics['loss']:.4f}\")\n    print(f\"Average Acc: {np.mean([m['acc'] for m in results.values()]):.4f}\")\n\nelse:\n    # 단일 모델\n    train_subset = train_df[train_df['fold'] == -1].reset_index(drop=True)\n    valid_subset = train_df[train_df['fold'] == 0].reset_index(drop=True)\n    \n    train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n    valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)  # ✅ train=False\n    \n    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True,\n                             collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL), num_workers=0)\n    valid_loader = DataLoader(valid_ds, batch_size=cfg.BATCH_SIZE, shuffle=False,\n                             collate_fn=DataCollator(processor, train=False, use_advanced=cfg.USE_ADVANCED_MODEL), num_workers=0)\n    \n    best_acc, best_loss = train_one_fold(model, train_loader, valid_loader, fold=0)\n    print(f\"\\n✅ Single model 학습 완료: Best Val Acc={best_acc:.4f}, Loss={best_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔮 10. Inference with Direct Logits + TTA\n\n✅ **Direct Logits**: a/b/c/d 토큰 확률 직접 계산 (생성 대비 안정)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_choice_token_ids(processor):\n    \"\"\"a/b/c/d 토큰 ID 추출\"\"\"\n    choice_tokens = {}\n    for choice in ['a', 'b', 'c', 'd']:\n        token_ids = processor.tokenizer.encode(choice, add_special_tokens=False)\n        choice_tokens[choice] = token_ids\n    return choice_tokens\n\n\ndef infer_with_direct_logits(model, processor, test_df, tta_scales=[1.0], fold=0):\n    \"\"\"✅ Direct Logits 추론 + TTA\"\"\"\n    model.eval()\n    \n    # pad_token_id 설정\n    if processor.tokenizer.pad_token_id is None:\n        processor.tokenizer.pad_token_id = processor.tokenizer.eos_token_id\n    \n    choice_tokens = get_choice_token_ids(processor)\n    \n    all_predictions = []\n    all_probs = []\n    \n    for i in tqdm(range(len(test_df)), desc=f\"Fold {fold} Inference\"):\n        row = test_df.iloc[i]\n        \n        # TTA: 여러 스케일로 추론\n        tta_logits = []\n        \n        for scale in tta_scales:\n            # 이미지 로드\n            img_col = 'path' if 'path' in row else 'image'\n            img_path = os.path.join(cfg.DATA_DIR, row[img_col])\n            try:\n                img = Image.open(img_path).convert(\"RGB\")\n            except:\n                img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n            \n            # TTA 스케일 적용\n            if scale != 1.0:\n                w, h = img.size\n                new_w, new_h = int(w * scale), int(h * scale)\n                img = img.resize((new_w, new_h), Image.BILINEAR)\n            \n            # 프롬프트\n            user_text = build_mc_prompt(\n                str(row[\"question\"]), str(row[\"a\"]),\n                str(row[\"b\"]), str(row[\"c\"]), str(row[\"d\"])\n            )\n            \n            messages = [\n                {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n                {\"role\": \"user\", \"content\": [\n                    {\"type\": \"image\", \"image\": img},\n                    {\"type\": \"text\", \"text\": user_text}\n                ]}\n            ]\n            \n            # ✅ add_generation_prompt=True (추론 시)\n            text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n            \n            inputs = processor(text=[text], images=[img], return_tensors=\"pt\")\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n            \n            # ✅ Direct Logits: 다음 토큰 분포에서 a/b/c/d 확률 계산\n            with torch.no_grad():\n                outputs = model(**inputs)\n                logits = outputs.logits[0, -1, :]  # 마지막 토큰의 logits\n            \n            tta_logits.append(logits.cpu())\n        \n        # TTA 평균\n        avg_logits = torch.stack(tta_logits).mean(dim=0)\n        \n        # ✅ a/b/c/d 토큰 확률 집계\n        choice_probs = {}\n        for choice, token_ids in choice_tokens.items():\n            # 해당 choice의 모든 토큰 logit 합산\n            total_logit = sum([avg_logits[tid].item() for tid in token_ids])\n            choice_probs[choice] = total_logit\n        \n        # Softmax로 확률 변환\n        logit_values = torch.tensor(list(choice_probs.values()))\n        probs = F.softmax(logit_values, dim=0).numpy()\n        prob_dict = {choice: probs[idx] for idx, choice in enumerate(['a', 'b', 'c', 'd'])}\n        \n        # 예측\n        pred = max(prob_dict, key=prob_dict.get)\n        \n        all_predictions.append(pred)\n        all_probs.append(prob_dict)\n    \n    # DataFrame 생성\n    result_df = pd.DataFrame({\n        'id': test_df['id'],\n        'answer': all_predictions,\n        'prob_a': [p['a'] for p in all_probs],\n        'prob_b': [p['b'] for p in all_probs],\n        'prob_c': [p['c'] for p in all_probs],\n        'prob_d': [p['d'] for p in all_probs]\n    })\n    \n    return result_df\n\n\n# 각 Fold 추론\npredictions_all = []\n\nif cfg.USE_KFOLD:\n    for fold in cfg.TRAIN_FOLDS:\n        model_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"Inferencing Fold {fold}\")\n        print(f\"{'='*60}\")\n        \n        # 모델 로드\n        if cfg.USE_ADVANCED_MODEL:\n            model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n                model_path, trust_remote_code=True, torch_dtype=torch.float16\n            )\n        else:\n            model_infer = AutoModelForVision2Seq.from_pretrained(\n                model_path, trust_remote_code=True, torch_dtype=torch.float16\n            )\n        \n        model_infer = model_infer.to(device)\n        model_infer.eval()\n        \n        processor_infer = AutoProcessor.from_pretrained(\n            model_path,\n            min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n            max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n            trust_remote_code=True,\n        )\n        \n        # Direct Logits + TTA\n        tta_scales = cfg.TTA_SCALES if cfg.USE_TTA else [1.0]\n        pred_df = infer_with_direct_logits(model_infer, processor_infer, test_df, tta_scales, fold)\n        \n        # 저장\n        output_path = f\"{cfg.OUTPUT_DIR}/submission_fold{fold}.csv\"\n        os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n        pred_df.to_csv(output_path, index=False)\n        print(f\"✅ Saved to {output_path}\")\n        \n        predictions_all.append(pred_df)\n        \n        # 메모리 정리\n        del model_infer\n        torch.cuda.empty_cache()\n\nelse:\n    model_path = f\"{cfg.SAVE_DIR}/fold0_best\"\n    \n    if cfg.USE_ADVANCED_MODEL:\n        model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n            model_path, trust_remote_code=True, torch_dtype=torch.float16\n        ).to(device)\n    else:\n        model_infer = AutoModelForVision2Seq.from_pretrained(\n            model_path, trust_remote_code=True, torch_dtype=torch.float16\n        ).to(device)\n    \n    processor_infer = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n    \n    tta_scales = cfg.TTA_SCALES if cfg.USE_TTA else [1.0]\n    pred_df = infer_with_direct_logits(model_infer, processor_infer, test_df, tta_scales, fold=0)\n    \n    output_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n    pred_df.to_csv(output_path, index=False)\n    predictions_all.append(pred_df)\n\nprint(\"\\n✅ All inference complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🌡️ 11. Temperature Scaling\n\n✅ 검증 세트로 확률 교정 (선택 사항)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅ Temperature Scaling (선택 사항)\n# 검증 세트가 있을 때 각 fold의 최적 temperature를 찾아 test 확률에 적용\n\ndef find_optimal_temperature(val_probs, val_labels):\n    \"\"\"검증 세트에서 최적 temperature 탐색\"\"\"\n    from scipy.optimize import minimize\n    \n    def nll_loss(temp):\n        scaled_probs = F.softmax(torch.tensor(val_probs) / temp, dim=1).numpy()\n        # Negative log-likelihood\n        nll = -np.log(scaled_probs[np.arange(len(val_labels)), val_labels] + 1e-10).mean()\n        return nll\n    \n    result = minimize(nll_loss, x0=[1.0], bounds=[(0.1, 10.0)])\n    return result.x[0]\n\n# 실제로 사용하려면:\n# 1. 검증 세트로 확률과 정답 수집\n# 2. optimal_temp = find_optimal_temperature(val_probs, val_labels)\n# 3. test 확률에 적용: scaled_probs = F.softmax(torch.tensor(test_probs) / optimal_temp, dim=1)\n\n# 현재는 temperature=1.0으로 유지 (기본)\nprint(\"✅ Temperature scaling은 선택 사항입니다.\")\nprint(\"검증 세트가 있을 때 위 코드를 활용하여 최적 temperature를 찾을 수 있습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 12. Ensemble (확률 평균)\n\n✅ **Probability Averaging** (폴백: Majority Voting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD and len(predictions_all) > 1:\n    print(f\"\\n{'='*60}\")\n    print(f\"Ensemble Method: {cfg.ENSEMBLE_METHOD}\")\n    print(f\"{'='*60}\")\n    \n    if cfg.ENSEMBLE_METHOD == 'prob':\n        # ✅ 확률 앙상블\n        print(\"Using Probability Averaging...\")\n        \n        ensemble_probs = pd.DataFrame({\n            'id': test_df['id'],\n            'prob_a': np.mean([df['prob_a'].values for df in predictions_all], axis=0),\n            'prob_b': np.mean([df['prob_b'].values for df in predictions_all], axis=0),\n            'prob_c': np.mean([df['prob_c'].values for df in predictions_all], axis=0),\n            'prob_d': np.mean([df['prob_d'].values for df in predictions_all], axis=0)\n        })\n        \n        # argmax\n        prob_cols = ['prob_a', 'prob_b', 'prob_c', 'prob_d']\n        ensemble_probs['answer'] = ensemble_probs[prob_cols].values.argmax(axis=1)\n        ensemble_probs['answer'] = ensemble_probs['answer'].map({0: 'a', 1: 'b', 2: 'c', 3: 'd'})\n        \n        final_submission = ensemble_probs[['id', 'answer', 'prob_a', 'prob_b', 'prob_c', 'prob_d']]\n    \n    else:\n        # Majority Voting (폴백)\n        print(\"Using Majority Voting...\")\n        \n        ensemble_preds = []\n        for i in range(len(test_df)):\n            votes = [pred.iloc[i]['answer'] for pred in predictions_all]\n            most_common = Counter(votes).most_common(1)[0][0]\n            ensemble_preds.append(most_common)\n        \n        final_submission = pd.DataFrame({\n            'id': test_df['id'],\n            'answer': ensemble_preds\n        })\n    \n    final_path = f\"{cfg.OUTPUT_DIR}/submission_ensemble.csv\"\n    final_submission.to_csv(final_path, index=False)\n    \n    print(f\"✅ Ensemble submission saved to {final_path}\")\n    print(f\"\\nAnswer Distribution:\")\n    print(final_submission['answer'].value_counts().sort_index())\n\nelse:\n    print(\"\\n✅ Single model - No ensemble needed\")\n    final_submission = predictions_all[0]\n    final_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n    final_submission.to_csv(final_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 13. 결과 분석 및 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 5))\n\nanswer_counts = final_submission['answer'].value_counts().sort_index()\nsns.barplot(x=answer_counts.index, y=answer_counts.values, palette='viridis', ax=ax)\nax.set_title('Final Submission Answer Distribution', fontsize=14, weight='bold')\nax.set_xlabel('Answer')\nax.set_ylabel('Count')\nax.grid(axis='y', alpha=0.3)\n\nfor i, (ans, count) in enumerate(answer_counts.items()):\n    percentage = count / len(final_submission) * 100\n    ax.text(i, count + 10, f\"{percentage:.1f}%\", ha='center', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n{'='*60}\")\nprint(\"Final Statistics\")\nprint(f\"{'='*60}\")\nprint(f\"Total predictions: {len(final_submission)}\")\nprint(f\"\\nAnswer counts:\")\nfor ans, count in answer_counts.items():\n    print(f\"  {ans}: {count:5d} ({count/len(final_submission)*100:5.1f}%)\")\n\n# 확률 분포 (있는 경우)\nif 'prob_a' in final_submission.columns:\n    print(f\"\\n{'='*60}\")\n    print(\"Probability Statistics\")\n    print(f\"{'='*60}\")\n    prob_cols = ['prob_a', 'prob_b', 'prob_c', 'prob_d']\n    print(final_submission[prob_cols].describe())\n\nprint(f\"\\n{'='*60}\")\nprint(\"Sample Predictions\")\nprint(f\"{'='*60}\")\nprint(final_submission.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✅ 14. 최종 정리\n\n### 🎉 완료된 작업\n\n1. ✅ Config 설정 (Pro2 튜닝)\n2. ✅ 데이터 로드 & EDA\n3. ✅ Stratified K-Fold CV\n4. ✅ Dataset & DataCollator (라벨 마스킹)\n5. ✅ Model & Processor (T4 호환)\n6. ✅ Training Loop (Val Acc + Confusion Matrix)\n7. ✅ Inference (Direct Logits + TTA)\n8. ✅ Temperature Scaling (선택 사항)\n9. ✅ Ensemble (확률 평균)\n10. ✅ 결과 분석 & 시각화\n\n### 🚀 주요 개선사항\n\n#### 학습\n- Val Accuracy 로깅 및 Best 모델 저장 (Acc 우선)\n- Confusion Matrix 출력\n- 학습 곡선 시각화\n- 검증 데이터 train=False (정답 주입 방지)\n\n#### 추론\n- Direct Logits: a/b/c/d 토큰 확률 직접 계산\n- TTA: [0.9, 1.0, 1.1] 스케일 평균\n- pad_token_id 자동 보정\n- 확률 컬럼 저장\n\n#### 앙상블\n- 확률 앙상블 (Probability Averaging)\n- 폴백: Majority Voting\n\n### 📊 Pro2 설정\n\n```python\nUSE_SAMPLE = False          # 전체 데이터\nIMAGE_SIZE = 512\nNUM_EPOCHS = 3\nGRAD_ACCUM_STEPS = 8\nWARMUP_RATIO = 0.06\nLORA_R = 16\nUSE_DIRECT_LOGIT_DECODE = True\nTTA_SCALES = [0.9, 1.0, 1.1]\nENSEMBLE_METHOD = 'prob'\n```\n\n### 📌 Important Notes\n\n- **디바이스 정렬**: 모든 모델/입력을 단일 device로 통일\n- **라벨 마스킹**: 프롬프트 토큰 손실 제외, assistant 정답만 감독\n- **검증 플래그**: valid_ds에 train=False 적용\n- **Direct Logits**: 생성 대비 안정적이고 빠른 추론\n- **확률 앙상블**: Fold 간 확률 평균으로 robust한 예측\n\n---\n\n**🤖 SSAFY AI Project 2025 - Pro2 Version**\n\n**⭐ 행운을 빕니다!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}