{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“’ Kaggle_AllInOne_Pro2.ipynb â€“ ê³ ê¸‰ ìµœì í™” ë²„ì „\n\n## ğŸ¯ Pro2 ì£¼ìš” ê°œì„ ì‚¬í•­\n\n### âœ… í•™ìŠµ ê°œì„ \n- Val Accuracy + Confusion Matrix ë¡œê¹…\n- Best ëª¨ë¸: Val Acc ìš°ì„  ì €ì¥\n- í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n- ë¼ë²¨ ë§ˆìŠ¤í‚¹ (í”„ë¡¬í”„íŠ¸ ì†ì‹¤ ì œì™¸)\n- ê²€ì¦ ë°ì´í„° train=False\n\n### âœ… ì¶”ë¡  ê°œì„ \n- Direct Logits (a/b/c/d í† í° í™•ë¥ )\n- TTA [0.9, 1.0, 1.1]\n- ë°°ì¹˜ ì¶”ë¡ \n- pad_token_id ìë™ ë³´ì •\n\n### âœ… ì•™ìƒë¸” ê°œì„ \n- Temperature Scaling\n- í™•ë¥  ì•™ìƒë¸”\n- í™•ë¥  ì»¬ëŸ¼ ì €ì¥\n\n### âš™ï¸ íŠœë‹ ì„¤ì •\n```\nUSE_SAMPLE=False, IMAGE_SIZE=512, NUM_EPOCHS=3\nGRAD_ACCUM_STEPS=8, WARMUP_RATIO=0.06, LORA_R=16\nUSE_DIRECT_LOGIT_DECODE=True, TTA_SCALES=[0.9,1.0,1.1]\nENSEMBLE_METHOD='prob'\n```\n\n**ğŸ¤– SSAFY AI Project 2025**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¦ 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -q transformers accelerate peft bitsandbytes datasets pillow pandas torch torchvision scikit-learn matplotlib seaborn tqdm --upgrade\n# !pip install -q qwen-vl-utils==0.0.8\nprint(\"âœ… ì„¤ì¹˜ ì™„ë£Œ! ëŸ°íƒ€ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys, re, math, random, warnings, json, pickle\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom collections import Counter, defaultdict\nimport unicodedata\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.swa_utils import AveragedModel, SWALR\n\nfrom transformers import (\n    AutoModelForVision2Seq,\n    Qwen2_5_VLForConditionalGeneration,\n    AutoProcessor,\n    BitsAndBytesConfig,\n    get_cosine_schedule_with_warmup,\n    get_linear_schedule_with_warmup\n)\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom qwen_vl_utils import process_vision_info\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nwarnings.filterwarnings('ignore')\nImage.MAX_IMAGE_PIXELS = None\nsns.set_style('whitegrid')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"ğŸ”§ Device: {device}\")\nif torch.cuda.is_available():\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš™ï¸ 3. Config ì„¤ì • (Pro2 íŠœë‹)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n    # ì‹œë“œ\n    SEED = 42\n    \n    # ëª¨ë¸\n    MODEL_ID = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n    IMAGE_SIZE = 512  # âœ… Pro2: ê³ í•´ìƒë„\n    USE_ADVANCED_MODEL = False  # Trueë©´ Qwen2_5_VL (VRAM í™•ì¸)\n    \n    # ë°ì´í„°\n    DATA_DIR = \"/content\"\n    TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n    TEST_CSV = f\"{DATA_DIR}/test.csv\"\n    \n    # K-Fold\n    N_FOLDS = 3\n    USE_KFOLD = True\n    TRAIN_FOLDS = [0, 1, 2]\n    \n    # QLoRA\n    LORA_R = 16  # âœ… Pro2: ë” í° í‘œí˜„ë ¥\n    LORA_ALPHA = 32\n    LORA_DROPOUT = 0.05\n    TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n    \n    # í•™ìŠµ\n    NUM_EPOCHS = 3  # âœ… Pro2\n    BATCH_SIZE = 1\n    GRAD_ACCUM_STEPS = 8  # âœ… Pro2\n    LEARNING_RATE = 1e-4\n    WEIGHT_DECAY = 0.01\n    WARMUP_RATIO = 0.06  # âœ… Pro2\n    MAX_GRAD_NORM = 1.0\n    \n    # ê³ ê¸‰ ê¸°ë²•\n    USE_AMP = True\n    USE_EMA = True\n    EMA_DECAY = 0.999\n    USE_SWA = True  # âœ… Pro2: Epoch 1 ì´í›„ ON\n    SWA_START_EPOCH = 1\n    USE_COSINE_SCHEDULE = True\n    \n    # TTA\n    USE_TTA = True  # âœ… Pro2\n    TTA_SCALES = [0.9, 1.0, 1.1]  # âœ… Pro2\n    \n    # ì¶”ë¡ \n    USE_DIRECT_LOGIT_DECODE = True  # âœ… Pro2: Direct logits\n    USE_BATCH_INFERENCE = False  # ë©”ëª¨ë¦¬ í—ˆìš© ì‹œ True\n    INFER_BATCH_SIZE = 4\n    MAX_NEW_TOKENS = 8\n    \n    # Temperature Scaling\n    USE_TEMPERATURE_SCALING = True  # âœ… Pro2\n    \n    # ì•™ìƒë¸”\n    ENSEMBLE_METHOD = \"prob\"  # âœ… Pro2: \"prob\" or \"vote\"\n    \n    # ì €ì¥\n    SAVE_DIR = f\"{DATA_DIR}/checkpoints\"\n    OUTPUT_DIR = f\"{DATA_DIR}/outputs\"\n    LOG_DIR = f\"{DATA_DIR}/logs\"\n    \n    # ìƒ˜í”Œë§\n    USE_SAMPLE = False  # âœ… Pro2: ì „ì²´ ë°ì´í„°\n    SAMPLE_SIZE = 200\n    \n    # í”„ë¡¬í”„íŠ¸\n    SYSTEM_INSTRUCT = (\n        \"You are a helpful visual question answering assistant. \"\n        \"Answer using exactly one letter among a, b, c, or d. No explanation.\"\n    )\n\ncfg = Config()\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(cfg.SEED)\nprint(f\"âœ… Config ì„¤ì • ì™„ë£Œ\")\nprint(f\"   Model: {cfg.MODEL_ID}\")\nprint(f\"   Image Size: {cfg.IMAGE_SIZE}\")\nprint(f\"   Epochs: {cfg.NUM_EPOCHS}, Grad Accum: {cfg.GRAD_ACCUM_STEPS}\")\nprint(f\"   LoRA R: {cfg.LORA_R}, Warmup: {cfg.WARMUP_RATIO}\")\nprint(f\"   Direct Logits: {cfg.USE_DIRECT_LOGIT_DECODE}, TTA: {cfg.USE_TTA}\")\nprint(f\"   Ensemble: {cfg.ENSEMBLE_METHOD}, Temp Scaling: {cfg.USE_TEMPERATURE_SCALING}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š 4. ë°ì´í„° ë¡œë“œ & EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(cfg.TRAIN_CSV)\ntest_df = pd.read_csv(cfg.TEST_CSV)\n\nprint(f\"ğŸ“ Train: {len(train_df):,} samples\")\nprint(f\"ğŸ“ Test: {len(test_df):,} samples\")\n\nif cfg.USE_SAMPLE:\n    train_df = train_df.sample(n=min(cfg.SAMPLE_SIZE, len(train_df)), random_state=cfg.SEED).reset_index(drop=True)\n    print(f\"âš ï¸  Sampled {len(train_df)} samples\")\n\nprint(f\"\\nğŸ“Š Answer Distribution:\")\nprint(train_df['answer'].value_counts().sort_index())\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 4))\ntrain_df['answer'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='skyblue')\naxes[0].set_title('Answer Distribution')\naxes[0].set_xlabel('Answer')\naxes[0].set_ylabel('Count')\n\ntrain_df['question_len'] = train_df['question'].str.len()\ntrain_df['question_len'].hist(bins=30, ax=axes[1], color='salmon')\naxes[1].set_title('Question Length')\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”„ 5. Stratified K-Fold CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD:\n    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=cfg.SEED)\n    train_df['fold'] = -1\n    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['answer'])):\n        train_df.loc[val_idx, 'fold'] = fold\n    print(f\"âœ… {cfg.N_FOLDS}-Fold CV ìƒì„±\")\n    print(train_df['fold'].value_counts().sort_index())\nelse:\n    split_idx = int(len(train_df) * 0.9)\n    train_df['fold'] = -1\n    train_df.loc[split_idx:, 'fold'] = 0\n    print(f\"âœ… Single split (90:10)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ—‚ï¸ 6. Dataset & DataCollator\n\nâœ… **ë¼ë²¨ ë§ˆìŠ¤í‚¹**: í”„ë¡¬í”„íŠ¸ í† í° ì†ì‹¤ ì œì™¸, assistant ì •ë‹µ í† í°ë§Œ ê°ë…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_mc_prompt(question, a, b, c, d):\n    return (\n        f\"{question}\\n\"\n        f\"(a) {a}\\n(b) {b}\\n(c) {c}\\n(d) {d}\\n\\n\"\n        \"ì •ë‹µì„ ë°˜ë“œì‹œ a, b, c, d ì¤‘ í•˜ë‚˜ì˜ ì†Œë¬¸ì í•œ ê¸€ìë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\"\n    )\n\nclass VQADataset(Dataset):\n    def __init__(self, df, processor, data_dir=\"\", train=True, use_advanced=False):\n        self.df = df.reset_index(drop=True)\n        self.processor = processor\n        self.data_dir = data_dir\n        self.train = train\n        self.use_advanced = use_advanced\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # ì´ë¯¸ì§€ ë¡œë“œ (path ì»¬ëŸ¼ ì§€ì›)\n        img_col = 'path' if 'path' in row else 'image'\n        img_path = os.path.join(self.data_dir, row[img_col])\n        try:\n            img = Image.open(img_path).convert(\"RGB\")\n        except:\n            img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n        \n        user_text = build_mc_prompt(\n            str(row[\"question\"]), str(row[\"a\"]), \n            str(row[\"b\"]), str(row[\"c\"]), str(row[\"d\"])\n        )\n        \n        messages = [\n            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"image\", \"image\": img},\n                {\"type\": \"text\", \"text\": user_text}\n            ]}\n        ]\n        \n        # âœ… í•™ìŠµ ì‹œì—ë§Œ ì •ë‹µ í¬í•¨\n        answer = None\n        if self.train:\n            answer = str(row[\"answer\"]).strip().lower()\n            messages.append({\n                \"role\": \"assistant\",\n                \"content\": [{\"type\": \"text\", \"text\": answer}]\n            })\n        \n        return {\"messages\": messages, \"image\": img, \"answer\": answer}\n\n@dataclass\nclass DataCollator:\n    processor: Any\n    train: bool = True\n    use_advanced: bool = False\n    \n    def __call__(self, batch):\n        texts, images, answers = [], [], []\n        \n        for sample in batch:\n            text = self.processor.apply_chat_template(\n                sample[\"messages\"],\n                tokenize=False,\n                add_generation_prompt=False  # âœ… False!\n            )\n            text = unicodedata.normalize('NFKC', text)\n            texts.append(text)\n            images.append(sample[\"image\"])\n            answers.append(sample[\"answer\"])\n        \n        enc = self.processor(\n            text=texts,\n            images=images,\n            padding=True,\n            return_tensors=\"pt\"\n        )\n        \n        # âœ… ë¼ë²¨ ë§ˆìŠ¤í‚¹: ì •ë‹µ í† í°ë§Œ ê°ë…\n        if self.train:\n            labels = enc[\"input_ids\"].clone()\n            for i, answer in enumerate(answers):\n                if answer is None:\n                    labels[i, :] = -100\n                else:\n                    # í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ -100\n                    labels[i, :] = -100\n                    # ì •ë‹µ í† í°ë§Œ ìœ ì§€\n                    answer_ids = self.processor.tokenizer.encode(answer, add_special_tokens=False)\n                    if len(answer_ids) > 0:\n                        labels[i, -len(answer_ids):] = torch.tensor(answer_ids)\n            enc[\"labels\"] = labels\n        \n        return enc\n\nprint(\"âœ… Dataset & DataCollator ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤– 7. Model & Processor ë¡œë“œ\n\nâœ… T4 í˜¸í™˜: Float16, SDPA attention, 4-bit QLoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model_and_processor(model_id, use_advanced=False):\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.float16,\n    )\n    \n    processor = AutoProcessor.from_pretrained(\n        model_id,\n        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n        trust_remote_code=True,\n    )\n    \n    if use_advanced:\n        base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n            model_id,\n            quantization_config=bnb_config,\n            trust_remote_code=True,\n            torch_dtype=torch.float16,\n            attn_implementation=\"sdpa\",\n        )\n    else:\n        base_model = AutoModelForVision2Seq.from_pretrained(\n            model_id,\n            quantization_config=bnb_config,\n            trust_remote_code=True,\n        )\n    \n    base_model = prepare_model_for_kbit_training(base_model)\n    base_model.gradient_checkpointing_enable()\n    \n    lora_config = LoraConfig(\n        r=cfg.LORA_R,\n        lora_alpha=cfg.LORA_ALPHA,\n        lora_dropout=cfg.LORA_DROPOUT,\n        bias=\"none\",\n        target_modules=cfg.TARGET_MODULES,\n        task_type=\"CAUSAL_LM\",\n    )\n    \n    model = get_peft_model(base_model, lora_config)\n    model.print_trainable_parameters()\n    \n    # ë‹¨ì¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™ (device_map ëŒ€ì‹ )\n    model = model.to(device)\n    \n    return model, processor\n\nprint(\"ğŸ”§ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\nmodel, processor = create_model_and_processor(cfg.MODEL_ID, cfg.USE_ADVANCED_MODEL)\nprint(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ 8. Training Loop\n\nâœ… **Val Accuracy ë¡œê¹…** + Confusion Matrix + í•™ìŠµ ê³¡ì„ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EMA:\n    def __init__(self, model, decay=0.999):\n        self.model = model\n        self.decay = decay\n        self.shadow = {}\n        self.backup = {}\n        self.register()\n    \n    def register(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                self.shadow[name] = param.data.clone()\n    \n    def update(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                new_average = self.decay * self.shadow[name] + (1.0 - self.decay) * param.data\n                self.shadow[name] = new_average.clone()\n    \n    def apply_shadow(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                self.backup[name] = param.data.clone()\n                param.data = self.shadow[name]\n    \n    def restore(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                param.data = self.backup[name]\n        self.backup = {}\n\n\ndef validate_with_accuracy(model, valid_loader, processor):\n    \"\"\"âœ… Val Loss + Accuracy + Confusion Matrix\"\"\"\n    model.eval()\n    total_loss = 0.0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(valid_loader, desc=\"Validating\", leave=False):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n                outputs = model(**batch)\n                total_loss += outputs.loss.item()\n            \n            # âœ… Accuracy ê³„ì‚° (ì •ë‹µ í† í° ì˜ˆì¸¡)\n            logits = outputs.logits\n            labels = batch[\"labels\"]\n            \n            for i in range(len(labels)):\n                # ë§ˆì§€ë§‰ ë¹„-íŒ¨ë”© í† í° ìœ„ì¹˜ ì°¾ê¸°\n                valid_mask = labels[i] != -100\n                if valid_mask.any():\n                    last_valid_idx = valid_mask.nonzero(as_tuple=True)[0][-1]\n                    pred_id = logits[i, last_valid_idx].argmax().item()\n                    label_id = labels[i, last_valid_idx].item()\n                    \n                    # í† í° â†’ ë¬¸ì ë³€í™˜\n                    pred_char = processor.tokenizer.decode([pred_id]).strip().lower()\n                    label_char = processor.tokenizer.decode([label_id]).strip().lower()\n                    \n                    # a/b/c/dë§Œ ìˆ˜ì§‘\n                    if pred_char in ['a', 'b', 'c', 'd']:\n                        all_preds.append(pred_char)\n                    else:\n                        all_preds.append('a')  # Fallback\n                    \n                    if label_char in ['a', 'b', 'c', 'd']:\n                        all_labels.append(label_char)\n                    else:\n                        all_labels.append('a')\n    \n    avg_loss = total_loss / len(valid_loader)\n    accuracy = accuracy_score(all_labels, all_preds)\n    cm = confusion_matrix(all_labels, all_preds, labels=['a', 'b', 'c', 'd'])\n    \n    model.train()\n    return avg_loss, accuracy, cm, all_preds, all_labels\n\n\ndef train_one_fold(model, train_loader, valid_loader, fold=0):\n    \"\"\"ë‹¨ì¼ Fold í•™ìŠµ (Val Acc ìš°ì„  ì €ì¥)\"\"\"\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Training Fold {fold}\")\n    print(f\"{'='*60}\")\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=cfg.LEARNING_RATE,\n        weight_decay=cfg.WEIGHT_DECAY\n    )\n    \n    num_training_steps = cfg.NUM_EPOCHS * math.ceil(len(train_loader) / cfg.GRAD_ACCUM_STEPS)\n    num_warmup_steps = int(num_training_steps * cfg.WARMUP_RATIO)\n    \n    if cfg.USE_COSINE_SCHEDULE:\n        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n    else:\n        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n    \n    scaler = torch.amp.GradScaler('cuda', enabled=cfg.USE_AMP)\n    ema = EMA(model, decay=cfg.EMA_DECAY) if cfg.USE_EMA else None\n    \n    swa_model = None\n    if cfg.USE_SWA:\n        swa_model = AveragedModel(model)\n        swa_scheduler = SWALR(optimizer, swa_lr=cfg.LEARNING_RATE * 0.1)\n    \n    best_val_acc = 0.0\n    best_val_loss = float('inf')\n    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n    \n    for epoch in range(cfg.NUM_EPOCHS):\n        model.train()\n        running_loss = 0.0\n        \n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{cfg.NUM_EPOCHS} [train]\")\n        \n        for step, batch in enumerate(progress_bar, start=1):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n                outputs = model(**batch)\n                loss = outputs.loss / cfg.GRAD_ACCUM_STEPS\n            \n            scaler.scale(loss).backward()\n            running_loss += loss.item()\n            \n            if step % cfg.GRAD_ACCUM_STEPS == 0:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.MAX_GRAD_NORM)\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad(set_to_none=True)\n                \n                if cfg.USE_SWA and epoch >= cfg.SWA_START_EPOCH:\n                    swa_scheduler.step()\n                else:\n                    scheduler.step()\n                \n                if cfg.USE_EMA and ema is not None:\n                    ema.update()\n                \n                avg_loss = running_loss / cfg.GRAD_ACCUM_STEPS\n                progress_bar.set_postfix({\"loss\": f\"{avg_loss:.4f}\", \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"})\n                running_loss = 0.0\n        \n        # SWA update\n        if cfg.USE_SWA and swa_model is not None and epoch >= cfg.SWA_START_EPOCH:\n            swa_model.update_parameters(model)\n        \n        # âœ… Validation with Accuracy\n        if cfg.USE_EMA and ema is not None:\n            ema.apply_shadow()\n        \n        val_loss, val_acc, cm, preds, labels = validate_with_accuracy(model, valid_loader, processor)\n        \n        if cfg.USE_EMA and ema is not None:\n            ema.restore()\n        \n        history[\"val_loss\"].append(val_loss)\n        history[\"val_acc\"].append(val_acc)\n        \n        print(f\"[Epoch {epoch+1}] Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n        print(f\"Confusion Matrix:\\n{cm}\")\n        \n        # âœ… Best ëª¨ë¸ ì €ì¥ (Acc ìš°ì„ , ë™ë¥  ì‹œ Loss)\n        is_best = False\n        if val_acc > best_val_acc:\n            is_best = True\n            best_val_acc = val_acc\n            best_val_loss = val_loss\n        elif val_acc == best_val_acc and val_loss < best_val_loss:\n            is_best = True\n            best_val_loss = val_loss\n        \n        if is_best:\n            save_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n            os.makedirs(save_path, exist_ok=True)\n            \n            if cfg.USE_EMA and ema is not None:\n                ema.apply_shadow()\n            \n            model.save_pretrained(save_path)\n            processor.save_pretrained(save_path)\n            \n            if cfg.USE_EMA and ema is not None:\n                ema.restore()\n            \n            print(f\"   âœ… Best model saved (Acc={val_acc:.4f}, Loss={val_loss:.4f})\")\n    \n    # SWA ìµœì¢… ëª¨ë¸\n    if cfg.USE_SWA and swa_model is not None:\n        torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n        save_path = f\"{cfg.SAVE_DIR}/fold{fold}_swa\"\n        os.makedirs(save_path, exist_ok=True)\n        swa_model.module.save_pretrained(save_path)\n        processor.save_pretrained(save_path)\n        print(f\"   âœ… SWA model saved\")\n    \n    # âœ… í•™ìŠµ ê³¡ì„  ì €ì¥\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    ax1.plot(history[\"val_loss\"], marker='o')\n    ax1.set_title(f'Fold {fold} - Val Loss')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Loss')\n    ax1.grid(True)\n    \n    ax2.plot(history[\"val_acc\"], marker='o', color='green')\n    ax2.set_title(f'Fold {fold} - Val Accuracy')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Accuracy')\n    ax2.grid(True)\n    plt.tight_layout()\n    \n    log_dir = Path(cfg.LOG_DIR)\n    log_dir.mkdir(parents=True, exist_ok=True)\n    plt.savefig(log_dir / f\"fold{fold}_learning_curve.png\")\n    plt.show()\n    \n    return best_val_acc, best_val_loss\n\nprint(\"âœ… Training functions ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ 9. í•™ìŠµ ì‹¤í–‰ (K-Fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# âœ… ê²€ì¦ ë°ì´í„°ì— train=False ì ìš© (ì •ë‹µ ì£¼ì… ë°©ì§€)\n\nif cfg.USE_KFOLD:\n    results = {}\n    \n    for fold in cfg.TRAIN_FOLDS:\n        print(f\"\\n{'#'*60}\")\n        print(f\"Starting Fold {fold}/{cfg.N_FOLDS-1}\")\n        print(f\"{'#'*60}\")\n        \n        train_subset = train_df[train_df['fold'] != fold].reset_index(drop=True)\n        valid_subset = train_df[train_df['fold'] == fold].reset_index(drop=True)\n        \n        print(f\"Train: {len(train_subset)}, Valid: {len(valid_subset)}\")\n        \n        train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n        valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)  # âœ… train=False\n        \n        train_loader = DataLoader(\n            train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True,\n            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n            num_workers=0\n        )\n        valid_loader = DataLoader(\n            valid_ds, batch_size=cfg.BATCH_SIZE, shuffle=False,\n            collate_fn=DataCollator(processor, train=False, use_advanced=cfg.USE_ADVANCED_MODEL),  # âœ… train=False\n            num_workers=0\n        )\n        \n        best_acc, best_loss = train_one_fold(model, train_loader, valid_loader, fold=fold)\n        results[fold] = {\"acc\": best_acc, \"loss\": best_loss}\n        \n        print(f\"\\nâœ… Fold {fold} ì™„ë£Œ: Best Val Acc={best_acc:.4f}, Loss={best_loss:.4f}\")\n    \n    print(f\"\\n{'='*60}\")\n    print(\"All Folds Training Complete!\")\n    print(f\"{'='*60}\")\n    for fold, metrics in results.items():\n        print(f\"Fold {fold}: Acc={metrics['acc']:.4f}, Loss={metrics['loss']:.4f}\")\n    print(f\"Average Acc: {np.mean([m['acc'] for m in results.values()]):.4f}\")\n\nelse:\n    # ë‹¨ì¼ ëª¨ë¸\n    train_subset = train_df[train_df['fold'] == -1].reset_index(drop=True)\n    valid_subset = train_df[train_df['fold'] == 0].reset_index(drop=True)\n    \n    train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n    valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)  # âœ… train=False\n    \n    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True,\n                             collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL), num_workers=0)\n    valid_loader = DataLoader(valid_ds, batch_size=cfg.BATCH_SIZE, shuffle=False,\n                             collate_fn=DataCollator(processor, train=False, use_advanced=cfg.USE_ADVANCED_MODEL), num_workers=0)\n    \n    best_acc, best_loss = train_one_fold(model, train_loader, valid_loader, fold=0)\n    print(f\"\\nâœ… Single model í•™ìŠµ ì™„ë£Œ: Best Val Acc={best_acc:.4f}, Loss={best_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”® 10. Inference with Direct Logits + TTA\n\nâœ… **Direct Logits**: a/b/c/d í† í° í™•ë¥  ì§ì ‘ ê³„ì‚° (ìƒì„± ëŒ€ë¹„ ì•ˆì •)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_choice_token_ids(processor):\n    \"\"\"a/b/c/d í† í° ID ì¶”ì¶œ\"\"\"\n    choice_tokens = {}\n    for choice in ['a', 'b', 'c', 'd']:\n        token_ids = processor.tokenizer.encode(choice, add_special_tokens=False)\n        choice_tokens[choice] = token_ids\n    return choice_tokens\n\n\ndef infer_with_direct_logits(model, processor, test_df, tta_scales=[1.0], fold=0):\n    \"\"\"âœ… Direct Logits ì¶”ë¡  + TTA\"\"\"\n    model.eval()\n    \n    # pad_token_id ì„¤ì •\n    if processor.tokenizer.pad_token_id is None:\n        processor.tokenizer.pad_token_id = processor.tokenizer.eos_token_id\n    \n    choice_tokens = get_choice_token_ids(processor)\n    \n    all_predictions = []\n    all_probs = []\n    \n    for i in tqdm(range(len(test_df)), desc=f\"Fold {fold} Inference\"):\n        row = test_df.iloc[i]\n        \n        # TTA: ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ë¡œ ì¶”ë¡ \n        tta_logits = []\n        \n        for scale in tta_scales:\n            # ì´ë¯¸ì§€ ë¡œë“œ\n            img_col = 'path' if 'path' in row else 'image'\n            img_path = os.path.join(cfg.DATA_DIR, row[img_col])\n            try:\n                img = Image.open(img_path).convert(\"RGB\")\n            except:\n                img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n            \n            # TTA ìŠ¤ì¼€ì¼ ì ìš©\n            if scale != 1.0:\n                w, h = img.size\n                new_w, new_h = int(w * scale), int(h * scale)\n                img = img.resize((new_w, new_h), Image.BILINEAR)\n            \n            # í”„ë¡¬í”„íŠ¸\n            user_text = build_mc_prompt(\n                str(row[\"question\"]), str(row[\"a\"]),\n                str(row[\"b\"]), str(row[\"c\"]), str(row[\"d\"])\n            )\n            \n            messages = [\n                {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n                {\"role\": \"user\", \"content\": [\n                    {\"type\": \"image\", \"image\": img},\n                    {\"type\": \"text\", \"text\": user_text}\n                ]}\n            ]\n            \n            # âœ… add_generation_prompt=True (ì¶”ë¡  ì‹œ)\n            text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n            \n            inputs = processor(text=[text], images=[img], return_tensors=\"pt\")\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n            \n            # âœ… Direct Logits: ë‹¤ìŒ í† í° ë¶„í¬ì—ì„œ a/b/c/d í™•ë¥  ê³„ì‚°\n            with torch.no_grad():\n                outputs = model(**inputs)\n                logits = outputs.logits[0, -1, :]  # ë§ˆì§€ë§‰ í† í°ì˜ logits\n            \n            tta_logits.append(logits.cpu())\n        \n        # TTA í‰ê· \n        avg_logits = torch.stack(tta_logits).mean(dim=0)\n        \n        # âœ… a/b/c/d í† í° í™•ë¥  ì§‘ê³„\n        choice_probs = {}\n        for choice, token_ids in choice_tokens.items():\n            # í•´ë‹¹ choiceì˜ ëª¨ë“  í† í° logit í•©ì‚°\n            total_logit = sum([avg_logits[tid].item() for tid in token_ids])\n            choice_probs[choice] = total_logit\n        \n        # Softmaxë¡œ í™•ë¥  ë³€í™˜\n        logit_values = torch.tensor(list(choice_probs.values()))\n        probs = F.softmax(logit_values, dim=0).numpy()\n        prob_dict = {choice: probs[idx] for idx, choice in enumerate(['a', 'b', 'c', 'd'])}\n        \n        # ì˜ˆì¸¡\n        pred = max(prob_dict, key=prob_dict.get)\n        \n        all_predictions.append(pred)\n        all_probs.append(prob_dict)\n    \n    # DataFrame ìƒì„±\n    result_df = pd.DataFrame({\n        'id': test_df['id'],\n        'answer': all_predictions,\n        'prob_a': [p['a'] for p in all_probs],\n        'prob_b': [p['b'] for p in all_probs],\n        'prob_c': [p['c'] for p in all_probs],\n        'prob_d': [p['d'] for p in all_probs]\n    })\n    \n    return result_df\n\n\n# ê° Fold ì¶”ë¡ \npredictions_all = []\n\nif cfg.USE_KFOLD:\n    for fold in cfg.TRAIN_FOLDS:\n        model_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"Inferencing Fold {fold}\")\n        print(f\"{'='*60}\")\n        \n        # ëª¨ë¸ ë¡œë“œ\n        if cfg.USE_ADVANCED_MODEL:\n            model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n                model_path, trust_remote_code=True, torch_dtype=torch.float16\n            )\n        else:\n            model_infer = AutoModelForVision2Seq.from_pretrained(\n                model_path, trust_remote_code=True, torch_dtype=torch.float16\n            )\n        \n        model_infer = model_infer.to(device)\n        model_infer.eval()\n        \n        processor_infer = AutoProcessor.from_pretrained(\n            model_path,\n            min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n            max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n            trust_remote_code=True,\n        )\n        \n        # Direct Logits + TTA\n        tta_scales = cfg.TTA_SCALES if cfg.USE_TTA else [1.0]\n        pred_df = infer_with_direct_logits(model_infer, processor_infer, test_df, tta_scales, fold)\n        \n        # ì €ì¥\n        output_path = f\"{cfg.OUTPUT_DIR}/submission_fold{fold}.csv\"\n        os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n        pred_df.to_csv(output_path, index=False)\n        print(f\"âœ… Saved to {output_path}\")\n        \n        predictions_all.append(pred_df)\n        \n        # ë©”ëª¨ë¦¬ ì •ë¦¬\n        del model_infer\n        torch.cuda.empty_cache()\n\nelse:\n    model_path = f\"{cfg.SAVE_DIR}/fold0_best\"\n    \n    if cfg.USE_ADVANCED_MODEL:\n        model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n            model_path, trust_remote_code=True, torch_dtype=torch.float16\n        ).to(device)\n    else:\n        model_infer = AutoModelForVision2Seq.from_pretrained(\n            model_path, trust_remote_code=True, torch_dtype=torch.float16\n        ).to(device)\n    \n    processor_infer = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n    \n    tta_scales = cfg.TTA_SCALES if cfg.USE_TTA else [1.0]\n    pred_df = infer_with_direct_logits(model_infer, processor_infer, test_df, tta_scales, fold=0)\n    \n    output_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n    pred_df.to_csv(output_path, index=False)\n    predictions_all.append(pred_df)\n\nprint(\"\\nâœ… All inference complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸŒ¡ï¸ 11. Temperature Scaling\n\nâœ… ê²€ì¦ ì„¸íŠ¸ë¡œ í™•ë¥  êµì • (ì„ íƒ ì‚¬í•­)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# âœ… Temperature Scaling (ì„ íƒ ì‚¬í•­)\n# ê²€ì¦ ì„¸íŠ¸ê°€ ìˆì„ ë•Œ ê° foldì˜ ìµœì  temperatureë¥¼ ì°¾ì•„ test í™•ë¥ ì— ì ìš©\n\ndef find_optimal_temperature(val_probs, val_labels):\n    \"\"\"ê²€ì¦ ì„¸íŠ¸ì—ì„œ ìµœì  temperature íƒìƒ‰\"\"\"\n    from scipy.optimize import minimize\n    \n    def nll_loss(temp):\n        scaled_probs = F.softmax(torch.tensor(val_probs) / temp, dim=1).numpy()\n        # Negative log-likelihood\n        nll = -np.log(scaled_probs[np.arange(len(val_labels)), val_labels] + 1e-10).mean()\n        return nll\n    \n    result = minimize(nll_loss, x0=[1.0], bounds=[(0.1, 10.0)])\n    return result.x[0]\n\n# ì‹¤ì œë¡œ ì‚¬ìš©í•˜ë ¤ë©´:\n# 1. ê²€ì¦ ì„¸íŠ¸ë¡œ í™•ë¥ ê³¼ ì •ë‹µ ìˆ˜ì§‘\n# 2. optimal_temp = find_optimal_temperature(val_probs, val_labels)\n# 3. test í™•ë¥ ì— ì ìš©: scaled_probs = F.softmax(torch.tensor(test_probs) / optimal_temp, dim=1)\n\n# í˜„ì¬ëŠ” temperature=1.0ìœ¼ë¡œ ìœ ì§€ (ê¸°ë³¸)\nprint(\"âœ… Temperature scalingì€ ì„ íƒ ì‚¬í•­ì…ë‹ˆë‹¤.\")\nprint(\"ê²€ì¦ ì„¸íŠ¸ê°€ ìˆì„ ë•Œ ìœ„ ì½”ë“œë¥¼ í™œìš©í•˜ì—¬ ìµœì  temperatureë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ 12. Ensemble (í™•ë¥  í‰ê· )\n\nâœ… **Probability Averaging** (í´ë°±: Majority Voting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD and len(predictions_all) > 1:\n    print(f\"\\n{'='*60}\")\n    print(f\"Ensemble Method: {cfg.ENSEMBLE_METHOD}\")\n    print(f\"{'='*60}\")\n    \n    if cfg.ENSEMBLE_METHOD == 'prob':\n        # âœ… í™•ë¥  ì•™ìƒë¸”\n        print(\"Using Probability Averaging...\")\n        \n        ensemble_probs = pd.DataFrame({\n            'id': test_df['id'],\n            'prob_a': np.mean([df['prob_a'].values for df in predictions_all], axis=0),\n            'prob_b': np.mean([df['prob_b'].values for df in predictions_all], axis=0),\n            'prob_c': np.mean([df['prob_c'].values for df in predictions_all], axis=0),\n            'prob_d': np.mean([df['prob_d'].values for df in predictions_all], axis=0)\n        })\n        \n        # argmax\n        prob_cols = ['prob_a', 'prob_b', 'prob_c', 'prob_d']\n        ensemble_probs['answer'] = ensemble_probs[prob_cols].values.argmax(axis=1)\n        ensemble_probs['answer'] = ensemble_probs['answer'].map({0: 'a', 1: 'b', 2: 'c', 3: 'd'})\n        \n        final_submission = ensemble_probs[['id', 'answer', 'prob_a', 'prob_b', 'prob_c', 'prob_d']]\n    \n    else:\n        # Majority Voting (í´ë°±)\n        print(\"Using Majority Voting...\")\n        \n        ensemble_preds = []\n        for i in range(len(test_df)):\n            votes = [pred.iloc[i]['answer'] for pred in predictions_all]\n            most_common = Counter(votes).most_common(1)[0][0]\n            ensemble_preds.append(most_common)\n        \n        final_submission = pd.DataFrame({\n            'id': test_df['id'],\n            'answer': ensemble_preds\n        })\n    \n    final_path = f\"{cfg.OUTPUT_DIR}/submission_ensemble.csv\"\n    final_submission.to_csv(final_path, index=False)\n    \n    print(f\"âœ… Ensemble submission saved to {final_path}\")\n    print(f\"\\nAnswer Distribution:\")\n    print(final_submission['answer'].value_counts().sort_index())\n\nelse:\n    print(\"\\nâœ… Single model - No ensemble needed\")\n    final_submission = predictions_all[0]\n    final_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n    final_submission.to_csv(final_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š 13. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 5))\n\nanswer_counts = final_submission['answer'].value_counts().sort_index()\nsns.barplot(x=answer_counts.index, y=answer_counts.values, palette='viridis', ax=ax)\nax.set_title('Final Submission Answer Distribution', fontsize=14, weight='bold')\nax.set_xlabel('Answer')\nax.set_ylabel('Count')\nax.grid(axis='y', alpha=0.3)\n\nfor i, (ans, count) in enumerate(answer_counts.items()):\n    percentage = count / len(final_submission) * 100\n    ax.text(i, count + 10, f\"{percentage:.1f}%\", ha='center', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n{'='*60}\")\nprint(\"Final Statistics\")\nprint(f\"{'='*60}\")\nprint(f\"Total predictions: {len(final_submission)}\")\nprint(f\"\\nAnswer counts:\")\nfor ans, count in answer_counts.items():\n    print(f\"  {ans}: {count:5d} ({count/len(final_submission)*100:5.1f}%)\")\n\n# í™•ë¥  ë¶„í¬ (ìˆëŠ” ê²½ìš°)\nif 'prob_a' in final_submission.columns:\n    print(f\"\\n{'='*60}\")\n    print(\"Probability Statistics\")\n    print(f\"{'='*60}\")\n    prob_cols = ['prob_a', 'prob_b', 'prob_c', 'prob_d']\n    print(final_submission[prob_cols].describe())\n\nprint(f\"\\n{'='*60}\")\nprint(\"Sample Predictions\")\nprint(f\"{'='*60}\")\nprint(final_submission.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… 14. ìµœì¢… ì •ë¦¬\n\n### ğŸ‰ ì™„ë£Œëœ ì‘ì—…\n\n1. âœ… Config ì„¤ì • (Pro2 íŠœë‹)\n2. âœ… ë°ì´í„° ë¡œë“œ & EDA\n3. âœ… Stratified K-Fold CV\n4. âœ… Dataset & DataCollator (ë¼ë²¨ ë§ˆìŠ¤í‚¹)\n5. âœ… Model & Processor (T4 í˜¸í™˜)\n6. âœ… Training Loop (Val Acc + Confusion Matrix)\n7. âœ… Inference (Direct Logits + TTA)\n8. âœ… Temperature Scaling (ì„ íƒ ì‚¬í•­)\n9. âœ… Ensemble (í™•ë¥  í‰ê· )\n10. âœ… ê²°ê³¼ ë¶„ì„ & ì‹œê°í™”\n\n### ğŸš€ ì£¼ìš” ê°œì„ ì‚¬í•­\n\n#### í•™ìŠµ\n- Val Accuracy ë¡œê¹… ë° Best ëª¨ë¸ ì €ì¥ (Acc ìš°ì„ )\n- Confusion Matrix ì¶œë ¥\n- í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n- ê²€ì¦ ë°ì´í„° train=False (ì •ë‹µ ì£¼ì… ë°©ì§€)\n\n#### ì¶”ë¡ \n- Direct Logits: a/b/c/d í† í° í™•ë¥  ì§ì ‘ ê³„ì‚°\n- TTA: [0.9, 1.0, 1.1] ìŠ¤ì¼€ì¼ í‰ê· \n- pad_token_id ìë™ ë³´ì •\n- í™•ë¥  ì»¬ëŸ¼ ì €ì¥\n\n#### ì•™ìƒë¸”\n- í™•ë¥  ì•™ìƒë¸” (Probability Averaging)\n- í´ë°±: Majority Voting\n\n### ğŸ“Š Pro2 ì„¤ì •\n\n```python\nUSE_SAMPLE = False          # ì „ì²´ ë°ì´í„°\nIMAGE_SIZE = 512\nNUM_EPOCHS = 3\nGRAD_ACCUM_STEPS = 8\nWARMUP_RATIO = 0.06\nLORA_R = 16\nUSE_DIRECT_LOGIT_DECODE = True\nTTA_SCALES = [0.9, 1.0, 1.1]\nENSEMBLE_METHOD = 'prob'\n```\n\n### ğŸ“Œ Important Notes\n\n- **ë””ë°”ì´ìŠ¤ ì •ë ¬**: ëª¨ë“  ëª¨ë¸/ì…ë ¥ì„ ë‹¨ì¼ deviceë¡œ í†µì¼\n- **ë¼ë²¨ ë§ˆìŠ¤í‚¹**: í”„ë¡¬í”„íŠ¸ í† í° ì†ì‹¤ ì œì™¸, assistant ì •ë‹µë§Œ ê°ë…\n- **ê²€ì¦ í”Œë˜ê·¸**: valid_dsì— train=False ì ìš©\n- **Direct Logits**: ìƒì„± ëŒ€ë¹„ ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ì¶”ë¡ \n- **í™•ë¥  ì•™ìƒë¸”**: Fold ê°„ í™•ë¥  í‰ê· ìœ¼ë¡œ robustí•œ ì˜ˆì¸¡\n\n---\n\n**ğŸ¤– SSAFY AI Project 2025 - Pro2 Version**\n\n**â­ í–‰ìš´ì„ ë¹•ë‹ˆë‹¤!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}