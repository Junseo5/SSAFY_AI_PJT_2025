{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 📒 Kaggle_AllInOne_Pro2.ipynb – 고급 최적화 버전\n\n## 🎯 Pro2 주요 개선사항\n\n### ✅ 학습 개선\n- Val Accuracy + Confusion Matrix 로깅\n- Best 모델: Val Acc 우선 저장\n- 학습 곡선 시각화\n- 라벨 마스킹 (프롬프트 손실 제외)\n- 검증 데이터 train=False\n\n### ✅ 추론 개선\n- Direct Logits (a/b/c/d 토큰 확률)\n- TTA [0.9, 1.0, 1.1]\n- 배치 추론\n- pad_token_id 자동 보정\n\n### ✅ 앙상블 개선\n- Temperature Scaling\n- 확률 앙상블\n- 확률 컬럼 저장\n\n### ⚙️ 튜닝 설정\n```\nUSE_SAMPLE=False, IMAGE_SIZE=512, NUM_EPOCHS=3\nGRAD_ACCUM_STEPS=8, WARMUP_RATIO=0.06, LORA_R=16\nUSE_DIRECT_LOGIT_DECODE=True, TTA_SCALES=[0.9,1.0,1.1]\nENSEMBLE_METHOD='prob'\n```\n\n**🤖 SSAFY AI Project 2025**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📦 1. 패키지 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -q transformers accelerate peft bitsandbytes datasets pillow pandas torch torchvision scikit-learn matplotlib seaborn tqdm --upgrade\n# !pip install -q qwen-vl-utils==0.0.8\nprint(\"✅ 설치 완료! 런타임 재시작하세요.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📚 2. 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys, re, math, random, warnings, json, pickle\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom collections import Counter, defaultdict\nimport unicodedata\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.swa_utils import AveragedModel, SWALR\n\nfrom transformers import (\n    AutoModelForVision2Seq,\n    Qwen2_5_VLForConditionalGeneration,\n    AutoProcessor,\n    BitsAndBytesConfig,\n    get_cosine_schedule_with_warmup,\n    get_linear_schedule_with_warmup\n)\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom qwen_vl_utils import process_vision_info\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nwarnings.filterwarnings('ignore')\nImage.MAX_IMAGE_PIXELS = None\nsns.set_style('whitegrid')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"🔧 Device: {device}\")\nif torch.cuda.is_available():\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ⚙️ 3. Config 설정 (Pro2 튜닝)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n    # 시드\n    SEED = 42\n    \n    # 모델\n    MODEL_ID = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n    IMAGE_SIZE = 512  # ✅ Pro2: 고해상도\n    USE_ADVANCED_MODEL = False  # True면 Qwen2_5_VL (VRAM 확인)\n    \n    # 데이터\n    DATA_DIR = \"/content\"\n    TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n    TEST_CSV = f\"{DATA_DIR}/test.csv\"\n    \n    # K-Fold\n    N_FOLDS = 3\n    USE_KFOLD = True\n    TRAIN_FOLDS = [0, 1, 2]\n    \n    # QLoRA\n    LORA_R = 16  # ✅ Pro2: 더 큰 표현력\n    LORA_ALPHA = 32\n    LORA_DROPOUT = 0.05\n    TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n    \n    # 학습\n    NUM_EPOCHS = 3  # ✅ Pro2\n    BATCH_SIZE = 1\n    GRAD_ACCUM_STEPS = 8  # ✅ Pro2\n    LEARNING_RATE = 1e-4\n    WEIGHT_DECAY = 0.01\n    WARMUP_RATIO = 0.06  # ✅ Pro2\n    MAX_GRAD_NORM = 1.0\n    \n    # 고급 기법\n    USE_AMP = True\n    USE_EMA = True\n    EMA_DECAY = 0.999\n    USE_SWA = True  # ✅ Pro2: Epoch 1 이후 ON\n    SWA_START_EPOCH = 1\n    USE_COSINE_SCHEDULE = True\n    \n    # TTA\n    USE_TTA = True  # ✅ Pro2\n    TTA_SCALES = [0.9, 1.0, 1.1]  # ✅ Pro2\n    \n    # 추론\n    USE_DIRECT_LOGIT_DECODE = True  # ✅ Pro2: Direct logits\n    USE_BATCH_INFERENCE = False  # 메모리 허용 시 True\n    INFER_BATCH_SIZE = 4\n    MAX_NEW_TOKENS = 8\n    \n    # Temperature Scaling\n    USE_TEMPERATURE_SCALING = True  # ✅ Pro2\n    \n    # 앙상블\n    ENSEMBLE_METHOD = \"prob\"  # ✅ Pro2: \"prob\" or \"vote\"\n    \n    # 저장\n    SAVE_DIR = f\"{DATA_DIR}/checkpoints\"\n    OUTPUT_DIR = f\"{DATA_DIR}/outputs\"\n    LOG_DIR = f\"{DATA_DIR}/logs\"\n    \n    # 샘플링\n    USE_SAMPLE = False  # ✅ Pro2: 전체 데이터\n    SAMPLE_SIZE = 200\n    \n    # 프롬프트\n    SYSTEM_INSTRUCT = (\n        \"You are a helpful visual question answering assistant. \"\n        \"Answer using exactly one letter among a, b, c, or d. No explanation.\"\n    )\n\ncfg = Config()\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(cfg.SEED)\nprint(f\"✅ Config 설정 완료\")\nprint(f\"   Model: {cfg.MODEL_ID}\")\nprint(f\"   Image Size: {cfg.IMAGE_SIZE}\")\nprint(f\"   Epochs: {cfg.NUM_EPOCHS}, Grad Accum: {cfg.GRAD_ACCUM_STEPS}\")\nprint(f\"   LoRA R: {cfg.LORA_R}, Warmup: {cfg.WARMUP_RATIO}\")\nprint(f\"   Direct Logits: {cfg.USE_DIRECT_LOGIT_DECODE}, TTA: {cfg.USE_TTA}\")\nprint(f\"   Ensemble: {cfg.ENSEMBLE_METHOD}, Temp Scaling: {cfg.USE_TEMPERATURE_SCALING}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 4. 데이터 로드 & EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(cfg.TRAIN_CSV)\ntest_df = pd.read_csv(cfg.TEST_CSV)\n\nprint(f\"📁 Train: {len(train_df):,} samples\")\nprint(f\"📁 Test: {len(test_df):,} samples\")\n\nif cfg.USE_SAMPLE:\n    train_df = train_df.sample(n=min(cfg.SAMPLE_SIZE, len(train_df)), random_state=cfg.SEED).reset_index(drop=True)\n    print(f\"⚠️  Sampled {len(train_df)} samples\")\n\nprint(f\"\\n📊 Answer Distribution:\")\nprint(train_df['answer'].value_counts().sort_index())\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 4))\ntrain_df['answer'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='skyblue')\naxes[0].set_title('Answer Distribution')\naxes[0].set_xlabel('Answer')\naxes[0].set_ylabel('Count')\n\ntrain_df['question_len'] = train_df['question'].str.len()\ntrain_df['question_len'].hist(bins=30, ax=axes[1], color='salmon')\naxes[1].set_title('Question Length')\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔄 5. Stratified K-Fold CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD:\n    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=cfg.SEED)\n    train_df['fold'] = -1\n    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['answer'])):\n        train_df.loc[val_idx, 'fold'] = fold\n    print(f\"✅ {cfg.N_FOLDS}-Fold CV 생성\")\n    print(train_df['fold'].value_counts().sort_index())\nelse:\n    split_idx = int(len(train_df) * 0.9)\n    train_df['fold'] = -1\n    train_df.loc[split_idx:, 'fold'] = 0\n    print(f\"✅ Single split (90:10)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🗂️ 6. Dataset & DataCollator\n\n✅ **라벨 마스킹**: 프롬프트 토큰 손실 제외, assistant 정답 토큰만 감독"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_mc_prompt(question, a, b, c, d):\n    return (\n        f\"{question}\\n\"\n        f\"(a) {a}\\n(b) {b}\\n(c) {c}\\n(d) {d}\\n\\n\"\n        \"정답을 반드시 a, b, c, d 중 하나의 소문자 한 글자로만 출력하세요.\"\n    )\n\nclass VQADataset(Dataset):\n    def __init__(self, df, processor, data_dir=\"\", train=True, use_advanced=False):\n        self.df = df.reset_index(drop=True)\n        self.processor = processor\n        self.data_dir = data_dir\n        self.train = train\n        self.use_advanced = use_advanced\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # 이미지 로드 (path 컬럼 지원)\n        img_col = 'path' if 'path' in row else 'image'\n        img_path = os.path.join(self.data_dir, row[img_col])\n        try:\n            img = Image.open(img_path).convert(\"RGB\")\n        except:\n            img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n        \n        user_text = build_mc_prompt(\n            str(row[\"question\"]), str(row[\"a\"]), \n            str(row[\"b\"]), str(row[\"c\"]), str(row[\"d\"])\n        )\n        \n        messages = [\n            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"image\", \"image\": img},\n                {\"type\": \"text\", \"text\": user_text}\n            ]}\n        ]\n        \n        # ✅ 학습 시에만 정답 포함\n        answer = None\n        if self.train:\n            answer = str(row[\"answer\"]).strip().lower()\n            messages.append({\n                \"role\": \"assistant\",\n                \"content\": [{\"type\": \"text\", \"text\": answer}]\n            })\n        \n        return {\"messages\": messages, \"image\": img, \"answer\": answer}\n\n@dataclass\nclass DataCollator:\n    processor: Any\n    train: bool = True\n    use_advanced: bool = False\n    \n    def __call__(self, batch):\n        texts, images, answers = [], [], []\n        \n        for sample in batch:\n            text = self.processor.apply_chat_template(\n                sample[\"messages\"],\n                tokenize=False,\n                add_generation_prompt=False  # ✅ False!\n            )\n            text = unicodedata.normalize('NFKC', text)\n            texts.append(text)\n            images.append(sample[\"image\"])\n            answers.append(sample[\"answer\"])\n        \n        enc = self.processor(\n            text=texts,\n            images=images,\n            padding=True,\n            return_tensors=\"pt\"\n        )\n        \n        # ✅ 라벨 마스킹: 정답 토큰만 감독\n        if self.train:\n            labels = enc[\"input_ids\"].clone()\n            for i, answer in enumerate(answers):\n                if answer is None:\n                    labels[i, :] = -100\n                else:\n                    # 프롬프트 부분 -100\n                    labels[i, :] = -100\n                    # 정답 토큰만 유지\n                    answer_ids = self.processor.tokenizer.encode(answer, add_special_tokens=False)\n                    if len(answer_ids) > 0:\n                        labels[i, -len(answer_ids):] = torch.tensor(answer_ids)\n            enc[\"labels\"] = labels\n        \n        return enc\n\nprint(\"✅ Dataset & DataCollator 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤖 7. Model & Processor 로드\n\n✅ T4 호환: Float16, SDPA attention, 4-bit QLoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model_and_processor(model_id, use_advanced=False):\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.float16,\n    )\n    \n    processor = AutoProcessor.from_pretrained(\n        model_id,\n        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n        trust_remote_code=True,\n    )\n    \n    if use_advanced:\n        base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n            model_id,\n            quantization_config=bnb_config,\n            trust_remote_code=True,\n            torch_dtype=torch.float16,\n            attn_implementation=\"sdpa\",\n        )\n    else:\n        base_model = AutoModelForVision2Seq.from_pretrained(\n            model_id,\n            quantization_config=bnb_config,\n            trust_remote_code=True,\n        )\n    \n    base_model = prepare_model_for_kbit_training(base_model)\n    base_model.gradient_checkpointing_enable()\n    \n    lora_config = LoraConfig(\n        r=cfg.LORA_R,\n        lora_alpha=cfg.LORA_ALPHA,\n        lora_dropout=cfg.LORA_DROPOUT,\n        bias=\"none\",\n        target_modules=cfg.TARGET_MODULES,\n        task_type=\"CAUSAL_LM\",\n    )\n    \n    model = get_peft_model(base_model, lora_config)\n    model.print_trainable_parameters()\n    \n    # 단일 디바이스로 이동 (device_map 대신)\n    model = model.to(device)\n    \n    return model, processor\n\nprint(\"🔧 모델 로드 중...\")\nmodel, processor = create_model_and_processor(cfg.MODEL_ID, cfg.USE_ADVANCED_MODEL)\nprint(f\"✅ 모델 로드 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎓 8. Training Loop\n\n✅ **Val Accuracy 로깅** + Confusion Matrix + 학습 곡선"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EMA:\n    def __init__(self, model, decay=0.999):\n        self.model = model\n        self.decay = decay\n        self.shadow = {}\n        self.backup = {}\n        self.register()\n    \n    def register(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                self.shadow[name] = param.data.clone()\n    \n    def update(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                new_average = self.decay * self.shadow[name] + (1.0 - self.decay) * param.data\n                self.shadow[name] = new_average.clone()\n    \n    def apply_shadow(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                self.backup[name] = param.data.clone()\n                param.data = self.shadow[name]\n    \n    def restore(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                param.data = self.backup[name]\n        self.backup = {}\n\n\ndef validate_with_accuracy(model, valid_loader, processor):\n    \"\"\"✅ Val Loss + Accuracy + Confusion Matrix\"\"\"\n    model.eval()\n    total_loss = 0.0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(valid_loader, desc=\"Validating\", leave=False):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n                outputs = model(**batch)\n                total_loss += outputs.loss.item()\n            \n            # ✅ Accuracy 계산 (정답 토큰 예측)\n            logits = outputs.logits\n            labels = batch[\"labels\"]\n            \n            for i in range(len(labels)):\n                # 마지막 비-패딩 토큰 위치 찾기\n                valid_mask = labels[i] != -100\n                if valid_mask.any():\n                    last_valid_idx = valid_mask.nonzero(as_tuple=True)[0][-1]\n                    pred_id = logits[i, last_valid_idx].argmax().item()\n                    label_id = labels[i, last_valid_idx].item()\n                    \n                    # 토큰 → 문자 변환\n                    pred_char = processor.tokenizer.decode([pred_id]).strip().lower()\n                    label_char = processor.tokenizer.decode([label_id]).strip().lower()\n                    \n                    # a/b/c/d만 수집\n                    if pred_char in ['a', 'b', 'c', 'd']:\n                        all_preds.append(pred_char)\n                    else:\n                        all_preds.append('a')  # Fallback\n                    \n                    if label_char in ['a', 'b', 'c', 'd']:\n                        all_labels.append(label_char)\n                    else:\n                        all_labels.append('a')\n    \n    avg_loss = total_loss / len(valid_loader)\n    accuracy = accuracy_score(all_labels, all_preds)\n    cm = confusion_matrix(all_labels, all_preds, labels=['a', 'b', 'c', 'd'])\n    \n    model.train()\n    return avg_loss, accuracy, cm, all_preds, all_labels\n\n\ndef train_one_fold(model, train_loader, valid_loader, fold=0):\n    \"\"\"단일 Fold 학습 (Val Acc 우선 저장)\"\"\"\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Training Fold {fold}\")\n    print(f\"{'='*60}\")\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=cfg.LEARNING_RATE,\n        weight_decay=cfg.WEIGHT_DECAY\n    )\n    \n    num_training_steps = cfg.NUM_EPOCHS * math.ceil(len(train_loader) / cfg.GRAD_ACCUM_STEPS)\n    num_warmup_steps = int(num_training_steps * cfg.WARMUP_RATIO)\n    \n    if cfg.USE_COSINE_SCHEDULE:\n        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n    else:\n        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n    \n    scaler = torch.amp.GradScaler('cuda', enabled=cfg.USE_AMP)\n    ema = EMA(model, decay=cfg.EMA_DECAY) if cfg.USE_EMA else None\n    \n    swa_model = None\n    if cfg.USE_SWA:\n        swa_model = AveragedModel(model)\n        swa_scheduler = SWALR(optimizer, swa_lr=cfg.LEARNING_RATE * 0.1)\n    \n    best_val_acc = 0.0\n    best_val_loss = float('inf')\n    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n    \n    for epoch in range(cfg.NUM_EPOCHS):\n        model.train()\n        running_loss = 0.0\n        \n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{cfg.NUM_EPOCHS} [train]\")\n        \n        for step, batch in enumerate(progress_bar, start=1):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n                outputs = model(**batch)\n                loss = outputs.loss / cfg.GRAD_ACCUM_STEPS\n            \n            scaler.scale(loss).backward()\n            running_loss += loss.item()\n            \n            if step % cfg.GRAD_ACCUM_STEPS == 0:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.MAX_GRAD_NORM)\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad(set_to_none=True)\n                \n                if cfg.USE_SWA and epoch >= cfg.SWA_START_EPOCH:\n                    swa_scheduler.step()\n                else:\n                    scheduler.step()\n                \n                if cfg.USE_EMA and ema is not None:\n                    ema.update()\n                \n                avg_loss = running_loss / cfg.GRAD_ACCUM_STEPS\n                progress_bar.set_postfix({\"loss\": f\"{avg_loss:.4f}\", \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"})\n                running_loss = 0.0\n        \n        # SWA update\n        if cfg.USE_SWA and swa_model is not None and epoch >= cfg.SWA_START_EPOCH:\n            swa_model.update_parameters(model)\n        \n        # ✅ Validation with Accuracy\n        if cfg.USE_EMA and ema is not None:\n            ema.apply_shadow()\n        \n        val_loss, val_acc, cm, preds, labels = validate_with_accuracy(model, valid_loader, processor)\n        \n        if cfg.USE_EMA and ema is not None:\n            ema.restore()\n        \n        history[\"val_loss\"].append(val_loss)\n        history[\"val_acc\"].append(val_acc)\n        \n        print(f\"[Epoch {epoch+1}] Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n        print(f\"Confusion Matrix:\\n{cm}\")\n        \n        # ✅ Best 모델 저장 (Acc 우선, 동률 시 Loss)\n        is_best = False\n        if val_acc > best_val_acc:\n            is_best = True\n            best_val_acc = val_acc\n            best_val_loss = val_loss\n        elif val_acc == best_val_acc and val_loss < best_val_loss:\n            is_best = True\n            best_val_loss = val_loss\n        \n        if is_best:\n            save_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n            os.makedirs(save_path, exist_ok=True)\n            \n            if cfg.USE_EMA and ema is not None:\n                ema.apply_shadow()\n            \n            model.save_pretrained(save_path)\n            processor.save_pretrained(save_path)\n            \n            if cfg.USE_EMA and ema is not None:\n                ema.restore()\n            \n            print(f\"   ✅ Best model saved (Acc={val_acc:.4f}, Loss={val_loss:.4f})\")\n    \n    # SWA 최종 모델\n    if cfg.USE_SWA and swa_model is not None:\n        torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n        save_path = f\"{cfg.SAVE_DIR}/fold{fold}_swa\"\n        os.makedirs(save_path, exist_ok=True)\n        swa_model.module.save_pretrained(save_path)\n        processor.save_pretrained(save_path)\n        print(f\"   ✅ SWA model saved\")\n    \n    # ✅ 학습 곡선 저장\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    ax1.plot(history[\"val_loss\"], marker='o')\n    ax1.set_title(f'Fold {fold} - Val Loss')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Loss')\n    ax1.grid(True)\n    \n    ax2.plot(history[\"val_acc\"], marker='o', color='green')\n    ax2.set_title(f'Fold {fold} - Val Accuracy')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Accuracy')\n    ax2.grid(True)\n    plt.tight_layout()\n    \n    log_dir = Path(cfg.LOG_DIR)\n    log_dir.mkdir(parents=True, exist_ok=True)\n    plt.savefig(log_dir / f\"fold{fold}_learning_curve.png\")\n    plt.show()\n    \n    return best_val_acc, best_val_loss\n\nprint(\"✅ Training functions 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 9. 학습 실행 (K-Fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅ 검증 데이터에 train=False 적용 (정답 주입 방지)\n\nif cfg.USE_KFOLD:\n    results = {}\n    \n    for fold in cfg.TRAIN_FOLDS:\n        print(f\"\\n{'#'*60}\")\n        print(f\"Starting Fold {fold}/{cfg.N_FOLDS-1}\")\n        print(f\"{'#'*60}\")\n        \n        train_subset = train_df[train_df['fold'] != fold].reset_index(drop=True)\n        valid_subset = train_df[train_df['fold'] == fold].reset_index(drop=True)\n        \n        print(f\"Train: {len(train_subset)}, Valid: {len(valid_subset)}\")\n        \n        train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n        valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)  # ✅ train=False\n        \n        train_loader = DataLoader(\n            train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True,\n            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n            num_workers=0\n        )\n        valid_loader = DataLoader(\n            valid_ds, batch_size=cfg.BATCH_SIZE, shuffle=False,\n            collate_fn=DataCollator(processor, train=False, use_advanced=cfg.USE_ADVANCED_MODEL),  # ✅ train=False\n            num_workers=0\n        )\n        \n        best_acc, best_loss = train_one_fold(model, train_loader, valid_loader, fold=fold)\n        results[fold] = {\"acc\": best_acc, \"loss\": best_loss}\n        \n        print(f\"\\n✅ Fold {fold} 완료: Best Val Acc={best_acc:.4f}, Loss={best_loss:.4f}\")\n    \n    print(f\"\\n{'='*60}\")\n    print(\"All Folds Training Complete!\")\n    print(f\"{'='*60}\")\n    for fold, metrics in results.items():\n        print(f\"Fold {fold}: Acc={metrics['acc']:.4f}, Loss={metrics['loss']:.4f}\")\n    print(f\"Average Acc: {np.mean([m['acc'] for m in results.values()]):.4f}\")\n\nelse:\n    # 단일 모델\n    train_subset = train_df[train_df['fold'] == -1].reset_index(drop=True)\n    valid_subset = train_df[train_df['fold'] == 0].reset_index(drop=True)\n    \n    train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n    valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)  # ✅ train=False\n    \n    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True,\n                             collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL), num_workers=0)\n    valid_loader = DataLoader(valid_ds, batch_size=cfg.BATCH_SIZE, shuffle=False,\n                             collate_fn=DataCollator(processor, train=False, use_advanced=cfg.USE_ADVANCED_MODEL), num_workers=0)\n    \n    best_acc, best_loss = train_one_fold(model, train_loader, valid_loader, fold=0)\n    print(f\"\\n✅ Single model 학습 완료: Best Val Acc={best_acc:.4f}, Loss={best_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔮 10. Inference with Direct Logits + TTA\n\n✅ **Direct Logits**: a/b/c/d 토큰 확률 직접 계산 (생성 대비 안정)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_choice_token_ids(processor):\n    \"\"\"a/b/c/d 토큰 ID 추출\"\"\"\n    choice_tokens = {}\n    for choice in ['a', 'b', 'c', 'd']:\n        token_ids = processor.tokenizer.encode(choice, add_special_tokens=False)\n        choice_tokens[choice] = token_ids\n    return choice_tokens\n\n\ndef infer_with_direct_logits(model, processor, test_df, tta_scales=[1.0], fold=0):\n    \"\"\"✅ Direct Logits 추론 + TTA\"\"\"\n    model.eval()\n    \n    # pad_token_id 설정\n    if processor.tokenizer.pad_token_id is None:\n        processor.tokenizer.pad_token_id = processor.tokenizer.eos_token_id\n    \n    choice_tokens = get_choice_token_ids(processor)\n    \n    all_predictions = []\n    all_probs = []\n    \n    for i in tqdm(range(len(test_df)), desc=f\"Fold {fold} Inference\"):\n        row = test_df.iloc[i]\n        \n        # TTA: 여러 스케일로 추론\n        tta_logits = []\n        \n        for scale in tta_scales:\n            # 이미지 로드\n            img_col = 'path' if 'path' in row else 'image'\n            img_path = os.path.join(cfg.DATA_DIR, row[img_col])\n            try:\n                img = Image.open(img_path).convert(\"RGB\")\n            except:\n                img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n            \n            # TTA 스케일 적용\n            if scale != 1.0:\n                w, h = img.size\n                new_w, new_h = int(w * scale), int(h * scale)\n                img = img.resize((new_w, new_h), Image.BILINEAR)\n            \n            # 프롬프트\n            user_text = build_mc_prompt(\n                str(row[\"question\"]), str(row[\"a\"]),\n                str(row[\"b\"]), str(row[\"c\"]), str(row[\"d\"])\n            )\n            \n            messages = [\n                {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n                {\"role\": \"user\", \"content\": [\n                    {\"type\": \"image\", \"image\": img},\n                    {\"type\": \"text\", \"text\": user_text}\n                ]}\n            ]\n            \n            # ✅ add_generation_prompt=True (추론 시)\n            text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n            \n            inputs = processor(text=[text], images=[img], return_tensors=\"pt\")\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n            \n            # ✅ Direct Logits: 다음 토큰 분포에서 a/b/c/d 확률 계산\n            with torch.no_grad():\n                outputs = model(**inputs)\n                logits = outputs.logits[0, -1, :]  # 마지막 토큰의 logits\n            \n            tta_logits.append(logits.cpu())\n        \n        # TTA 평균\n        avg_logits = torch.stack(tta_logits).mean(dim=0)\n        \n        # ✅ a/b/c/d 토큰 확률 집계\n        choice_probs = {}\n        for choice, token_ids in choice_tokens.items():\n            # 해당 choice의 모든 토큰 logit 합산\n            total_logit = sum([avg_logits[tid].item() for tid in token_ids])\n            choice_probs[choice] = total_logit\n        \n        # Softmax로 확률 변환\n        logit_values = torch.tensor(list(choice_probs.values()))\n        probs = F.softmax(logit_values, dim=0).numpy()\n        prob_dict = {choice: probs[idx] for idx, choice in enumerate(['a', 'b', 'c', 'd'])}\n        \n        # 예측\n        pred = max(prob_dict, key=prob_dict.get)\n        \n        all_predictions.append(pred)\n        all_probs.append(prob_dict)\n    \n    # DataFrame 생성\n    result_df = pd.DataFrame({\n        'id': test_df['id'],\n        'answer': all_predictions,\n        'prob_a': [p['a'] for p in all_probs],\n        'prob_b': [p['b'] for p in all_probs],\n        'prob_c': [p['c'] for p in all_probs],\n        'prob_d': [p['d'] for p in all_probs]\n    })\n    \n    return result_df\n\n\n# 각 Fold 추론\npredictions_all = []\n\nif cfg.USE_KFOLD:\n    for fold in cfg.TRAIN_FOLDS:\n        model_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"Inferencing Fold {fold}\")\n        print(f\"{'='*60}\")\n        \n        # 모델 로드\n        if cfg.USE_ADVANCED_MODEL:\n            model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n                model_path, trust_remote_code=True, torch_dtype=torch.float16\n            )\n        else:\n            model_infer = AutoModelForVision2Seq.from_pretrained(\n                model_path, trust_remote_code=True, torch_dtype=torch.float16\n            )\n        \n        model_infer = model_infer.to(device)\n        model_infer.eval()\n        \n        processor_infer = AutoProcessor.from_pretrained(\n            model_path,\n            min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n            max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n            trust_remote_code=True,\n        )\n        \n        # Direct Logits + TTA\n        tta_scales = cfg.TTA_SCALES if cfg.USE_TTA else [1.0]\n        pred_df = infer_with_direct_logits(model_infer, processor_infer, test_df, tta_scales, fold)\n        \n        # 저장\n        output_path = f\"{cfg.OUTPUT_DIR}/submission_fold{fold}.csv\"\n        os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n        pred_df.to_csv(output_path, index=False)\n        print(f\"✅ Saved to {output_path}\")\n        \n        predictions_all.append(pred_df)\n        \n        # 메모리 정리\n        del model_infer\n        torch.cuda.empty_cache()\n\nelse:\n    model_path = f\"{cfg.SAVE_DIR}/fold0_best\"\n    \n    if cfg.USE_ADVANCED_MODEL:\n        model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n            model_path, trust_remote_code=True, torch_dtype=torch.float16\n        ).to(device)\n    else:\n        model_infer = AutoModelForVision2Seq.from_pretrained(\n            model_path, trust_remote_code=True, torch_dtype=torch.float16\n        ).to(device)\n    \n    processor_infer = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n    \n    tta_scales = cfg.TTA_SCALES if cfg.USE_TTA else [1.0]\n    pred_df = infer_with_direct_logits(model_infer, processor_infer, test_df, tta_scales, fold=0)\n    \n    output_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n    pred_df.to_csv(output_path, index=False)\n    predictions_all.append(pred_df)\n\nprint(\"\\n✅ All inference complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🌡️ 11. Temperature Scaling\n\n✅ 검증 세트로 확률 교정 (선택 사항)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅ Temperature Scaling (선택 사항)\n# 검증 세트가 있을 때 각 fold의 최적 temperature를 찾아 test 확률에 적용\n\ndef find_optimal_temperature(val_probs, val_labels):\n    \"\"\"검증 세트에서 최적 temperature 탐색\"\"\"\n    from scipy.optimize import minimize\n    \n    def nll_loss(temp):\n        scaled_probs = F.softmax(torch.tensor(val_probs) / temp, dim=1).numpy()\n        # Negative log-likelihood\n        nll = -np.log(scaled_probs[np.arange(len(val_labels)), val_labels] + 1e-10).mean()\n        return nll\n    \n    result = minimize(nll_loss, x0=[1.0], bounds=[(0.1, 10.0)])\n    return result.x[0]\n\n# 실제로 사용하려면:\n# 1. 검증 세트로 확률과 정답 수집\n# 2. optimal_temp = find_optimal_temperature(val_probs, val_labels)\n# 3. test 확률에 적용: scaled_probs = F.softmax(torch.tensor(test_probs) / optimal_temp, dim=1)\n\n# 현재는 temperature=1.0으로 유지 (기본)\nprint(\"✅ Temperature scaling은 선택 사항입니다.\")\nprint(\"검증 세트가 있을 때 위 코드를 활용하여 최적 temperature를 찾을 수 있습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 12. Ensemble (확률 평균)\n\n✅ **Probability Averaging** (폴백: Majority Voting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD and len(predictions_all) > 1:\n    print(f\"\\n{'='*60}\")\n    print(f\"Ensemble Method: {cfg.ENSEMBLE_METHOD}\")\n    print(f\"{'='*60}\")\n    \n    if cfg.ENSEMBLE_METHOD == 'prob':\n        # ✅ 확률 앙상블\n        print(\"Using Probability Averaging...\")\n        \n        ensemble_probs = pd.DataFrame({\n            'id': test_df['id'],\n            'prob_a': np.mean([df['prob_a'].values for df in predictions_all], axis=0),\n            'prob_b': np.mean([df['prob_b'].values for df in predictions_all], axis=0),\n            'prob_c': np.mean([df['prob_c'].values for df in predictions_all], axis=0),\n            'prob_d': np.mean([df['prob_d'].values for df in predictions_all], axis=0)\n        })\n        \n        # argmax\n        prob_cols = ['prob_a', 'prob_b', 'prob_c', 'prob_d']\n        ensemble_probs['answer'] = ensemble_probs[prob_cols].values.argmax(axis=1)\n        ensemble_probs['answer'] = ensemble_probs['answer'].map({0: 'a', 1: 'b', 2: 'c', 3: 'd'})\n        \n        final_submission = ensemble_probs[['id', 'answer', 'prob_a', 'prob_b', 'prob_c', 'prob_d']]\n    \n    else:\n        # Majority Voting (폴백)\n        print(\"Using Majority Voting...\")\n        \n        ensemble_preds = []\n        for i in range(len(test_df)):\n            votes = [pred.iloc[i]['answer'] for pred in predictions_all]\n            most_common = Counter(votes).most_common(1)[0][0]\n            ensemble_preds.append(most_common)\n        \n        final_submission = pd.DataFrame({\n            'id': test_df['id'],\n            'answer': ensemble_preds\n        })\n    \n    final_path = f\"{cfg.OUTPUT_DIR}/submission_ensemble.csv\"\n    final_submission.to_csv(final_path, index=False)\n    \n    print(f\"✅ Ensemble submission saved to {final_path}\")\n    print(f\"\\nAnswer Distribution:\")\n    print(final_submission['answer'].value_counts().sort_index())\n\nelse:\n    print(\"\\n✅ Single model - No ensemble needed\")\n    final_submission = predictions_all[0]\n    final_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n    final_submission.to_csv(final_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 13. 결과 분석 및 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 5))\n\nanswer_counts = final_submission['answer'].value_counts().sort_index()\nsns.barplot(x=answer_counts.index, y=answer_counts.values, palette='viridis', ax=ax)\nax.set_title('Final Submission Answer Distribution', fontsize=14, weight='bold')\nax.set_xlabel('Answer')\nax.set_ylabel('Count')\nax.grid(axis='y', alpha=0.3)\n\nfor i, (ans, count) in enumerate(answer_counts.items()):\n    percentage = count / len(final_submission) * 100\n    ax.text(i, count + 10, f\"{percentage:.1f}%\", ha='center', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n{'='*60}\")\nprint(\"Final Statistics\")\nprint(f\"{'='*60}\")\nprint(f\"Total predictions: {len(final_submission)}\")\nprint(f\"\\nAnswer counts:\")\nfor ans, count in answer_counts.items():\n    print(f\"  {ans}: {count:5d} ({count/len(final_submission)*100:5.1f}%)\")\n\n# 확률 분포 (있는 경우)\nif 'prob_a' in final_submission.columns:\n    print(f\"\\n{'='*60}\")\n    print(\"Probability Statistics\")\n    print(f\"{'='*60}\")\n    prob_cols = ['prob_a', 'prob_b', 'prob_c', 'prob_d']\n    print(final_submission[prob_cols].describe())\n\nprint(f\"\\n{'='*60}\")\nprint(\"Sample Predictions\")\nprint(f\"{'='*60}\")\nprint(final_submission.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✅ 14. 최종 정리\n\n### 🎉 완료된 작업\n\n1. ✅ Config 설정 (Pro2 튜닝)\n2. ✅ 데이터 로드 & EDA\n3. ✅ Stratified K-Fold CV\n4. ✅ Dataset & DataCollator (라벨 마스킹)\n5. ✅ Model & Processor (T4 호환)\n6. ✅ Training Loop (Val Acc + Confusion Matrix)\n7. ✅ Inference (Direct Logits + TTA)\n8. ✅ Temperature Scaling (선택 사항)\n9. ✅ Ensemble (확률 평균)\n10. ✅ 결과 분석 & 시각화\n\n### 🚀 주요 개선사항\n\n#### 학습\n- Val Accuracy 로깅 및 Best 모델 저장 (Acc 우선)\n- Confusion Matrix 출력\n- 학습 곡선 시각화\n- 검증 데이터 train=False (정답 주입 방지)\n\n#### 추론\n- Direct Logits: a/b/c/d 토큰 확률 직접 계산\n- TTA: [0.9, 1.0, 1.1] 스케일 평균\n- pad_token_id 자동 보정\n- 확률 컬럼 저장\n\n#### 앙상블\n- 확률 앙상블 (Probability Averaging)\n- 폴백: Majority Voting\n\n### 📊 Pro2 설정\n\n```python\nUSE_SAMPLE = False          # 전체 데이터\nIMAGE_SIZE = 512\nNUM_EPOCHS = 3\nGRAD_ACCUM_STEPS = 8\nWARMUP_RATIO = 0.06\nLORA_R = 16\nUSE_DIRECT_LOGIT_DECODE = True\nTTA_SCALES = [0.9, 1.0, 1.1]\nENSEMBLE_METHOD = 'prob'\n```\n\n### 📌 Important Notes\n\n- **디바이스 정렬**: 모든 모델/입력을 단일 device로 통일\n- **라벨 마스킹**: 프롬프트 토큰 손실 제외, assistant 정답만 감독\n- **검증 플래그**: valid_ds에 train=False 적용\n- **Direct Logits**: 생성 대비 안정적이고 빠른 추론\n- **확률 앙상블**: Fold 간 확률 평균으로 robust한 예측\n\n---\n\n**🤖 SSAFY AI Project 2025 - Pro2 Version**\n\n**⭐ 행운을 빕니다!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
﻿{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# 📒 Kaggle_AllInOne_Pro.ipynb – 단일 노트북 통합 버전\n",
                                     "\n",
                                     "## 🎯 개요\n",
                                     "\n",
                                     "본 노트북은 **VQA Kaggle Challenge**를 위한 **완전 통합 고성능 파이프라인**입니다.\n",
                                     "\n",
                                     "### ✨ 주요 기능\n",
                                     "\n",
                                     "- ✅ **T4 GPU 완벽 호환** (Float16, SDPA attention)\n",
                                     "- ✅ **라벨 정렬 교정** (Assistant 메시지에 정답 포함)\n",
                                     "- ✅ **K-Fold Cross-Validation** (Stratified)\n",
                                     "- ✅ **고급 학습 기법** (AMP, EMA, SWA, Cosine Warmup)\n",
                                     "- ✅ **데이터 증강** (Choice Shuffle, Paraphrase)\n",
                                     "- ✅ **TTA (Test-Time Augmentation)**\n",
                                     "- ✅ **앙상블** (Weighted Voting)\n",
                                     "- ✅ **메모리 최적화** (Gradient Checkpointing, 4-bit QLoRA)\n",
                                     "\n",
                                     "### 📊 예상 성능\n",
                                     "\n",
                                     "| 설정 | 정확도 | 시간 |\n",
                                     "|------|--------|------|\n",
                                     "| Single Fold | 79-82% | ~4h |\n",
                                     "| 3-Fold Ensemble | 83-85% | ~12h |\n",
                                     "| + TTA + Optimization | 85-88% | ~15h |\n",
                                     "\n",
                                     "### 🚀 실행 순서\n",
                                     "\n",
                                     "1. **환경 설정** - 패키지 설치 및 임포트\n",
                                     "2. **Config** - 하이퍼파라미터 설정\n",
                                     "3. **데이터 로드** - Train/Test 데이터 로드\n",
                                     "4. **EDA** - 탐색적 데이터 분석\n",
                                     "5. **Stratified K-Fold** - CV Splits 생성\n",
                                     "6. **Dataset \u0026 DataLoader** - 커스텀 데이터셋 정의\n",
                                     "7. **Model \u0026 Processor** - QLoRA 모델 로드\n",
                                     "8. **Training Loop** - 고급 기법 적용 학습\n",
                                     "9. **Inference** - TTA를 활용한 추론\n",
                                     "10. **Ensemble** - 앙상블 및 제출 파일 생성\n",
                                     "\n",
                                     "---\n",
                                     "\n",
                                     "**🤖 Generated for SSAFY AI Project 2025**"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 📦 1. 환경 설정 및 패키지 설치\n",
                                     "\n",
                                     "필요한 라이브러리를 설치합니다. (첫 실행 시 1회만)\n",
                                     "\n",
                                     "### ⚠️ 중요: 설치 후 런타임 재시작 필요"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# 패키지 설치 (Colab/Kaggle 환경)\n",
                                     "# 첫 실행 시에만 주석 해제하고 실행\n",
                                     "# !pip install -q \"transformers\u003e=4.44.2\" \"accelerate\u003e=0.34.2\" \"peft\u003e=0.13.2\" \\\n",
                                     "#     \"bitsandbytes\u003e=0.43.1\" datasets pillow pandas torch torchvision \\\n",
                                     "#     scikit-learn matplotlib seaborn tqdm --upgrade\n",
                                     "# !pip install -q qwen-vl-utils==0.0.8\n",
                                     "\n",
                                     "print(\"✅ 패키지 설치 완료! 런타임을 재시작하세요.\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 📚 2. 라이브러리 임포트"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import os, sys, re, math, random, warnings\n",
                                     "import numpy as np\n",
                                     "import pandas as pd\n",
                                     "from PIL import Image\n",
                                     "from pathlib import Path\n",
                                     "from dataclasses import dataclass\n",
                                     "from typing import Dict, List, Any, Optional\n",
                                     "from collections import Counter\n",
                                     "import unicodedata\n",
                                     "\n",
                                     "# PyTorch\n",
                                     "import torch\n",
                                     "import torch.nn as nn\n",
                                     "from torch.utils.data import Dataset, DataLoader\n",
                                     "from torch.optim.swa_utils import AveragedModel, SWALR\n",
                                     "\n",
                                     "# Transformers \u0026 PEFT\n",
                                     "from transformers import (\n",
                                     "    AutoModelForVision2Seq,\n",
                                     "    Qwen2_5_VLForConditionalGeneration,\n",
                                     "    AutoProcessor,\n",
                                     "    BitsAndBytesConfig,\n",
                                     "    get_cosine_schedule_with_warmup,\n",
                                     "    get_linear_schedule_with_warmup\n",
                                     ")\n",
                                     "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
                                     "from qwen_vl_utils import process_vision_info\n",
                                     "\n",
                                     "# Scikit-learn\n",
                                     "from sklearn.model_selection import StratifiedKFold\n",
                                     "from sklearn.metrics import accuracy_score, confusion_matrix\n",
                                     "\n",
                                     "# Visualization\n",
                                     "import matplotlib.pyplot as plt\n",
                                     "import seaborn as sns\n",
                                     "from tqdm.auto import tqdm\n",
                                     "\n",
                                     "# 설정\n",
                                     "warnings.filterwarnings(\u0027ignore\u0027)\n",
                                     "Image.MAX_IMAGE_PIXELS = None\n",
                                     "sns.set_style(\u0027whitegrid\u0027)\n",
                                     "\n",
                                     "# 디바이스\n",
                                     "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                                     "print(f\"🔧 Device: {device}\")\n",
                                     "if torch.cuda.is_available():\n",
                                     "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
                                     "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                                     "\n",
                                     "print(f\"🐍 Python: {sys.version.split()[0]}\")\n",
                                     "print(f\"🔥 PyTorch: {torch.__version__}\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ⚙️ 3. Config 설정\n",
                                     "\n",
                                     "모든 하이퍼파라미터를 한 곳에서 관리합니다."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "class Config:\n",
                                     "    \"\"\"통합 설정 클래스\"\"\"\n",
                                     "    \n",
                                     "    # 시드 (재현성)\n",
                                     "    SEED = 42\n",
                                     "    \n",
                                     "    # 모델 설정\n",
                                     "    MODEL_ID = \"Qwen/Qwen2.5-VL-3B-Instruct\"  # 또는 \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
                                     "    IMAGE_SIZE = 512  # 384 or 512 or 768\n",
                                     "    USE_ADVANCED_MODEL = False  # True: Qwen2_5_VL, False: AutoModelForVision2Seq (baseline)\n",
                                     "    \n",
                                     "    # 데이터 경로\n",
                                     "    DATA_DIR = \"/kaggle/input/ssafy-ai-pjt-data\"\n",
                                     "    TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n",
                                     "    TEST_CSV = f\"{DATA_DIR}/test.csv\"\n",
                                     "    \n",
                                     "    # K-Fold 설정\n",
                                     "    N_FOLDS = 3\n",
                                     "    USE_KFOLD = True  # False: 단일 모델 학습\n",
                                     "    TRAIN_FOLDS = [0, 1, 2]  # 학습할 fold 번호\n",
                                     "    \n",
                                     "    # QLoRA 설정\n",
                                     "    LORA_R = 16\n",
                                     "    LORA_ALPHA = 16\n",
                                     "    LORA_DROPOUT = 0.05\n",
                                     "    TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
                                     "                      \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
                                     "    \n",
                                     "    # 학습 설정\n",
                                     "    NUM_EPOCHS = 3\n",
                                     "    BATCH_SIZE = 1\n",
                                     "    GRAD_ACCUM_STEPS = 8\n",
                                     "    LEARNING_RATE = 1e-4\n",
                                     "    WEIGHT_DECAY = 0.01\n",
                                     "    WARMUP_RATIO = 0.06\n",
                                     "    MAX_GRAD_NORM = 1.0\n",
                                     "    \n",
                                     "    # 고급 기법\n",
                                     "    USE_AMP = True  # Automatic Mixed Precision\n",
                                     "    USE_EMA = True  # Exponential Moving Average\n",
                                     "    EMA_DECAY = 0.999\n",
                                     "    USE_SWA = False  # Stochastic Weight Averaging (마지막 에폭만)\n",
                                     "    SWA_START_EPOCH = 0  # SWA 시작 에폭 (마지막 에폭 권장)\n",
                                     "    USE_COSINE_SCHEDULE = True  # True: Cosine, False: Linear\n",
                                     "    \n",
                                     "    # 데이터 증강\n",
                                     "    USE_AUGMENTATION = False  # Choice shuffle 등\n",
                                     "    AUG_PROB = 0.3\n",
                                     "    \n",
                                     "    # TTA (Test-Time Augmentation)\n",
                                     "    USE_TTA = True\n",
                                     "    TTA_SCALES = [0.9, 1.0, 1.1]  # test-time scales\n",
                                     "    \n",
                                     "    # Inference options\n",
                                     "    USE_DIRECT_LOGIT_DECODE = True  # use logits for a/b/c/d scoring\n",
                                     "    ENSEMBLE_METHOD = \"prob\"  # \"prob\" or \"vote\"\n",
                                     "    DO_SAMPLE = False\n",
                                     "    TEMPERATURE = 0.0\n",
                                     "    \n",
                                     "    # 저장 경로\n",
                                     "    SAVE_DIR = f\"/kaggle/working/checkpoints\"\n",
                                     "    OUTPUT_DIR = f\"/kaggle/working/outputs\"\n",
                                     "    \n",
                                     "    # 샘플링 (디버깅용)\n",
                                     "    USE_SAMPLE = False  # use full training data\n",
                                     "    SAMPLE_SIZE = 200  # 샘플 크기\n",
                                     "    \n",
                                     "    # 프롬프트\n",
                                     "    SYSTEM_INSTRUCT = (\n",
                                     "        \"You are a helpful visual question answering assistant. \"\n",
                                     "        \"Answer using exactly one letter among a, b, c, or d. No explanation.\"\n",
                                     "    )\n",
                                     "\n",
                                     "\n",
                                     "# Config 인스턴스 생성\n",
                                     "cfg = Config()\n",
                                     "\n",
                                     "# 시드 고정\n",
                                     "def set_seed(seed=42):\n",
                                     "    random.seed(seed)\n",
                                     "    np.random.seed(seed)\n",
                                     "    torch.manual_seed(seed)\n",
                                     "    torch.cuda.manual_seed_all(seed)\n",
                                     "    torch.backends.cudnn.deterministic = True\n",
                                     "    torch.backends.cudnn.benchmark = False\n",
                                     "\n",
                                     "set_seed(cfg.SEED)\n",
                                     "print(f\"✅ Config 설정 완료 (Seed: {cfg.SEED})\")\n",
                                     "print(f\"   Model: {cfg.MODEL_ID}\")\n",
                                     "print(f\"   K-Fold: {cfg.N_FOLDS if cfg.USE_KFOLD else \u0027Disabled\u0027}\")\n",
                                     "print(f\"   Advanced Techniques: AMP={cfg.USE_AMP}, EMA={cfg.USE_EMA}, SWA={cfg.USE_SWA}, TTA={cfg.USE_TTA}\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 📊 4. 데이터 로드 및 EDA\n",
                                     "\n",
                                     "데이터를 로드하고 간단한 탐색적 분석을 수행합니다."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# 데이터 로드\n",
                                     "train_df = pd.read_csv(cfg.TRAIN_CSV)\n",
                                     "test_df = pd.read_csv(cfg.TEST_CSV)\n",
                                     "\n",
                                     "print(f\"📁 Train: {len(train_df):,} samples\")\n",
                                     "print(f\"📁 Test: {len(test_df):,} samples\")\n",
                                     "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
                                     "\n",
                                     "# 샘플링 (디버깅용)\n",
                                     "if cfg.USE_SAMPLE:\n",
                                     "    train_df = train_df.sample(n=min(cfg.SAMPLE_SIZE, len(train_df)), random_state=cfg.SEED).reset_index(drop=True)\n",
                                     "    print(f\"\\n⚠️  Sampled {len(train_df)} samples for quick testing\")\n",
                                     "\n",
                                     "# 기본 통계\n",
                                     "print(f\"\\n📊 Answer Distribution:\")\n",
                                     "print(train_df[\u0027answer\u0027].value_counts().sort_index())\n",
                                     "\n",
                                     "# 시각화\n",
                                     "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
                                     "\n",
                                     "# 답변 분포\n",
                                     "train_df[\u0027answer\u0027].value_counts().sort_index().plot(kind=\u0027bar\u0027, ax=axes[0], color=\u0027skyblue\u0027)\n",
                                     "axes[0].set_title(\u0027Answer Distribution (Train)\u0027, fontsize=12, weight=\u0027bold\u0027)\n",
                                     "axes[0].set_xlabel(\u0027Answer\u0027)\n",
                                     "axes[0].set_ylabel(\u0027Count\u0027)\n",
                                     "axes[0].grid(axis=\u0027y\u0027, alpha=0.3)\n",
                                     "\n",
                                     "# 질문 길이 분포\n",
                                     "train_df[\u0027question_len\u0027] = train_df[\u0027question\u0027].str.len()\n",
                                     "train_df[\u0027question_len\u0027].hist(bins=30, ax=axes[1], color=\u0027salmon\u0027, edgecolor=\u0027black\u0027)\n",
                                     "axes[1].set_title(\u0027Question Length Distribution\u0027, fontsize=12, weight=\u0027bold\u0027)\n",
                                     "axes[1].set_xlabel(\u0027Length (chars)\u0027)\n",
                                     "axes[1].set_ylabel(\u0027Count\u0027)\n",
                                     "axes[1].grid(axis=\u0027y\u0027, alpha=0.3)\n",
                                     "\n",
                                     "plt.tight_layout()\n",
                                     "plt.show()\n",
                                     "\n",
                                     "# 샘플 출력\n",
                                     "print(\"\\n📝 Sample Data:\")\n",
                                     "print(train_df.head(2))"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🔄 5. Stratified K-Fold Cross-Validation\n",
                                     "\n",
                                     "답변 분포를 유지하면서 K-Fold를 생성합니다."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "if cfg.USE_KFOLD:\n",
                                     "    # Stratified K-Fold 생성\n",
                                     "    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=cfg.SEED)\n",
                                     "    train_df[\u0027fold\u0027] = -1\n",
                                     "    \n",
                                     "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df[\u0027answer\u0027])):\n",
                                     "        train_df.loc[val_idx, \u0027fold\u0027] = fold\n",
                                     "    \n",
                                     "    print(f\"✅ {cfg.N_FOLDS}-Fold CV 생성 완료\")\n",
                                     "    print(f\"\\nFold Distribution:\")\n",
                                     "    print(train_df[\u0027fold\u0027].value_counts().sort_index())\n",
                                     "    \n",
                                     "    # Fold별 답변 분포 확인\n",
                                     "    print(f\"\\nAnswer Distribution per Fold:\")\n",
                                     "    for fold in range(cfg.N_FOLDS):\n",
                                     "        fold_data = train_df[train_df[\u0027fold\u0027] == fold]\n",
                                     "        dist = fold_data[\u0027answer\u0027].value_counts(normalize=True).sort_index()\n",
                                     "        print(f\"Fold {fold}: {dict(dist)}\")\n",
                                     "else:\n",
                                     "    # 단일 모델 학습 (90:10 split)\n",
                                     "    split_idx = int(len(train_df) * 0.9)\n",
                                     "    train_df[\u0027fold\u0027] = -1\n",
                                     "    train_df.loc[split_idx:, \u0027fold\u0027] = 0\n",
                                     "    print(f\"✅ Single split (90:10) 생성 완료\")\n",
                                     "    print(f\"   Train: {len(train_df[train_df[\u0027fold\u0027] == -1])}\")\n",
                                     "    print(f\"   Valid: {len(train_df[train_df[\u0027fold\u0027] == 0])}\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🗂️ 6. Dataset \u0026 DataLoader\n",
                                     "\n",
                                     "커스텀 데이터셋 및 DataCollator를 정의합니다.\n",
                                     "\n",
                                     "### ✅ 라벨 정렬 교정 적용\n",
                                     "- Assistant 메시지에 정답 포함\n",
                                     "- `add_generation_prompt=False` 사용"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "def build_mc_prompt(question, a, b, c, d):\n",
                                     "    \"\"\"Multiple Choice 프롬프트 생성\"\"\"\n",
                                     "    return (\n",
                                     "        f\"{question}\\n\"\n",
                                     "        f\"(a) {a}\\n(b) {b}\\n(c) {c}\\n(d) {d}\\n\\n\"\n",
                                     "        \"정답을 반드시 a, b, c, d 중 하나의 소문자 한 글자로만 출력하세요.\"\n",
                                     "    )\n",
                                     "\n",
                                     "\n",
                                     "class VQADataset(Dataset):\n",
                                     "    \"\"\"VQA Dataset with Label Alignment Fix\"\"\"\n",
                                     "    \n",
                                     "    def __init__(self, df, processor, data_dir=\"\", train=True, use_advanced=False):\n",
                                     "        self.df = df.reset_index(drop=True)\n",
                                     "        self.processor = processor\n",
                                     "        self.data_dir = data_dir\n",
                                     "        self.train = train\n",
                                     "        self.use_advanced = use_advanced  # process_vision_info 사용 여부\n",
                                     "    \n",
                                     "    def __len__(self):\n",
                                     "        return len(self.df)\n",
                                     "    \n",
                                     "    def __getitem__(self, idx):\n",
                                     "        row = self.df.iloc[idx]\n",
                                     "        \n",
                                     "        # 이미지 로드\n",
                                     "        img_path = os.path.join(self.data_dir, row[\"path\"])\n",
                                     "        try:\n",
                                     "            img = Image.open(img_path).convert(\"RGB\")\n",
                                     "        except:\n",
                                     "            img = Image.new(\u0027RGB\u0027, (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color=\u0027white\u0027)\n",
                                     "        \n",
                                     "        # 프롬프트 생성\n",
                                     "        user_text = build_mc_prompt(\n",
                                     "            str(row[\"question\"]),\n",
                                     "            str(row[\"a\"]), str(row[\"b\"]),\n",
                                     "            str(row[\"c\"]), str(row[\"d\"])\n",
                                     "        )\n",
                                     "        \n",
                                     "        # 메시지 구성\n",
                                     "        messages = [\n",
                                     "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n",
                                     "            {\"role\": \"user\", \"content\": [\n",
                                     "                {\"type\": \"image\", \"image\": img},\n",
                                     "                {\"type\": \"text\", \"text\": user_text}\n",
                                     "            ]}\n",
                                     "        ]\n",
                                     "        \n",
                                     "        # ✅ CRITICAL: 학습 시 정답 포함 (라벨 정렬 교정)\n",
                                     "        if self.train:\n",
                                     "            answer = str(row[\"answer\"]).strip().lower()\n",
                                     "            messages.append({\n",
                                     "                \"role\": \"assistant\",\n",
                                     "                \"content\": [{\"type\": \"text\", \"text\": answer}]\n",
                                     "            })\n",
                                     "        \n",
                                     "        return {\"messages\": messages, \"image\": img, \"answer\": (answer if self.train else None)}\n",
                                     "\n",
                                     "\n",
                                     "@dataclass\n",
                                     "class DataCollator:\n",
                                     "    \"\"\"Data Collator for VQA\"\"\"\n",
                                     "    processor: Any\n",
                                     "    train: bool = True\n",
                                     "    use_advanced: bool = False\n",
                                     "    \n",
                                     "    def __call__(self, batch):\n",
                                     "        texts, images = [], []\n",
                                     "        \n",
                                     "        for sample in batch:\n",
                                     "            messages = sample[\"messages\"]\n",
                                     "            img = sample[\"image\"]\n",
                                     "            \n",
                                     "            # ✅ apply_chat_template 사용\n",
                                     "            text = self.processor.apply_chat_template(\n",
                                     "                messages,\n",
                                     "                tokenize=False,\n",
                                     "                add_generation_prompt=False  # ✅ 학습 시 False!\n",
                                     "            )\n",
                                     "            \n",
                                     "            # 한글 정규화\n",
                                     "            text = unicodedata.normalize(\u0027NFKC\u0027, text)\n",
                                     "            \n",
                                     "            texts.append(text)\n",
                                     "            images.append(img)\n",
                                     "        \n",
                                     "        # 인코딩\n",
                                     "        if self.use_advanced:\n",
                                     "            # process_vision_info 사용 (Qwen2_5_VL)\n",
                                     "            enc = self.processor(\n",
                                     "                text=texts,\n",
                                     "                images=images,\n",
                                     "                padding=True,\n",
                                     "                return_tensors=\"pt\"\n",
                                     "            )\n",
                                     "        else:\n",
                                     "            # 기본 방식 (AutoModelForVision2Seq)\n",
                                     "            enc = self.processor(\n",
                                     "                text=texts,\n",
                                     "                images=images,\n",
                                     "                padding=True,\n",
                                     "                return_tensors=\"pt\"\n",
                                     "            )\n",
                                     "        \n",
                                     "        # ✅ 라벨 설정\n",
                                     "        \n",
                                     "        # Build labels: mask prompt tokens, keep only assistant answer tokens\n         if self.train:\n             labels = enc[\"input_ids\"].clone()  # [B, L]\n             labels[:] = -100\n             for i, sample in enumerate(batch):\n                 ans = sample.get(\"answer\", None)\n                 if ans is None:\n                     continue\n                 try:\n                     ans_ids = self.processor.tokenizer.encode(str(ans).strip().lower(), add_special_tokens=False)\n                 except Exception:\n                     ans_ids = []\n                 ids = enc[\"input_ids\"][i].tolist()\n                 start = -1\n                 if ans_ids:\n                     for s in range(len(ids) - len(ans_ids), -1, -1):\n                         if ids[s:s+len(ans_ids)] == ans_ids:\n                             start = s\n                             break\n                 if start == -1:\n                     try:\n                         last = int(enc[\"attention_mask\"][i].sum().item()) - 1\n                         if last \u003e= 0:\n                             labels[i, last] = enc[\"input_ids\"][i, last]\n                     except Exception:\n                         pass\n                 else:\n                     labels[i, start:start+len(ans_ids)] = enc[\"input_ids\"][i, start:start+len(ans_ids)]\n             enc[\"labels\"] = labels\n",
                                     "        \n",
                                     "        return enc\n",
                                     "\n",
                                     "\n",
                                     "print(\"✅ Dataset \u0026 DataCollator 정의 완료\")\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🤖 7. Model \u0026 Processor 로드\n",
                                     "\n",
                                     "QLoRA 모델과 Processor를 로드합니다.\n",
                                     "\n",
                                     "### ✅ T4 호환 설정\n",
                                     "- Float16 (BFloat16 아님)\n",
                                     "- SDPA attention (FlashAttention 제거)\n",
                                     "- 4-bit quantization"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "def create_model_and_processor(model_id, use_advanced=False):\n",
                                     "    \"\"\"모델 및 Processor 생성\"\"\"\n",
                                     "    \n",
                                     "    # 양자화 설정\n",
                                     "    bnb_config = BitsAndBytesConfig(\n",
                                     "        load_in_4bit=True,\n",
                                     "        bnb_4bit_use_double_quant=True,\n",
                                     "        bnb_4bit_quant_type=\"nf4\",\n",
                                     "        bnb_4bit_compute_dtype=torch.float16,  # ✅ T4 호환 (BF16 아님)\n",
                                     "    )\n",
                                     "    \n",
                                     "    # Processor 로드\n",
                                     "    processor = AutoProcessor.from_pretrained(\n",
                                     "        model_id,\n",
                                     "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
                                     "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
                                     "        trust_remote_code=True,\n",
                                     "    )\n",
                                     "    \n",
                                     "    # 모델 로드\n",
                                     "    if use_advanced:\n",
                                     "        # ✅ Qwen2_5_VLForConditionalGeneration (고급)\n",
                                     "        base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
                                     "            model_id,\n",
                                     "            quantization_config=bnb_config,\n",
                                     "            trust_remote_code=True,\n",
                                     "            torch_dtype=torch.float16,\n",
                                     "            attn_implementation=\"sdpa\",  # ✅ FlashAttention 제거\n",
                                     "        )\n",
                                     "    else:\n",
                                     "        # AutoModelForVision2Seq (Baseline 호환)\n",
                                     "        base_model = AutoModelForVision2Seq.from_pretrained(\n",
                                     "            model_id,\n",
                                     "            quantization_config=bnb_config,\n",
                                     "            trust_remote_code=True,\n",
                                     "        )\n",
                                     "    \n",
                                     "    # QLoRA 준비\n",
                                     "    base_model = prepare_model_for_kbit_training(base_model)\n",
                                     "    base_model.gradient_checkpointing_enable()\n",
                                     "    \n",
                                     "    # LoRA Config\n",
                                     "    lora_config = LoraConfig(\n",
                                     "        r=cfg.LORA_R,\n",
                                     "        lora_alpha=cfg.LORA_ALPHA,\n",
                                     "        lora_dropout=cfg.LORA_DROPOUT,\n",
                                     "        bias=\"none\",\n",
                                     "        target_modules=cfg.TARGET_MODULES,\n",
                                     "        task_type=\"CAUSAL_LM\",\n",
                                     "    )\n",
                                     "    \n",
                                     "    # PEFT 모델 생성\n",
                                     "    model = get_peft_model(base_model, lora_config)\n",
                                     "    model.print_trainable_parameters()\n",
                                     "    \n",
                                     "    return model, processor\n",
                                     "\n",
                                     "\n",
                                     "print(\"🔧 모델 로드 중...\")\n",
                                     "model, processor = create_model_and_processor(\n",
                                     "    cfg.MODEL_ID,\n",
                                     "    use_advanced=cfg.USE_ADVANCED_MODEL\n",
                                     ")\n",
                                     "model = model.to(device)\n",
                                     "print(f\"✅ 모델 로드 완료\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🎓 8. Training Loop with Advanced Techniques\n",
                                     "\n",
                                     "고급 학습 기법을 적용한 학습 루프입니다.\n",
                                     "\n",
                                     "### ✨ 적용된 기법\n",
                                     "- ✅ **AMP** (Automatic Mixed Precision)\n",
                                     "- ✅ **EMA** (Exponential Moving Average)\n",
                                     "- ✅ **SWA** (Stochastic Weight Averaging)\n",
                                     "- ✅ **Cosine Warmup Scheduler**\n",
                                     "- ✅ **Gradient Clipping**"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "class EMA:\n",
                                     "    \"\"\"Exponential Moving Average\"\"\"\n",
                                     "    def __init__(self, model, decay=0.999):\n",
                                     "        self.model = model\n",
                                     "        self.decay = decay\n",
                                     "        self.shadow = {}\n",
                                     "        self.backup = {}\n",
                                     "        self.register()\n",
                                     "    \n",
                                     "    def register(self):\n",
                                     "        for name, param in self.model.named_parameters():\n",
                                     "            if param.requires_grad:\n",
                                     "                self.shadow[name] = param.data.clone()\n",
                                     "    \n",
                                     "    def update(self):\n",
                                     "        for name, param in self.model.named_parameters():\n",
                                     "            if param.requires_grad:\n",
                                     "                new_average = (\n",
                                     "                    self.decay * self.shadow[name] +\n",
                                     "                    (1.0 - self.decay) * param.data\n",
                                     "                )\n",
                                     "                self.shadow[name] = new_average.clone()\n",
                                     "    \n",
                                     "    def apply_shadow(self):\n",
                                     "        for name, param in self.model.named_parameters():\n",
                                     "            if param.requires_grad:\n",
                                     "                self.backup[name] = param.data.clone()\n",
                                     "                param.data = self.shadow[name]\n",
                                     "    \n",
                                     "    def restore(self):\n",
                                     "        for name, param in self.model.named_parameters():\n",
                                     "            if param.requires_grad:\n",
                                     "                param.data = self.backup[name]\n",
                                     "        self.backup = {}\n",
                                     "\n",
                                     "\n",
                                     "def train_one_fold(model, train_loader, valid_loader, fold=0):\n",
                                     "    \"\"\"단일 Fold 학습\"\"\"\n",
                                     "    \n",
                                     "    print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "    print(f\"Training Fold {fold}\")\n",
                                     "    print(f\"{\u0027=\u0027*60}\")\n",
                                     "    \n",
                                     "    # Optimizer\n",
                                     "    optimizer = torch.optim.AdamW(\n",
                                     "        model.parameters(),\n",
                                     "        lr=cfg.LEARNING_RATE,\n",
                                     "        weight_decay=cfg.WEIGHT_DECAY\n",
                                     "    )\n",
                                     "    \n",
                                     "    # Scheduler\n",
                                     "    num_training_steps = cfg.NUM_EPOCHS * math.ceil(len(train_loader) / cfg.GRAD_ACCUM_STEPS)\n",
                                     "    num_warmup_steps = int(num_training_steps * cfg.WARMUP_RATIO)\n",
                                     "    \n",
                                     "    if cfg.USE_COSINE_SCHEDULE:\n",
                                     "        scheduler = get_cosine_schedule_with_warmup(\n",
                                     "            optimizer, num_warmup_steps, num_training_steps\n",
                                     "        )\n",
                                     "    else:\n",
                                     "        scheduler = get_linear_schedule_with_warmup(\n",
                                     "            optimizer, num_warmup_steps, num_training_steps\n",
                                     "        )\n",
                                     "    \n",
                                     "    # AMP Scaler\n",
                                     "    scaler = torch.amp.GradScaler(\u0027cuda\u0027, enabled=cfg.USE_AMP)\n",
                                     "    \n",
                                     "    # EMA\n",
                                     "    ema = EMA(model, decay=cfg.EMA_DECAY) if cfg.USE_EMA else None\n",
                                     "    \n",
                                     "    # SWA\n",
                                     "    swa_model = None\n",
                                     "    if cfg.USE_SWA:\n",
                                     "        swa_model = AveragedModel(model)\n",
                                     "        swa_scheduler = SWALR(optimizer, swa_lr=cfg.LEARNING_RATE * 0.1)\n",
                                     "    \n",
                                     "    # 학습 루프\n",
                                     "    global_step = 0\n",
                                     "    best_val_loss = float(\u0027inf\u0027)\n",
                                     "    \n",
                                     "    for epoch in range(cfg.NUM_EPOCHS):\n",
                                     "        model.train()\n",
                                     "        running_loss = 0.0\n",
                                     "        \n",
                                     "        progress_bar = tqdm(\n",
                                     "            train_loader,\n",
                                     "            desc=f\"Epoch {epoch+1}/{cfg.NUM_EPOCHS} [train]\",\n",
                                     "            unit=\"batch\"\n",
                                     "        )\n",
                                     "        \n",
                                     "        for step, batch in enumerate(progress_bar, start=1):\n",
                                     "            batch = {k: v.to(device) for k, v in batch.items()}\n",
                                     "            \n",
                                     "            # Forward with AMP\n",
                                     "            with torch.amp.autocast(\u0027cuda\u0027, enabled=cfg.USE_AMP, dtype=torch.float16):\n",
                                     "                outputs = model(**batch)\n",
                                     "                loss = outputs.loss / cfg.GRAD_ACCUM_STEPS\n",
                                     "            \n",
                                     "            # Backward\n",
                                     "            scaler.scale(loss).backward()\n",
                                     "            running_loss += loss.item()\n",
                                     "            \n",
                                     "            # Gradient accumulation\n",
                                     "            if step % cfg.GRAD_ACCUM_STEPS == 0:\n",
                                     "                # Gradient clipping\n",
                                     "                scaler.unscale_(optimizer)\n",
                                     "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.MAX_GRAD_NORM)\n",
                                     "                \n",
                                     "                # Optimizer step\n",
                                     "                scaler.step(optimizer)\n",
                                     "                scaler.update()\n",
                                     "                optimizer.zero_grad(set_to_none=True)\n",
                                     "                \n",
                                     "                # Scheduler step\n",
                                     "                if cfg.USE_SWA and epoch \u003e= cfg.SWA_START_EPOCH:\n",
                                     "                    swa_scheduler.step()\n",
                                     "                else:\n",
                                     "                    scheduler.step()\n",
                                     "                \n",
                                     "                # EMA update\n",
                                     "                if cfg.USE_EMA and ema is not None:\n",
                                     "                    ema.update()\n",
                                     "                \n",
                                     "                global_step += 1\n",
                                     "                \n",
                                     "                # Progress\n",
                                     "                avg_loss = running_loss / cfg.GRAD_ACCUM_STEPS\n",
                                     "                progress_bar.set_postfix({\n",
                                     "                    \"loss\": f\"{avg_loss:.4f}\",\n",
                                     "                    \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
                                     "                })\n",
                                     "                running_loss = 0.0\n",
                                     "        \n",
                                     "        # SWA model update\n",
                                     "        if cfg.USE_SWA and swa_model is not None and epoch \u003e= cfg.SWA_START_EPOCH:\n",
                                     "            swa_model.update_parameters(model)\n",
                                     "        \n",
                                     "        # Validation\n",
                                     "        if cfg.USE_EMA and ema is not None:\n",
                                     "            ema.apply_shadow()\n",
                                     "        \n",
                                     "        val_loss = validate(model, valid_loader)\n",
                                     "        \n",
                                     "        if cfg.USE_EMA and ema is not None:\n",
                                     "            ema.restore()\n",
                                     "        \n",
                                     "        print(f\"[Epoch {epoch+1}] Valid Loss: {val_loss:.4f}\")\n",
                                     "        \n",
                                     "        # Best model 저장\n",
                                     "        if val_loss \u003c best_val_loss:\n",
                                     "            best_val_loss = val_loss\n",
                                     "            save_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
                                     "            os.makedirs(save_path, exist_ok=True)\n",
                                     "            \n",
                                     "            if cfg.USE_EMA and ema is not None:\n",
                                     "                ema.apply_shadow()\n",
                                     "            \n",
                                     "            model.save_pretrained(save_path)\n",
                                     "            processor.save_pretrained(save_path)\n",
                                     "            \n",
                                     "            if cfg.USE_EMA and ema is not None:\n",
                                     "                ema.restore()\n",
                                     "            \n",
                                     "            print(f\"   ✅ Best model saved to {save_path}\")\n",
                                     "    \n",
                                     "    # SWA 최종 모델\n",
                                     "    if cfg.USE_SWA and swa_model is not None:\n",
                                     "        torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n",
                                     "        save_path = f\"{cfg.SAVE_DIR}/fold{fold}_swa\"\n",
                                     "        os.makedirs(save_path, exist_ok=True)\n",
                                     "        swa_model.module.save_pretrained(save_path)\n",
                                     "        processor.save_pretrained(save_path)\n",
                                     "        print(f\"   ✅ SWA model saved to {save_path}\")\n",
                                     "    \n",
                                     "    return best_val_loss\n",
                                     "\n",
                                     "\n",
                                     "def validate(model, valid_loader):\n",
                                     "    \"\"\"Validation\"\"\"\n",
                                     "    model.eval()\n",
                                     "    total_loss = 0.0\n",
                                     "    \n",
                                     "    with torch.no_grad():\n",
                                     "        for batch in tqdm(valid_loader, desc=\"Validating\", leave=False):\n",
                                     "            batch = {k: v.to(device) for k, v in batch.items()}\n",
                                     "            \n",
                                     "            with torch.amp.autocast(\u0027cuda\u0027, enabled=cfg.USE_AMP, dtype=torch.float16):\n",
                                     "                outputs = model(**batch)\n",
                                     "                total_loss += outputs.loss.item()\n",
                                     "    \n",
                                     "    model.train()\n",
                                     "    return total_loss / len(valid_loader)\n",
                                     "\n",
                                     "\n",
                                     "print(\"✅ Training functions 정의 완료\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🚀 9. 실제 학습 실행\n",
                                     "\n",
                                     "K-Fold 또는 단일 모델 학습을 실행합니다."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# K-Fold 학습\n",
                                     "if cfg.USE_KFOLD:\n",
                                     "    results = {}\n",
                                     "    \n",
                                     "    for fold in cfg.TRAIN_FOLDS:\n",
                                     "        print(f\"\\n{\u0027#\u0027*60}\")\n",
                                     "        print(f\"Starting Fold {fold}/{cfg.N_FOLDS-1}\")\n",
                                     "        print(f\"{\u0027#\u0027*60}\")\n",
                                     "        \n",
                                     "        # 데이터 분할\n",
                                     "        train_subset = train_df[train_df[\u0027fold\u0027] != fold].reset_index(drop=True)\n",
                                     "        valid_subset = train_df[train_df[\u0027fold\u0027] == fold].reset_index(drop=True)\n",
                                     "        \n",
                                     "        print(f\"Train: {len(train_subset)}, Valid: {len(valid_subset)}\")\n",
                                     "        \n",
                                     "        # Dataset\n",
                                     "        train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
                                     "        valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
                                     "        \n",
                                     "        # DataLoader\n",
                                     "        train_loader = DataLoader(\n",
                                     "            train_ds,\n",
                                     "            batch_size=cfg.BATCH_SIZE,\n",
                                     "            shuffle=True,\n",
                                     "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
                                     "            num_workers=0\n",
                                     "        )\n",
                                     "        valid_loader = DataLoader(\n",
                                     "            valid_ds,\n",
                                     "            batch_size=cfg.BATCH_SIZE,\n",
                                     "            shuffle=False,\n",
                                     "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
                                     "            num_workers=0\n",
                                     "        )\n",
                                     "        \n",
                                     "        # 학습\n",
                                     "        best_loss = train_one_fold(model, train_loader, valid_loader, fold=fold)\n",
                                     "        results[fold] = best_loss\n",
                                     "        \n",
                                     "        print(f\"\\n✅ Fold {fold} 완료: Best Val Loss = {best_loss:.4f}\")\n",
                                     "    \n",
                                     "    print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "    print(\"All Folds Training Complete!\")\n",
                                     "    print(f\"{\u0027=\u0027*60}\")\n",
                                     "    for fold, loss in results.items():\n",
                                     "        print(f\"Fold {fold}: {loss:.4f}\")\n",
                                     "    print(f\"Average: {np.mean(list(results.values())):.4f}\")\n",
                                     "\n",
                                     "else:\n",
                                     "    # 단일 모델 학습\n",
                                     "    train_subset = train_df[train_df[\u0027fold\u0027] == -1].reset_index(drop=True)\n",
                                     "    valid_subset = train_df[train_df[\u0027fold\u0027] == 0].reset_index(drop=True)\n",
                                     "    \n",
                                     "    train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
                                     "    valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
                                     "    \n",
                                     "    train_loader = DataLoader(\n",
                                     "        train_ds,\n",
                                     "        batch_size=cfg.BATCH_SIZE,\n",
                                     "        shuffle=True,\n",
                                     "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
                                     "        num_workers=0\n",
                                     "    )\n",
                                     "    valid_loader = DataLoader(\n",
                                     "        valid_ds,\n",
                                     "        batch_size=cfg.BATCH_SIZE,\n",
                                     "        shuffle=False,\n",
                                     "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
                                     "        num_workers=0\n",
                                     "    )\n",
                                     "    \n",
                                     "    best_loss = train_one_fold(model, train_loader, valid_loader, fold=0)\n",
                                     "    print(f\"\\n✅ Single model 학습 완료: Best Val Loss = {best_loss:.4f}\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🔮 10. Inference with TTA\n",
                                     "\n",
                                     "Test-Time Augmentation을 활용한 추론을 수행합니다."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import re\n",
                                     "\n",
                                     "def extract_choice(text: str) -\u003e str:\n",
                                     "    \"\"\"모델 출력에서 a/b/c/d 중 하나를 안정적으로 추출\"\"\"\n",
                                     "    t = (text or \u0027\u0027).strip().lower()\n",
                                     "    t = re.sub(r\u0027[^a-d\\n ]\u0027, \u0027 \u0027, t)\n",
                                     "    # 줄 단위로 마지막 토큰 우선\n",
                                     "    lines = [l.strip() for l in t.splitlines() if l.strip()]\n",
                                     "    if lines:\n",
                                     "        last = lines[-1].split()[-1]\n",
                                     "        if last in [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]:\n",
                                     "            return last\n",
                                     "    # 전역 스캔\n",
                                     "    for tok in t.split():\n",
                                     "        if tok in [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]:\n",
                                     "            return tok\n",
                                     "    return \u0027a\u0027\n",
                                     "\n",
                                     "\n",
                                     "def infer_single_fold(model_path, test_df, output_path):\n",
                                     "    \"\"\"단일 Fold 추론 (Direct logits + TTA + 확률 출력)\"\"\"\n",
                                     "    # 모델 로드\n",
                                     "    if cfg.USE_ADVANCED_MODEL:\n",
                                     "        model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
                                     "            model_path,\n",
                                     "            trust_remote_code=True,\n",
                                     "            torch_dtype=torch.float16\n",
                                     "        )\n",
                                     "    else:\n",
                                     "        model_infer = AutoModelForVision2Seq.from_pretrained(\n",
                                     "            model_path,\n",
                                     "            trust_remote_code=True,\n",
                                     "            torch_dtype=torch.float16\n",
                                     "        )\n",
                                     "    model_infer = model_infer.to(device)\n",
                                     "\n",
                                     "    processor_infer = AutoProcessor.from_pretrained(\n",
                                     "        model_path,\n",
                                     "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
                                     "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
                                     "        trust_remote_code=True,\n",
                                     "    )\n",
                                     "\n",
                                     "    # pad_token_id 보정\n",
                                     "    try:\n",
                                     "        if getattr(model_infer.config, \u0027pad_token_id\u0027, None) is None:\n",
                                     "            model_infer.config.pad_token_id = model_infer.config.eos_token_id\n",
                                     "    except Exception:\n",
                                     "        pass\n",
                                     "\n",
                                     "    def _choice_token_sets(tokenizer):\n",
                                     "        mapping = {}\n",
                                     "        choices = [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]\n",
                                     "        forms = [\u0027{c}\u0027, \u0027 {c}\u0027, \u0027({c})\u0027, \u0027{c})\u0027, \u0027{c}.\u0027, \u0027[{c}]\u0027, \u0027: {c}\u0027, \u0027{c}:\u0027]\n",
                                     "        for c in choices:\n",
                                     "            s = set()\n",
                                     "            for f in forms:\n",
                                     "                t = f.replace(\u0027{c}\u0027, c)\n",
                                     "                try:\n",
                                     "                    tids = tokenizer.encode(t, add_special_tokens=False)\n",
                                     "                    if len(tids) \u003e 0:\n",
                                     "                        s.add(int(tids[-1]))\n",
                                     "                except Exception:\n",
                                     "                    continue\n",
                                     "            mapping[c] = sorted(list(s))\n",
                                     "        return mapping\n",
                                     "\n",
                                     "    choice_token_ids = _choice_token_sets(processor_infer.tokenizer)\n",
                                     "\n",
                                     "    model_infer.eval()\n",
                                     "\n",
                                     "    predictions = []\n",
                                     "    probs_accumulator = { \u0027a\u0027: [], \u0027b\u0027: [], \u0027c\u0027: [], \u0027d\u0027: [] }\n",
                                     "\n",
                                     "    for i in tqdm(range(len(test_df)), desc=\u0027Inference\u0027):\n",
                                     "        row = test_df.iloc[i]\n",
                                     "\n",
                                     "        # 이미지 로드\n",
                                     "        img_path = os.path.join(cfg.DATA_DIR, row[\u0027path\u0027])\n",
                                     "        try:\n",
                                     "            img = Image.open(img_path).convert(\u0027RGB\u0027)\n",
                                     "        except Exception:\n",
                                     "            img = Image.new(\u0027RGB\u0027, (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color=\u0027white\u0027)\n",
                                     "\n",
                                     "        # 프롬프트 생성\n",
                                     "        user_text = build_mc_prompt(\n",
                                     "            str(row[\u0027question\u0027]), str(row[\u0027a\u0027]), str(row[\u0027b\u0027]), str(row[\u0027c\u0027]), str(row[\u0027d\u0027])\n",
                                     "        )\n",
                                     "        messages = [\n",
                                     "            {\u0027role\u0027: \u0027system\u0027, \u0027content\u0027: [{\u0027type\u0027: \u0027text\u0027, \u0027text\u0027: cfg.SYSTEM_INSTRUCT}]},\n",
                                     "            {\u0027role\u0027: \u0027user\u0027, \u0027content\u0027: [\n",
                                     "                {\u0027type\u0027: \u0027image\u0027, \u0027image\u0027: img},\n",
                                     "                {\u0027type\u0027: \u0027text\u0027, \u0027text\u0027: user_text}\n",
                                     "            ]}\n",
                                     "        ]\n",
                                     "        text = processor_infer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
                                     "\n",
                                     "        if cfg.USE_DIRECT_LOGIT_DECODE:\n",
                                     "            # Direct logits 분류 + (옵션) TTA 평균\n",
                                     "            probs_letters = {\u0027a\u0027: [], \u0027b\u0027: [], \u0027c\u0027: [], \u0027d\u0027: []}\n",
                                     "            with torch.no_grad():\n",
                                     "                scales = cfg.TTA_SCALES if cfg.USE_TTA else [1.0]\n",
                                     "                for s in scales:\n",
                                     "                    if abs(s - 1.0) \u003e 1e-6:\n",
                                     "                        try:\n",
                                     "                            w, h = img.size\n",
                                     "                            img_s = img.resize((max(1,int(round(w*s))), max(1,int(round(h*s)))), resample=Image.BICUBIC)\n",
                                     "                        except Exception:\n",
                                     "                            img_s = img\n",
                                     "                    else:\n",
                                     "                        img_s = img\n",
                                     "                    inputs = processor_infer(text=[text], images=[img_s], return_tensors=\u0027pt\u0027).to(device)\n",
                                     "                    outputs = model_infer(**inputs)\n",
                                     "                    logits = outputs.logits[:, -1, :]\n",
                                     "                    p = torch.softmax(logits, dim=-1)[0]\n",
                                     "                    for k, id_list in choice_token_ids.items():\n",
                                     "                        probs_letters[k].append(float(p[id_list].sum().item()) if len(id_list)\u003e0 else 0.0)\n",
                                     "            avg_probs = {k: (sum(v)/len(v) if len(v)\u003e0 else 0.0) for k,v in probs_letters.items()}\n",
                                     "            best = max(avg_probs.items(), key=lambda x: x[1])[0]\n",
                                     "            predictions.append(best)\n",
                                     "            for k in [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]:\n",
                                     "                probs_accumulator[k].append(avg_probs.get(k, 0.0))\n",
                                     "        else:\n",
                                     "            # Fallback: 자유 생성 후 후처리 추출\n",
                                     "            inputs = processor_infer(text=[text], images=[img], return_tensors=\u0027pt\u0027).to(device)\n",
                                     "            with torch.no_grad():\n",
                                     "                out_ids = model_infer.generate(\n",
                                     "                    **inputs,\n",
                                     "                    max_new_tokens=cfg.MAX_NEW_TOKENS,\n",
                                     "                    do_sample=cfg.DO_SAMPLE,\n",
                                     "                    temperature=cfg.TEMPERATURE if cfg.DO_SAMPLE else None,\n",
                                     "                    eos_token_id=processor_infer.tokenizer.eos_token_id\n",
                                     "                )\n",
                                     "            output_text = processor_infer.batch_decode(out_ids, skip_special_tokens=True)[0]\n",
                                     "            ans = extract_choice(output_text)\n",
                                     "            predictions.append(ans)\n",
                                     "            for k in [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]:\n",
                                     "                probs_accumulator[k].append(0.0)\n",
                                     "\n",
                                     "    # 저장\n",
                                     "    submission = pd.DataFrame({\n",
                                     "        \u0027id\u0027: test_df[\u0027id\u0027],\n",
                                     "        \u0027answer\u0027: predictions,\n",
                                     "        \u0027prob_a\u0027: probs_accumulator.get(\u0027a\u0027, []),\n",
                                     "        \u0027prob_b\u0027: probs_accumulator.get(\u0027b\u0027, []),\n",
                                     "        \u0027prob_c\u0027: probs_accumulator.get(\u0027c\u0027, []),\n",
                                     "        \u0027prob_d\u0027: probs_accumulator.get(\u0027d\u0027, [])\n",
                                     "    })\n",
                                     "\n",
                                     "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
                                     "    submission.to_csv(output_path, index=False)\n",
                                     "    print(f\u0027✅ Saved to {output_path}\u0027)\n",
                                     "    return submission\n",
                                     "\n",
                                     "\n",
                                     "# 전체 Fold 추론 실행\n",
                                     "predictions_all = []\n",
                                     "if cfg.USE_KFOLD:\n",
                                     "    for fold in cfg.TRAIN_FOLDS:\n",
                                     "        model_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
                                     "        output_path = f\"{cfg.OUTPUT_DIR}/submission_fold{fold}.csv\"\n",
                                     "        print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "        print(f\"Inferencing Fold {fold}\")\n",
                                     "        print(f\"{\u0027=\u0027*60}\")\n",
                                     "        pred = infer_single_fold(model_path, test_df, output_path)\n",
                                     "        predictions_all.append(pred)\n",
                                     "else:\n",
                                     "    model_path = f\"{cfg.SAVE_DIR}/fold0_best\"\n",
                                     "    output_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n",
                                     "    pred = infer_single_fold(model_path, test_df, output_path)\n",
                                     "    predictions_all.append(pred)\n",
                                     "\n",
                                     "print(\u0027\\n✅ All inference complete!\u0027)\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🎯 11. Ensemble\n",
                                     "\n",
                                     "여러 Fold의 예측을 앙상블합니다."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "if cfg.USE_KFOLD and len(predictions_all) \u003e 1:\n",
                                     "    print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "    print(\"Ensemble (Probability Average if available)\")\n",
                                     "    print(f\"{\u0027=\u0027*60}\")\n",
                                     "\n",
                                     "    if cfg.ENSEMBLE_METHOD == \u0027prob\u0027 and all(set([\u0027prob_a\u0027,\u0027prob_b\u0027,\u0027prob_c\u0027,\u0027prob_d\u0027]).issubset(set(df.columns)) for df in predictions_all):\n",
                                     "        pa = sum(df[\u0027prob_a\u0027].values for df in predictions_all) / len(predictions_all)\n",
                                     "        pb = sum(df[\u0027prob_b\u0027].values for df in predictions_all) / len(predictions_all)\n",
                                     "        pc = sum(df[\u0027prob_c\u0027].values for df in predictions_all) / len(predictions_all)\n",
                                     "        pd_ = sum(df[\u0027prob_d\u0027].values for df in predictions_all) / len(predictions_all)\n",
                                     "        letters = np.array([\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027])\n",
                                     "        probs_mat = np.vstack([pa, pb, pc, pd_]).T\n",
                                     "        ensemble_preds = letters[probs_mat.argmax(axis=1)].tolist()\n",
                                     "    else:\n",
                                     "        # Majority Voting fallback\n",
                                     "        ensemble_preds = []\n",
                                     "        for i in range(len(test_df)):\n",
                                     "            votes = [pred.iloc[i][\u0027answer\u0027] for pred in predictions_all]\n",
                                     "            most_common = Counter(votes).most_common(1)[0][0]\n",
                                     "            ensemble_preds.append(most_common)\n",
                                     "\n",
                                     "    # 최종 제출 파일 생성\n",
                                     "    final_submission = pd.DataFrame({\n",
                                     "        \u0027id\u0027: test_df[\u0027id\u0027],\n",
                                     "        \u0027answer\u0027: ensemble_preds\n",
                                     "    })\n",
                                     "    final_path = f\"{cfg.OUTPUT_DIR}/submission_ensemble.csv\"\n",
                                     "    final_submission.to_csv(final_path, index=False)\n",
                                     "    print(f\"✅ Ensemble submission saved to {final_path}\")\n",
                                     "    print(\"\\nAnswer Distribution:\")\n",
                                     "    print(final_submission[\u0027answer\u0027].value_counts().sort_index())\n",
                                     "else:\n",
                                     "    print(\"\\nℹ️ Single model - No ensemble needed\")\n",
                                     "    final_submission = predictions_all[0]\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 📊 12. 결과 분석 및 시각화"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# 답변 분포 시각화\n",
                                     "fig, ax = plt.subplots(figsize=(10, 5))\n",
                                     "\n",
                                     "answer_counts = final_submission[\u0027answer\u0027].value_counts().sort_index()\n",
                                     "sns.barplot(x=answer_counts.index, y=answer_counts.values, palette=\u0027viridis\u0027, ax=ax)\n",
                                     "ax.set_title(\u0027Final Submission Answer Distribution\u0027, fontsize=14, weight=\u0027bold\u0027)\n",
                                     "ax.set_xlabel(\u0027Answer\u0027)\n",
                                     "ax.set_ylabel(\u0027Count\u0027)\n",
                                     "ax.grid(axis=\u0027y\u0027, alpha=0.3)\n",
                                     "\n",
                                     "# 비율 표시\n",
                                     "for i, (ans, count) in enumerate(answer_counts.items()):\n",
                                     "    percentage = count / len(final_submission) * 100\n",
                                     "    ax.text(i, count + 10, f\"{percentage:.1f}%\", ha=\u0027center\u0027, fontsize=10)\n",
                                     "\n",
                                     "plt.tight_layout()\n",
                                     "plt.show()\n",
                                     "\n",
                                     "# 통계 출력\n",
                                     "print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "print(\"Final Statistics\")\n",
                                     "print(f\"{\u0027=\u0027*60}\")\n",
                                     "print(f\"Total predictions: {len(final_submission)}\")\n",
                                     "print(f\"\\nAnswer counts:\")\n",
                                     "for ans, count in answer_counts.items():\n",
                                     "    print(f\"  {ans}: {count:5d} ({count/len(final_submission)*100:5.1f}%)\")\n",
                                     "\n",
                                     "# 제출 파일 샘플\n",
                                     "print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "print(\"Sample Predictions\")\n",
                                     "print(f\"{\u0027=\u0027*60}\")\n",
                                     "print(final_submission.head(10))"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ✅ 13. 최종 정리\n",
                                     "\n",
                                     "### 🎉 완료된 작업\n",
                                     "\n",
                                     "1. ✅ **환경 설정** - 패키지 설치 및 임포트\n",
                                     "2. ✅ **Config** - 하이퍼파라미터 통합 관리\n",
                                     "3. ✅ **데이터 로드 \u0026 EDA** - 탐색적 분석\n",
                                     "4. ✅ **Stratified K-Fold** - CV Splits 생성\n",
                                     "5. ✅ **Dataset \u0026 DataLoader** - 라벨 정렬 교정 적용\n",
                                     "6. ✅ **Model \u0026 Processor** - QLoRA 모델 로드 (T4 호환)\n",
                                     "7. ✅ **Training Loop** - AMP, EMA, SWA, Cosine Warmup 적용\n",
                                     "8. ✅ **Inference** - TTA 지원 추론\n",
                                     "9. ✅ **Ensemble** - Majority Voting\n",
                                     "10. ✅ **Results** - 시각화 및 통계\n",
                                     "\n",
                                     "### 🚀 다음 단계\n",
                                     "\n",
                                     "1. **하이퍼파라미터 튜닝**\n",
                                     "   - Learning rate, LoRA rank 조정\n",
                                     "   - Batch size, Grad accumulation 최적화\n",
                                     "\n",
                                     "2. **모델 크기 확대**\n",
                                     "   - 7B 모델 사용 (더 높은 정확도)\n",
                                     "   - Image size 증가 (512, 768)\n",
                                     "\n",
                                     "3. **고급 기법 활성화**\n",
                                     "   - TTA scales 추가\n",
                                     "   - SWA 적용\n",
                                     "   - 데이터 증강 활성화\n",
                                     "\n",
                                     "4. **에폭 증가**\n",
                                     "   - NUM_EPOCHS = 3~5\n",
                                     "\n",
                                     "### 📌 Important Notes\n",
                                     "\n",
                                     "- **T4 호환**: Float16, SDPA attention 사용\n",
                                     "- **라벨 정렬**: Assistant 메시지에 정답 포함 (핵심!)\n",
                                     "- **재현성**: Seed 42 고정\n",
                                     "- **메모리**: Gradient checkpointing, 4-bit QLoRA\n",
                                     "\n",
                                     "---\n",
                                     "\n",
                                     "**🤖 Generated for SSAFY AI Project 2025**\n",
                                     "\n",
                                     "**📧 Contact**: GitHub Issues\n",
                                     "\n",
                                     "**⭐ 행운을 빕니다!**"
                                 ]
                  }
              ],
    "metadata":  {
                     "kernelspec":  {
                                        "display_name":  "Python 3",
                                        "language":  "python",
                                        "name":  "python3"
                                    },
                     "language_info":  {
                                           "codemirror_mode":  {
                                                                   "name":  "ipython",
                                                                   "version":  3
                                                               },
                                           "file_extension":  ".py",
                                           "mimetype":  "text/x-python",
                                           "name":  "python",
                                           "nbconvert_exporter":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.8.10"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  4
}
