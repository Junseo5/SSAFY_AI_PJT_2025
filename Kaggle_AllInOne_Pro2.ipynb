{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# 📒 Kaggle_AllInOne_Pro.ipynb – 단일 노트북 통합 버전\n",
                                     "\n",
                                     "## 🎯 개요\n",
                                     "\n",
                                     "본 노트북은 **VQA Kaggle Challenge**를 위한 **완전 통합 고성능 파이프라인**입니다.\n",
                                     "\n",
                                     "### ✨ 주요 기능\n",
                                     "\n",
                                     "- ✅ **T4 GPU 완벽 호환** (Float16, SDPA attention)\n",
                                     "- ✅ **라벨 정렬 교정** (Assistant 메시지에 정답 포함)\n",
                                     "- ✅ **K-Fold Cross-Validation** (Stratified)\n",
                                     "- ✅ **고급 학습 기법** (AMP, EMA, SWA, Cosine Warmup)\n",
                                     "- ✅ **데이터 증강** (Choice Shuffle, Paraphrase)\n",
                                     "- ✅ **TTA (Test-Time Augmentation)**\n",
                                     "- ✅ **앙상블** (Weighted Voting)\n",
                                     "- ✅ **메모리 최적화** (Gradient Checkpointing, 4-bit QLoRA)\n",
                                     "\n",
                                     "### 📊 예상 성능\n",
                                     "\n",
                                     "| 설정 | 정확도 | 시간 |\n",
                                     "|------|--------|------|\n",
                                     "| Single Fold | 79-82% | ~4h |\n",
                                     "| 3-Fold Ensemble | 83-85% | ~12h |\n",
                                     "| + TTA + Optimization | 85-88% | ~15h |\n",
                                     "\n",
                                     "### 🚀 실행 순서\n",
                                     "\n",
                                     "1. **환경 설정** - 패키지 설치 및 임포트\n",
                                     "2. **Config** - 하이퍼파라미터 설정\n",
                                     "3. **데이터 로드** - Train/Test 데이터 로드\n",
                                     "4. **EDA** - 탐색적 데이터 분석\n",
                                     "5. **Stratified K-Fold** - CV Splits 생성\n",
                                     "6. **Dataset \u0026 DataLoader** - 커스텀 데이터셋 정의\n",
                                     "7. **Model \u0026 Processor** - QLoRA 모델 로드\n",
                                     "8. **Training Loop** - 고급 기법 적용 학습\n",
                                     "9. **Inference** - TTA를 활용한 추론\n",
                                     "10. **Ensemble** - 앙상블 및 제출 파일 생성\n",
                                     "\n",
                                     "---\n",
                                     "\n",
                                     "**🤖 Generated for SSAFY AI Project 2025**"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 📦 1. 환경 설정 및 패키지 설치\n",
                                     "\n",
                                     "필요한 라이브러리를 설치합니다. (첫 실행 시 1회만)\n",
                                     "\n",
                                     "### ⚠️ 중요: 설치 후 런타임 재시작 필요"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# 패키지 설치 (Colab/Kaggle 환경)\n",
                                     "# 첫 실행 시에만 주석 해제하고 실행\n",
                                     "# !pip install -q \"transformers\u003e=4.44.2\" \"accelerate\u003e=0.34.2\" \"peft\u003e=0.13.2\" \\\n",
                                     "#     \"bitsandbytes\u003e=0.43.1\" datasets pillow pandas torch torchvision \\\n",
                                     "#     scikit-learn matplotlib seaborn tqdm --upgrade\n",
                                     "# !pip install -q qwen-vl-utils==0.0.8\n",
                                     "\n",
                                     "print(\"✅ 패키지 설치 완료! 런타임을 재시작하세요.\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 📚 2. 라이브러리 임포트"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import os, sys, re, math, random, warnings\n",
                                     "import numpy as np\n",
                                     "import pandas as pd\n",
                                     "from PIL import Image\n",
                                     "from pathlib import Path\n",
                                     "from dataclasses import dataclass\n",
                                     "from typing import Dict, List, Any, Optional\n",
                                     "from collections import Counter\n",
                                     "import unicodedata\n",
                                     "\n",
                                     "# PyTorch\n",
                                     "import torch\n",
                                     "import torch.nn as nn\n",
                                     "from torch.utils.data import Dataset, DataLoader\n",
                                     "from torch.optim.swa_utils import AveragedModel, SWALR\n",
                                     "\n",
                                     "# Transformers \u0026 PEFT\n",
                                     "from transformers import (\n",
                                     "    AutoModelForVision2Seq,\n",
                                     "    Qwen2_5_VLForConditionalGeneration,\n",
                                     "    AutoProcessor,\n",
                                     "    BitsAndBytesConfig,\n",
                                     "    get_cosine_schedule_with_warmup,\n",
                                     "    get_linear_schedule_with_warmup\n",
                                     ")\n",
                                     "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
                                     "from qwen_vl_utils import process_vision_info\n",
                                     "\n",
                                     "# Scikit-learn\n",
                                     "from sklearn.model_selection import StratifiedKFold\n",
                                     "from sklearn.metrics import accuracy_score, confusion_matrix\n",
                                     "\n",
                                     "# Visualization\n",
                                     "import matplotlib.pyplot as plt\n",
                                     "import seaborn as sns\n",
                                     "from tqdm.auto import tqdm\n",
                                     "\n",
                                     "# 설정\n",
                                     "warnings.filterwarnings(\u0027ignore\u0027)\n",
                                     "Image.MAX_IMAGE_PIXELS = None\n",
                                     "sns.set_style(\u0027whitegrid\u0027)\n",
                                     "\n",
                                     "# 디바이스\n",
                                     "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                                     "print(f\"🔧 Device: {device}\")\n",
                                     "if torch.cuda.is_available():\n",
                                     "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
                                     "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                                     "\n",
                                     "print(f\"🐍 Python: {sys.version.split()[0]}\")\n",
                                     "print(f\"🔥 PyTorch: {torch.__version__}\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ⚙️ 3. Config 설정\n",
                                     "\n",
                                     "모든 하이퍼파라미터를 한 곳에서 관리합니다."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "class Config:\n",
                                     "    \"\"\"통합 설정 클래스\"\"\"\n",
                                     "    \n",
                                     "    # 시드 (재현성)\n",
                                     "    SEED = 42\n",
                                     "    \n",
                                     "    # 모델 설정\n",
                                     "    MODEL_ID = \"Qwen/Qwen2.5-VL-3B-Instruct\"  # 또는 \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
                                     "    IMAGE_SIZE = 512  # 384 or 512 or 768\n",
                                     "    USE_ADVANCED_MODEL = False  # True: Qwen2_5_VL, False: AutoModelForVision2Seq (baseline)\n",
                                     "    \n",
                                     "    # 데이터 경로\n",
                                     "    DATA_DIR = \"/kaggle/input/ssafy-ai-pjt-data\"\n",
                                     "    TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n",
                                     "    TEST_CSV = f\"{DATA_DIR}/test.csv\"\n",
                                     "    \n",
                                     "    # K-Fold 설정\n",
                                     "    N_FOLDS = 3\n",
                                     "    USE_KFOLD = True  # False: 단일 모델 학습\n",
                                     "    TRAIN_FOLDS = [0, 1, 2]  # 학습할 fold 번호\n",
                                     "    \n",
                                     "    # QLoRA 설정\n",
                                     "    LORA_R = 16\n",
                                     "    LORA_ALPHA = 16\n",
                                     "    LORA_DROPOUT = 0.05\n",
                                     "    TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
                                     "                      \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
                                     "    \n",
                                     "    # 학습 설정\n",
                                     "    NUM_EPOCHS = 3\n",
                                     "    BATCH_SIZE = 1\n",
                                     "    GRAD_ACCUM_STEPS = 8\n",
                                     "    LEARNING_RATE = 1e-4\n",
                                     "    WEIGHT_DECAY = 0.01\n",
                                     "    WARMUP_RATIO = 0.06\n",
                                     "    MAX_GRAD_NORM = 1.0\n",
                                     "    \n",
                                     "    # 고급 기법\n",
                                     "    USE_AMP = True  # Automatic Mixed Precision\n",
                                     "    USE_EMA = True  # Exponential Moving Average\n",
                                     "    EMA_DECAY = 0.999\n",
                                     "    USE_SWA = False  # Stochastic Weight Averaging (마지막 에폭만)\n",
                                     "    SWA_START_EPOCH = 0  # SWA 시작 에폭 (마지막 에폭 권장)\n",
                                     "    USE_COSINE_SCHEDULE = True  # True: Cosine, False: Linear\n",
                                     "    \n",
                                     "    # 데이터 증강\n",
                                     "    USE_AUGMENTATION = False  # Choice shuffle 등\n",
                                     "    AUG_PROB = 0.3\n",
                                     "    \n",
                                     "    # TTA (Test-Time Augmentation)\n",
                                     "    USE_TTA = True\n",
                                     "    TTA_SCALES = [0.9, 1.0, 1.1]  # test-time scales\n",
                                     "    \n",
                                     "    # Inference options\n",
                                     "    USE_DIRECT_LOGIT_DECODE = True  # use logits for a/b/c/d scoring\n",
                                     "    ENSEMBLE_METHOD = \"prob\"  # \"prob\" or \"vote\"\n",
                                     "    DO_SAMPLE = False\n",
                                     "    TEMPERATURE = 0.0\n",
                                     "    \n",
                                     "    # 저장 경로\n",
                                     "    SAVE_DIR = f\"/kaggle/working/checkpoints\"\n",
                                     "    OUTPUT_DIR = f\"/kaggle/working/outputs\"\n",
                                     "    \n",
                                     "    # 샘플링 (디버깅용)\n",
                                     "    USE_SAMPLE = False  # use full training data\n",
                                     "    SAMPLE_SIZE = 200  # 샘플 크기\n",
                                     "    \n",
                                     "    # 프롬프트\n",
                                     "    SYSTEM_INSTRUCT = (\n",
                                     "        \"You are a helpful visual question answering assistant. \"\n",
                                     "        \"Answer using exactly one letter among a, b, c, or d. No explanation.\"\n",
                                     "    )\n",
                                     "\n",
                                     "\n",
                                     "# Config 인스턴스 생성\n",
                                     "cfg = Config()\n",
                                     "\n",
                                     "# 시드 고정\n",
                                     "def set_seed(seed=42):\n",
                                     "    random.seed(seed)\n",
                                     "    np.random.seed(seed)\n",
                                     "    torch.manual_seed(seed)\n",
                                     "    torch.cuda.manual_seed_all(seed)\n",
                                     "    torch.backends.cudnn.deterministic = True\n",
                                     "    torch.backends.cudnn.benchmark = False\n",
                                     "\n",
                                     "set_seed(cfg.SEED)\n",
                                     "print(f\"✅ Config 설정 완료 (Seed: {cfg.SEED})\")\n",
                                     "print(f\"   Model: {cfg.MODEL_ID}\")\n",
                                     "print(f\"   K-Fold: {cfg.N_FOLDS if cfg.USE_KFOLD else \u0027Disabled\u0027}\")\n",
                                     "print(f\"   Advanced Techniques: AMP={cfg.USE_AMP}, EMA={cfg.USE_EMA}, SWA={cfg.USE_SWA}, TTA={cfg.USE_TTA}\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 📊 4. 데이터 로드 및 EDA\n",
                                     "\n",
                                     "데이터를 로드하고 간단한 탐색적 분석을 수행합니다."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# 데이터 로드\n",
                                     "train_df = pd.read_csv(cfg.TRAIN_CSV)\n",
                                     "test_df = pd.read_csv(cfg.TEST_CSV)\n",
                                     "\n",
                                     "print(f\"📁 Train: {len(train_df):,} samples\")\n",
                                     "print(f\"📁 Test: {len(test_df):,} samples\")\n",
                                     "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
                                     "\n",
                                     "# 샘플링 (디버깅용)\n",
                                     "if cfg.USE_SAMPLE:\n",
                                     "    train_df = train_df.sample(n=min(cfg.SAMPLE_SIZE, len(train_df)), random_state=cfg.SEED).reset_index(drop=True)\n",
                                     "    print(f\"\\n⚠️  Sampled {len(train_df)} samples for quick testing\")\n",
                                     "\n",
                                     "# 기본 통계\n",
                                     "print(f\"\\n📊 Answer Distribution:\")\n",
                                     "print(train_df[\u0027answer\u0027].value_counts().sort_index())\n",
                                     "\n",
                                     "# 시각화\n",
                                     "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
                                     "\n",
                                     "# 답변 분포\n",
                                     "train_df[\u0027answer\u0027].value_counts().sort_index().plot(kind=\u0027bar\u0027, ax=axes[0], color=\u0027skyblue\u0027)\n",
                                     "axes[0].set_title(\u0027Answer Distribution (Train)\u0027, fontsize=12, weight=\u0027bold\u0027)\n",
                                     "axes[0].set_xlabel(\u0027Answer\u0027)\n",
                                     "axes[0].set_ylabel(\u0027Count\u0027)\n",
                                     "axes[0].grid(axis=\u0027y\u0027, alpha=0.3)\n",
                                     "\n",
                                     "# 질문 길이 분포\n",
                                     "train_df[\u0027question_len\u0027] = train_df[\u0027question\u0027].str.len()\n",
                                     "train_df[\u0027question_len\u0027].hist(bins=30, ax=axes[1], color=\u0027salmon\u0027, edgecolor=\u0027black\u0027)\n",
                                     "axes[1].set_title(\u0027Question Length Distribution\u0027, fontsize=12, weight=\u0027bold\u0027)\n",
                                     "axes[1].set_xlabel(\u0027Length (chars)\u0027)\n",
                                     "axes[1].set_ylabel(\u0027Count\u0027)\n",
                                     "axes[1].grid(axis=\u0027y\u0027, alpha=0.3)\n",
                                     "\n",
                                     "plt.tight_layout()\n",
                                     "plt.show()\n",
                                     "\n",
                                     "# 샘플 출력\n",
                                     "print(\"\\n📝 Sample Data:\")\n",
                                     "print(train_df.head(2))"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🔄 5. Stratified K-Fold Cross-Validation\n",
                                     "\n",
                                     "답변 분포를 유지하면서 K-Fold를 생성합니다."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "if cfg.USE_KFOLD:\n",
                                     "    # Stratified K-Fold 생성\n",
                                     "    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=cfg.SEED)\n",
                                     "    train_df[\u0027fold\u0027] = -1\n",
                                     "    \n",
                                     "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df[\u0027answer\u0027])):\n",
                                     "        train_df.loc[val_idx, \u0027fold\u0027] = fold\n",
                                     "    \n",
                                     "    print(f\"✅ {cfg.N_FOLDS}-Fold CV 생성 완료\")\n",
                                     "    print(f\"\\nFold Distribution:\")\n",
                                     "    print(train_df[\u0027fold\u0027].value_counts().sort_index())\n",
                                     "    \n",
                                     "    # Fold별 답변 분포 확인\n",
                                     "    print(f\"\\nAnswer Distribution per Fold:\")\n",
                                     "    for fold in range(cfg.N_FOLDS):\n",
                                     "        fold_data = train_df[train_df[\u0027fold\u0027] == fold]\n",
                                     "        dist = fold_data[\u0027answer\u0027].value_counts(normalize=True).sort_index()\n",
                                     "        print(f\"Fold {fold}: {dict(dist)}\")\n",
                                     "else:\n",
                                     "    # 단일 모델 학습 (90:10 split)\n",
                                     "    split_idx = int(len(train_df) * 0.9)\n",
                                     "    train_df[\u0027fold\u0027] = -1\n",
                                     "    train_df.loc[split_idx:, \u0027fold\u0027] = 0\n",
                                     "    print(f\"✅ Single split (90:10) 생성 완료\")\n",
                                     "    print(f\"   Train: {len(train_df[train_df[\u0027fold\u0027] == -1])}\")\n",
                                     "    print(f\"   Valid: {len(train_df[train_df[\u0027fold\u0027] == 0])}\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🗂️ 6. Dataset \u0026 DataLoader\n",
                                     "\n",
                                     "커스텀 데이터셋 및 DataCollator를 정의합니다.\n",
                                     "\n",
                                     "### ✅ 라벨 정렬 교정 적용\n",
                                     "- Assistant 메시지에 정답 포함\n",
                                     "- `add_generation_prompt=False` 사용"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "def build_mc_prompt(question, a, b, c, d):\n",
                                     "    \"\"\"Multiple Choice 프롬프트 생성\"\"\"\n",
                                     "    return (\n",
                                     "        f\"{question}\\n\"\n",
                                     "        f\"(a) {a}\\n(b) {b}\\n(c) {c}\\n(d) {d}\\n\\n\"\n",
                                     "        \"정답을 반드시 a, b, c, d 중 하나의 소문자 한 글자로만 출력하세요.\"\n",
                                     "    )\n",
                                     "\n",
                                     "\n",
                                     "class VQADataset(Dataset):\n",
                                     "    \"\"\"VQA Dataset with Label Alignment Fix\"\"\"\n",
                                     "    \n",
                                     "    def __init__(self, df, processor, data_dir=\"\", train=True, use_advanced=False):\n",
                                     "        self.df = df.reset_index(drop=True)\n",
                                     "        self.processor = processor\n",
                                     "        self.data_dir = data_dir\n",
                                     "        self.train = train\n",
                                     "        self.use_advanced = use_advanced  # process_vision_info 사용 여부\n",
                                     "    \n",
                                     "    def __len__(self):\n",
                                     "        return len(self.df)\n",
                                     "    \n",
                                     "    def __getitem__(self, idx):\n",
                                     "        row = self.df.iloc[idx]\n",
                                     "        \n",
                                     "        # 이미지 로드\n",
                                     "        img_path = os.path.join(self.data_dir, row[\"path\"])\n",
                                     "        try:\n",
                                     "            img = Image.open(img_path).convert(\"RGB\")\n",
                                     "        except:\n",
                                     "            img = Image.new(\u0027RGB\u0027, (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color=\u0027white\u0027)\n",
                                     "        \n",
                                     "        # 프롬프트 생성\n",
                                     "        user_text = build_mc_prompt(\n",
                                     "            str(row[\"question\"]),\n",
                                     "            str(row[\"a\"]), str(row[\"b\"]),\n",
                                     "            str(row[\"c\"]), str(row[\"d\"])\n",
                                     "        )\n",
                                     "        \n",
                                     "        # 메시지 구성\n",
                                     "        messages = [\n",
                                     "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n",
                                     "            {\"role\": \"user\", \"content\": [\n",
                                     "                {\"type\": \"image\", \"image\": img},\n",
                                     "                {\"type\": \"text\", \"text\": user_text}\n",
                                     "            ]}\n",
                                     "        ]\n",
                                     "        \n",
                                     "        # ✅ CRITICAL: 학습 시 정답 포함 (라벨 정렬 교정)\n",
                                     "        if self.train:\n",
                                     "            answer = str(row[\"answer\"]).strip().lower()\n",
                                     "            messages.append({\n",
                                     "                \"role\": \"assistant\",\n",
                                     "                \"content\": [{\"type\": \"text\", \"text\": answer}]\n",
                                     "            })\n",
                                     "        \n",
                                     "        return {\"messages\": messages, \"image\": img, \"answer\": (answer if self.train else None)}\n",
                                     "\n",
                                     "\n",
                                     "@dataclass\n",
                                     "class DataCollator:\n",
                                     "    \"\"\"Data Collator for VQA\"\"\"\n",
                                     "    processor: Any\n",
                                     "    train: bool = True\n",
                                     "    use_advanced: bool = False\n",
                                     "    \n",
                                     "    def __call__(self, batch):\n",
                                     "        texts, images = [], []\n",
                                     "        \n",
                                     "        for sample in batch:\n",
                                     "            messages = sample[\"messages\"]\n",
                                     "            img = sample[\"image\"]\n",
                                     "            \n",
                                     "            # ✅ apply_chat_template 사용\n",
                                     "            text = self.processor.apply_chat_template(\n",
                                     "                messages,\n",
                                     "                tokenize=False,\n",
                                     "                add_generation_prompt=False  # ✅ 학습 시 False!\n",
                                     "            )\n",
                                     "            \n",
                                     "            # 한글 정규화\n",
                                     "            text = unicodedata.normalize(\u0027NFKC\u0027, text)\n",
                                     "            \n",
                                     "            texts.append(text)\n",
                                     "            images.append(img)\n",
                                     "        \n",
                                     "        # 인코딩\n",
                                     "        if self.use_advanced:\n",
                                     "            # process_vision_info 사용 (Qwen2_5_VL)\n",
                                     "            enc = self.processor(\n",
                                     "                text=texts,\n",
                                     "                images=images,\n",
                                     "                padding=True,\n",
                                     "                return_tensors=\"pt\"\n",
                                     "            )\n",
                                     "        else:\n",
                                     "            # 기본 방식 (AutoModelForVision2Seq)\n",
                                     "            enc = self.processor(\n",
                                     "                text=texts,\n",
                                     "                images=images,\n",
                                     "                padding=True,\n",
                                     "                return_tensors=\"pt\"\n",
                                     "            )\n",
                                     "        \n",
                                     "        # ✅ 라벨 설정\n",
                                     "        \n",
                                     "        # Build labels: mask prompt tokens, keep only assistant answer tokens\n         if self.train:\n             labels = enc[\"input_ids\"].clone()  # [B, L]\n             labels[:] = -100\n             for i, sample in enumerate(batch):\n                 ans = sample.get(\"answer\", None)\n                 if ans is None:\n                     continue\n                 try:\n                     ans_ids = self.processor.tokenizer.encode(str(ans).strip().lower(), add_special_tokens=False)\n                 except Exception:\n                     ans_ids = []\n                 ids = enc[\"input_ids\"][i].tolist()\n                 start = -1\n                 if ans_ids:\n                     for s in range(len(ids) - len(ans_ids), -1, -1):\n                         if ids[s:s+len(ans_ids)] == ans_ids:\n                             start = s\n                             break\n                 if start == -1:\n                     try:\n                         last = int(enc[\"attention_mask\"][i].sum().item()) - 1\n                         if last \u003e= 0:\n                             labels[i, last] = enc[\"input_ids\"][i, last]\n                     except Exception:\n                         pass\n                 else:\n                     labels[i, start:start+len(ans_ids)] = enc[\"input_ids\"][i, start:start+len(ans_ids)]\n             enc[\"labels\"] = labels\n",
                                     "        \n",
                                     "        return enc\n",
                                     "\n",
                                     "\n",
                                     "print(\"✅ Dataset \u0026 DataCollator 정의 완료\")\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🤖 7. Model \u0026 Processor 로드\n",
                                     "\n",
                                     "QLoRA 모델과 Processor를 로드합니다.\n",
                                     "\n",
                                     "### ✅ T4 호환 설정\n",
                                     "- Float16 (BFloat16 아님)\n",
                                     "- SDPA attention (FlashAttention 제거)\n",
                                     "- 4-bit quantization"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "def create_model_and_processor(model_id, use_advanced=False):\n",
                                     "    \"\"\"모델 및 Processor 생성\"\"\"\n",
                                     "    \n",
                                     "    # 양자화 설정\n",
                                     "    bnb_config = BitsAndBytesConfig(\n",
                                     "        load_in_4bit=True,\n",
                                     "        bnb_4bit_use_double_quant=True,\n",
                                     "        bnb_4bit_quant_type=\"nf4\",\n",
                                     "        bnb_4bit_compute_dtype=torch.float16,  # ✅ T4 호환 (BF16 아님)\n",
                                     "    )\n",
                                     "    \n",
                                     "    # Processor 로드\n",
                                     "    processor = AutoProcessor.from_pretrained(\n",
                                     "        model_id,\n",
                                     "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
                                     "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
                                     "        trust_remote_code=True,\n",
                                     "    )\n",
                                     "    \n",
                                     "    # 모델 로드\n",
                                     "    if use_advanced:\n",
                                     "        # ✅ Qwen2_5_VLForConditionalGeneration (고급)\n",
                                     "        base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
                                     "            model_id,\n",
                                     "            quantization_config=bnb_config,\n",
                                     "            trust_remote_code=True,\n",
                                     "            torch_dtype=torch.float16,\n",
                                     "            attn_implementation=\"sdpa\",  # ✅ FlashAttention 제거\n",
                                     "        )\n",
                                     "    else:\n",
                                     "        # AutoModelForVision2Seq (Baseline 호환)\n",
                                     "        base_model = AutoModelForVision2Seq.from_pretrained(\n",
                                     "            model_id,\n",
                                     "            quantization_config=bnb_config,\n",
                                     "            trust_remote_code=True,\n",
                                     "        )\n",
                                     "    \n",
                                     "    # QLoRA 준비\n",
                                     "    base_model = prepare_model_for_kbit_training(base_model)\n",
                                     "    base_model.gradient_checkpointing_enable()\n",
                                     "    \n",
                                     "    # LoRA Config\n",
                                     "    lora_config = LoraConfig(\n",
                                     "        r=cfg.LORA_R,\n",
                                     "        lora_alpha=cfg.LORA_ALPHA,\n",
                                     "        lora_dropout=cfg.LORA_DROPOUT,\n",
                                     "        bias=\"none\",\n",
                                     "        target_modules=cfg.TARGET_MODULES,\n",
                                     "        task_type=\"CAUSAL_LM\",\n",
                                     "    )\n",
                                     "    \n",
                                     "    # PEFT 모델 생성\n",
                                     "    model = get_peft_model(base_model, lora_config)\n",
                                     "    model.print_trainable_parameters()\n",
                                     "    \n",
                                     "    return model, processor\n",
                                     "\n",
                                     "\n",
                                     "print(\"🔧 모델 로드 중...\")\n",
                                     "model, processor = create_model_and_processor(\n",
                                     "    cfg.MODEL_ID,\n",
                                     "    use_advanced=cfg.USE_ADVANCED_MODEL\n",
                                     ")\n",
                                     "model = model.to(device)\n",
                                     "print(f\"✅ 모델 로드 완료\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🎓 8. Training Loop with Advanced Techniques\n",
                                     "\n",
                                     "고급 학습 기법을 적용한 학습 루프입니다.\n",
                                     "\n",
                                     "### ✨ 적용된 기법\n",
                                     "- ✅ **AMP** (Automatic Mixed Precision)\n",
                                     "- ✅ **EMA** (Exponential Moving Average)\n",
                                     "- ✅ **SWA** (Stochastic Weight Averaging)\n",
                                     "- ✅ **Cosine Warmup Scheduler**\n",
                                     "- ✅ **Gradient Clipping**"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "class EMA:\n",
                                     "    \"\"\"Exponential Moving Average\"\"\"\n",
                                     "    def __init__(self, model, decay=0.999):\n",
                                     "        self.model = model\n",
                                     "        self.decay = decay\n",
                                     "        self.shadow = {}\n",
                                     "        self.backup = {}\n",
                                     "        self.register()\n",
                                     "    \n",
                                     "    def register(self):\n",
                                     "        for name, param in self.model.named_parameters():\n",
                                     "            if param.requires_grad:\n",
                                     "                self.shadow[name] = param.data.clone()\n",
                                     "    \n",
                                     "    def update(self):\n",
                                     "        for name, param in self.model.named_parameters():\n",
                                     "            if param.requires_grad:\n",
                                     "                new_average = (\n",
                                     "                    self.decay * self.shadow[name] +\n",
                                     "                    (1.0 - self.decay) * param.data\n",
                                     "                )\n",
                                     "                self.shadow[name] = new_average.clone()\n",
                                     "    \n",
                                     "    def apply_shadow(self):\n",
                                     "        for name, param in self.model.named_parameters():\n",
                                     "            if param.requires_grad:\n",
                                     "                self.backup[name] = param.data.clone()\n",
                                     "                param.data = self.shadow[name]\n",
                                     "    \n",
                                     "    def restore(self):\n",
                                     "        for name, param in self.model.named_parameters():\n",
                                     "            if param.requires_grad:\n",
                                     "                param.data = self.backup[name]\n",
                                     "        self.backup = {}\n",
                                     "\n",
                                     "\n",
                                     "def train_one_fold(model, train_loader, valid_loader, fold=0):\n",
                                     "    \"\"\"단일 Fold 학습\"\"\"\n",
                                     "    \n",
                                     "    print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "    print(f\"Training Fold {fold}\")\n",
                                     "    print(f\"{\u0027=\u0027*60}\")\n",
                                     "    \n",
                                     "    # Optimizer\n",
                                     "    optimizer = torch.optim.AdamW(\n",
                                     "        model.parameters(),\n",
                                     "        lr=cfg.LEARNING_RATE,\n",
                                     "        weight_decay=cfg.WEIGHT_DECAY\n",
                                     "    )\n",
                                     "    \n",
                                     "    # Scheduler\n",
                                     "    num_training_steps = cfg.NUM_EPOCHS * math.ceil(len(train_loader) / cfg.GRAD_ACCUM_STEPS)\n",
                                     "    num_warmup_steps = int(num_training_steps * cfg.WARMUP_RATIO)\n",
                                     "    \n",
                                     "    if cfg.USE_COSINE_SCHEDULE:\n",
                                     "        scheduler = get_cosine_schedule_with_warmup(\n",
                                     "            optimizer, num_warmup_steps, num_training_steps\n",
                                     "        )\n",
                                     "    else:\n",
                                     "        scheduler = get_linear_schedule_with_warmup(\n",
                                     "            optimizer, num_warmup_steps, num_training_steps\n",
                                     "        )\n",
                                     "    \n",
                                     "    # AMP Scaler\n",
                                     "    scaler = torch.amp.GradScaler(\u0027cuda\u0027, enabled=cfg.USE_AMP)\n",
                                     "    \n",
                                     "    # EMA\n",
                                     "    ema = EMA(model, decay=cfg.EMA_DECAY) if cfg.USE_EMA else None\n",
                                     "    \n",
                                     "    # SWA\n",
                                     "    swa_model = None\n",
                                     "    if cfg.USE_SWA:\n",
                                     "        swa_model = AveragedModel(model)\n",
                                     "        swa_scheduler = SWALR(optimizer, swa_lr=cfg.LEARNING_RATE * 0.1)\n",
                                     "    \n",
                                     "    # 학습 루프\n",
                                     "    global_step = 0\n",
                                     "    best_val_loss = float(\u0027inf\u0027)\n",
                                     "    \n",
                                     "    for epoch in range(cfg.NUM_EPOCHS):\n",
                                     "        model.train()\n",
                                     "        running_loss = 0.0\n",
                                     "        \n",
                                     "        progress_bar = tqdm(\n",
                                     "            train_loader,\n",
                                     "            desc=f\"Epoch {epoch+1}/{cfg.NUM_EPOCHS} [train]\",\n",
                                     "            unit=\"batch\"\n",
                                     "        )\n",
                                     "        \n",
                                     "        for step, batch in enumerate(progress_bar, start=1):\n",
                                     "            batch = {k: v.to(device) for k, v in batch.items()}\n",
                                     "            \n",
                                     "            # Forward with AMP\n",
                                     "            with torch.amp.autocast(\u0027cuda\u0027, enabled=cfg.USE_AMP, dtype=torch.float16):\n",
                                     "                outputs = model(**batch)\n",
                                     "                loss = outputs.loss / cfg.GRAD_ACCUM_STEPS\n",
                                     "            \n",
                                     "            # Backward\n",
                                     "            scaler.scale(loss).backward()\n",
                                     "            running_loss += loss.item()\n",
                                     "            \n",
                                     "            # Gradient accumulation\n",
                                     "            if step % cfg.GRAD_ACCUM_STEPS == 0:\n",
                                     "                # Gradient clipping\n",
                                     "                scaler.unscale_(optimizer)\n",
                                     "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.MAX_GRAD_NORM)\n",
                                     "                \n",
                                     "                # Optimizer step\n",
                                     "                scaler.step(optimizer)\n",
                                     "                scaler.update()\n",
                                     "                optimizer.zero_grad(set_to_none=True)\n",
                                     "                \n",
                                     "                # Scheduler step\n",
                                     "                if cfg.USE_SWA and epoch \u003e= cfg.SWA_START_EPOCH:\n",
                                     "                    swa_scheduler.step()\n",
                                     "                else:\n",
                                     "                    scheduler.step()\n",
                                     "                \n",
                                     "                # EMA update\n",
                                     "                if cfg.USE_EMA and ema is not None:\n",
                                     "                    ema.update()\n",
                                     "                \n",
                                     "                global_step += 1\n",
                                     "                \n",
                                     "                # Progress\n",
                                     "                avg_loss = running_loss / cfg.GRAD_ACCUM_STEPS\n",
                                     "                progress_bar.set_postfix({\n",
                                     "                    \"loss\": f\"{avg_loss:.4f}\",\n",
                                     "                    \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
                                     "                })\n",
                                     "                running_loss = 0.0\n",
                                     "        \n",
                                     "        # SWA model update\n",
                                     "        if cfg.USE_SWA and swa_model is not None and epoch \u003e= cfg.SWA_START_EPOCH:\n",
                                     "            swa_model.update_parameters(model)\n",
                                     "        \n",
                                     "        # Validation\n",
                                     "        if cfg.USE_EMA and ema is not None:\n",
                                     "            ema.apply_shadow()\n",
                                     "        \n",
                                     "        val_loss = validate(model, valid_loader)\n",
                                     "        \n",
                                     "        if cfg.USE_EMA and ema is not None:\n",
                                     "            ema.restore()\n",
                                     "        \n",
                                     "        print(f\"[Epoch {epoch+1}] Valid Loss: {val_loss:.4f}\")\n",
                                     "        \n",
                                     "        # Best model 저장\n",
                                     "        if val_loss \u003c best_val_loss:\n",
                                     "            best_val_loss = val_loss\n",
                                     "            save_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
                                     "            os.makedirs(save_path, exist_ok=True)\n",
                                     "            \n",
                                     "            if cfg.USE_EMA and ema is not None:\n",
                                     "                ema.apply_shadow()\n",
                                     "            \n",
                                     "            model.save_pretrained(save_path)\n",
                                     "            processor.save_pretrained(save_path)\n",
                                     "            \n",
                                     "            if cfg.USE_EMA and ema is not None:\n",
                                     "                ema.restore()\n",
                                     "            \n",
                                     "            print(f\"   ✅ Best model saved to {save_path}\")\n",
                                     "    \n",
                                     "    # SWA 최종 모델\n",
                                     "    if cfg.USE_SWA and swa_model is not None:\n",
                                     "        torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n",
                                     "        save_path = f\"{cfg.SAVE_DIR}/fold{fold}_swa\"\n",
                                     "        os.makedirs(save_path, exist_ok=True)\n",
                                     "        swa_model.module.save_pretrained(save_path)\n",
                                     "        processor.save_pretrained(save_path)\n",
                                     "        print(f\"   ✅ SWA model saved to {save_path}\")\n",
                                     "    \n",
                                     "    return best_val_loss\n",
                                     "\n",
                                     "\n",
                                     "def validate(model, valid_loader):\n",
                                     "    \"\"\"Validation\"\"\"\n",
                                     "    model.eval()\n",
                                     "    total_loss = 0.0\n",
                                     "    \n",
                                     "    with torch.no_grad():\n",
                                     "        for batch in tqdm(valid_loader, desc=\"Validating\", leave=False):\n",
                                     "            batch = {k: v.to(device) for k, v in batch.items()}\n",
                                     "            \n",
                                     "            with torch.amp.autocast(\u0027cuda\u0027, enabled=cfg.USE_AMP, dtype=torch.float16):\n",
                                     "                outputs = model(**batch)\n",
                                     "                total_loss += outputs.loss.item()\n",
                                     "    \n",
                                     "    model.train()\n",
                                     "    return total_loss / len(valid_loader)\n",
                                     "\n",
                                     "\n",
                                     "print(\"✅ Training functions 정의 완료\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🚀 9. 실제 학습 실행\n",
                                     "\n",
                                     "K-Fold 또는 단일 모델 학습을 실행합니다."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# K-Fold 학습\n",
                                     "if cfg.USE_KFOLD:\n",
                                     "    results = {}\n",
                                     "    \n",
                                     "    for fold in cfg.TRAIN_FOLDS:\n",
                                     "        print(f\"\\n{\u0027#\u0027*60}\")\n",
                                     "        print(f\"Starting Fold {fold}/{cfg.N_FOLDS-1}\")\n",
                                     "        print(f\"{\u0027#\u0027*60}\")\n",
                                     "        \n",
                                     "        # 데이터 분할\n",
                                     "        train_subset = train_df[train_df[\u0027fold\u0027] != fold].reset_index(drop=True)\n",
                                     "        valid_subset = train_df[train_df[\u0027fold\u0027] == fold].reset_index(drop=True)\n",
                                     "        \n",
                                     "        print(f\"Train: {len(train_subset)}, Valid: {len(valid_subset)}\")\n",
                                     "        \n",
                                     "        # Dataset\n",
                                     "        train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
                                     "        valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
                                     "        \n",
                                     "        # DataLoader\n",
                                     "        train_loader = DataLoader(\n",
                                     "            train_ds,\n",
                                     "            batch_size=cfg.BATCH_SIZE,\n",
                                     "            shuffle=True,\n",
                                     "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
                                     "            num_workers=0\n",
                                     "        )\n",
                                     "        valid_loader = DataLoader(\n",
                                     "            valid_ds,\n",
                                     "            batch_size=cfg.BATCH_SIZE,\n",
                                     "            shuffle=False,\n",
                                     "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
                                     "            num_workers=0\n",
                                     "        )\n",
                                     "        \n",
                                     "        # 학습\n",
                                     "        best_loss = train_one_fold(model, train_loader, valid_loader, fold=fold)\n",
                                     "        results[fold] = best_loss\n",
                                     "        \n",
                                     "        print(f\"\\n✅ Fold {fold} 완료: Best Val Loss = {best_loss:.4f}\")\n",
                                     "    \n",
                                     "    print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "    print(\"All Folds Training Complete!\")\n",
                                     "    print(f\"{\u0027=\u0027*60}\")\n",
                                     "    for fold, loss in results.items():\n",
                                     "        print(f\"Fold {fold}: {loss:.4f}\")\n",
                                     "    print(f\"Average: {np.mean(list(results.values())):.4f}\")\n",
                                     "\n",
                                     "else:\n",
                                     "    # 단일 모델 학습\n",
                                     "    train_subset = train_df[train_df[\u0027fold\u0027] == -1].reset_index(drop=True)\n",
                                     "    valid_subset = train_df[train_df[\u0027fold\u0027] == 0].reset_index(drop=True)\n",
                                     "    \n",
                                     "    train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
                                     "    valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
                                     "    \n",
                                     "    train_loader = DataLoader(\n",
                                     "        train_ds,\n",
                                     "        batch_size=cfg.BATCH_SIZE,\n",
                                     "        shuffle=True,\n",
                                     "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
                                     "        num_workers=0\n",
                                     "    )\n",
                                     "    valid_loader = DataLoader(\n",
                                     "        valid_ds,\n",
                                     "        batch_size=cfg.BATCH_SIZE,\n",
                                     "        shuffle=False,\n",
                                     "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
                                     "        num_workers=0\n",
                                     "    )\n",
                                     "    \n",
                                     "    best_loss = train_one_fold(model, train_loader, valid_loader, fold=0)\n",
                                     "    print(f\"\\n✅ Single model 학습 완료: Best Val Loss = {best_loss:.4f}\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🔮 10. Inference with TTA\n",
                                     "\n",
                                     "Test-Time Augmentation을 활용한 추론을 수행합니다."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import re\n",
                                     "\n",
                                     "def extract_choice(text: str) -\u003e str:\n",
                                     "    \"\"\"모델 출력에서 a/b/c/d 중 하나를 안정적으로 추출\"\"\"\n",
                                     "    t = (text or \u0027\u0027).strip().lower()\n",
                                     "    t = re.sub(r\u0027[^a-d\\n ]\u0027, \u0027 \u0027, t)\n",
                                     "    # 줄 단위로 마지막 토큰 우선\n",
                                     "    lines = [l.strip() for l in t.splitlines() if l.strip()]\n",
                                     "    if lines:\n",
                                     "        last = lines[-1].split()[-1]\n",
                                     "        if last in [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]:\n",
                                     "            return last\n",
                                     "    # 전역 스캔\n",
                                     "    for tok in t.split():\n",
                                     "        if tok in [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]:\n",
                                     "            return tok\n",
                                     "    return \u0027a\u0027\n",
                                     "\n",
                                     "\n",
                                     "def infer_single_fold(model_path, test_df, output_path):\n",
                                     "    \"\"\"단일 Fold 추론 (Direct logits + TTA + 확률 출력)\"\"\"\n",
                                     "    # 모델 로드\n",
                                     "    if cfg.USE_ADVANCED_MODEL:\n",
                                     "        model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
                                     "            model_path,\n",
                                     "            trust_remote_code=True,\n",
                                     "            torch_dtype=torch.float16\n",
                                     "        )\n",
                                     "    else:\n",
                                     "        model_infer = AutoModelForVision2Seq.from_pretrained(\n",
                                     "            model_path,\n",
                                     "            trust_remote_code=True,\n",
                                     "            torch_dtype=torch.float16\n",
                                     "        )\n",
                                     "    model_infer = model_infer.to(device)\n",
                                     "\n",
                                     "    processor_infer = AutoProcessor.from_pretrained(\n",
                                     "        model_path,\n",
                                     "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
                                     "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
                                     "        trust_remote_code=True,\n",
                                     "    )\n",
                                     "\n",
                                     "    # pad_token_id 보정\n",
                                     "    try:\n",
                                     "        if getattr(model_infer.config, \u0027pad_token_id\u0027, None) is None:\n",
                                     "            model_infer.config.pad_token_id = model_infer.config.eos_token_id\n",
                                     "    except Exception:\n",
                                     "        pass\n",
                                     "\n",
                                     "    def _choice_token_sets(tokenizer):\n",
                                     "        mapping = {}\n",
                                     "        choices = [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]\n",
                                     "        forms = [\u0027{c}\u0027, \u0027 {c}\u0027, \u0027({c})\u0027, \u0027{c})\u0027, \u0027{c}.\u0027, \u0027[{c}]\u0027, \u0027: {c}\u0027, \u0027{c}:\u0027]\n",
                                     "        for c in choices:\n",
                                     "            s = set()\n",
                                     "            for f in forms:\n",
                                     "                t = f.replace(\u0027{c}\u0027, c)\n",
                                     "                try:\n",
                                     "                    tids = tokenizer.encode(t, add_special_tokens=False)\n",
                                     "                    if len(tids) \u003e 0:\n",
                                     "                        s.add(int(tids[-1]))\n",
                                     "                except Exception:\n",
                                     "                    continue\n",
                                     "            mapping[c] = sorted(list(s))\n",
                                     "        return mapping\n",
                                     "\n",
                                     "    choice_token_ids = _choice_token_sets(processor_infer.tokenizer)\n",
                                     "\n",
                                     "    model_infer.eval()\n",
                                     "\n",
                                     "    predictions = []\n",
                                     "    probs_accumulator = { \u0027a\u0027: [], \u0027b\u0027: [], \u0027c\u0027: [], \u0027d\u0027: [] }\n",
                                     "\n",
                                     "    for i in tqdm(range(len(test_df)), desc=\u0027Inference\u0027):\n",
                                     "        row = test_df.iloc[i]\n",
                                     "\n",
                                     "        # 이미지 로드\n",
                                     "        img_path = os.path.join(cfg.DATA_DIR, row[\u0027path\u0027])\n",
                                     "        try:\n",
                                     "            img = Image.open(img_path).convert(\u0027RGB\u0027)\n",
                                     "        except Exception:\n",
                                     "            img = Image.new(\u0027RGB\u0027, (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color=\u0027white\u0027)\n",
                                     "\n",
                                     "        # 프롬프트 생성\n",
                                     "        user_text = build_mc_prompt(\n",
                                     "            str(row[\u0027question\u0027]), str(row[\u0027a\u0027]), str(row[\u0027b\u0027]), str(row[\u0027c\u0027]), str(row[\u0027d\u0027])\n",
                                     "        )\n",
                                     "        messages = [\n",
                                     "            {\u0027role\u0027: \u0027system\u0027, \u0027content\u0027: [{\u0027type\u0027: \u0027text\u0027, \u0027text\u0027: cfg.SYSTEM_INSTRUCT}]},\n",
                                     "            {\u0027role\u0027: \u0027user\u0027, \u0027content\u0027: [\n",
                                     "                {\u0027type\u0027: \u0027image\u0027, \u0027image\u0027: img},\n",
                                     "                {\u0027type\u0027: \u0027text\u0027, \u0027text\u0027: user_text}\n",
                                     "            ]}\n",
                                     "        ]\n",
                                     "        text = processor_infer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
                                     "\n",
                                     "        if cfg.USE_DIRECT_LOGIT_DECODE:\n",
                                     "            # Direct logits 분류 + (옵션) TTA 평균\n",
                                     "            probs_letters = {\u0027a\u0027: [], \u0027b\u0027: [], \u0027c\u0027: [], \u0027d\u0027: []}\n",
                                     "            with torch.no_grad():\n",
                                     "                scales = cfg.TTA_SCALES if cfg.USE_TTA else [1.0]\n",
                                     "                for s in scales:\n",
                                     "                    if abs(s - 1.0) \u003e 1e-6:\n",
                                     "                        try:\n",
                                     "                            w, h = img.size\n",
                                     "                            img_s = img.resize((max(1,int(round(w*s))), max(1,int(round(h*s)))), resample=Image.BICUBIC)\n",
                                     "                        except Exception:\n",
                                     "                            img_s = img\n",
                                     "                    else:\n",
                                     "                        img_s = img\n",
                                     "                    inputs = processor_infer(text=[text], images=[img_s], return_tensors=\u0027pt\u0027).to(device)\n",
                                     "                    outputs = model_infer(**inputs)\n",
                                     "                    logits = outputs.logits[:, -1, :]\n",
                                     "                    p = torch.softmax(logits, dim=-1)[0]\n",
                                     "                    for k, id_list in choice_token_ids.items():\n",
                                     "                        probs_letters[k].append(float(p[id_list].sum().item()) if len(id_list)\u003e0 else 0.0)\n",
                                     "            avg_probs = {k: (sum(v)/len(v) if len(v)\u003e0 else 0.0) for k,v in probs_letters.items()}\n",
                                     "            best = max(avg_probs.items(), key=lambda x: x[1])[0]\n",
                                     "            predictions.append(best)\n",
                                     "            for k in [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]:\n",
                                     "                probs_accumulator[k].append(avg_probs.get(k, 0.0))\n",
                                     "        else:\n",
                                     "            # Fallback: 자유 생성 후 후처리 추출\n",
                                     "            inputs = processor_infer(text=[text], images=[img], return_tensors=\u0027pt\u0027).to(device)\n",
                                     "            with torch.no_grad():\n",
                                     "                out_ids = model_infer.generate(\n",
                                     "                    **inputs,\n",
                                     "                    max_new_tokens=cfg.MAX_NEW_TOKENS,\n",
                                     "                    do_sample=cfg.DO_SAMPLE,\n",
                                     "                    temperature=cfg.TEMPERATURE if cfg.DO_SAMPLE else None,\n",
                                     "                    eos_token_id=processor_infer.tokenizer.eos_token_id\n",
                                     "                )\n",
                                     "            output_text = processor_infer.batch_decode(out_ids, skip_special_tokens=True)[0]\n",
                                     "            ans = extract_choice(output_text)\n",
                                     "            predictions.append(ans)\n",
                                     "            for k in [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]:\n",
                                     "                probs_accumulator[k].append(0.0)\n",
                                     "\n",
                                     "    # 저장\n",
                                     "    submission = pd.DataFrame({\n",
                                     "        \u0027id\u0027: test_df[\u0027id\u0027],\n",
                                     "        \u0027answer\u0027: predictions,\n",
                                     "        \u0027prob_a\u0027: probs_accumulator.get(\u0027a\u0027, []),\n",
                                     "        \u0027prob_b\u0027: probs_accumulator.get(\u0027b\u0027, []),\n",
                                     "        \u0027prob_c\u0027: probs_accumulator.get(\u0027c\u0027, []),\n",
                                     "        \u0027prob_d\u0027: probs_accumulator.get(\u0027d\u0027, [])\n",
                                     "    })\n",
                                     "\n",
                                     "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
                                     "    submission.to_csv(output_path, index=False)\n",
                                     "    print(f\u0027✅ Saved to {output_path}\u0027)\n",
                                     "    return submission\n",
                                     "\n",
                                     "\n",
                                     "# 전체 Fold 추론 실행\n",
                                     "predictions_all = []\n",
                                     "if cfg.USE_KFOLD:\n",
                                     "    for fold in cfg.TRAIN_FOLDS:\n",
                                     "        model_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
                                     "        output_path = f\"{cfg.OUTPUT_DIR}/submission_fold{fold}.csv\"\n",
                                     "        print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "        print(f\"Inferencing Fold {fold}\")\n",
                                     "        print(f\"{\u0027=\u0027*60}\")\n",
                                     "        pred = infer_single_fold(model_path, test_df, output_path)\n",
                                     "        predictions_all.append(pred)\n",
                                     "else:\n",
                                     "    model_path = f\"{cfg.SAVE_DIR}/fold0_best\"\n",
                                     "    output_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n",
                                     "    pred = infer_single_fold(model_path, test_df, output_path)\n",
                                     "    predictions_all.append(pred)\n",
                                     "\n",
                                     "print(\u0027\\n✅ All inference complete!\u0027)\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 🎯 11. Ensemble\n",
                                     "\n",
                                     "여러 Fold의 예측을 앙상블합니다."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "if cfg.USE_KFOLD and len(predictions_all) \u003e 1:\n",
                                     "    print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "    print(\"Ensemble (Probability Average if available)\")\n",
                                     "    print(f\"{\u0027=\u0027*60}\")\n",
                                     "\n",
                                     "    if cfg.ENSEMBLE_METHOD == \u0027prob\u0027 and all(set([\u0027prob_a\u0027,\u0027prob_b\u0027,\u0027prob_c\u0027,\u0027prob_d\u0027]).issubset(set(df.columns)) for df in predictions_all):\n",
                                     "        pa = sum(df[\u0027prob_a\u0027].values for df in predictions_all) / len(predictions_all)\n",
                                     "        pb = sum(df[\u0027prob_b\u0027].values for df in predictions_all) / len(predictions_all)\n",
                                     "        pc = sum(df[\u0027prob_c\u0027].values for df in predictions_all) / len(predictions_all)\n",
                                     "        pd_ = sum(df[\u0027prob_d\u0027].values for df in predictions_all) / len(predictions_all)\n",
                                     "        letters = np.array([\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027])\n",
                                     "        probs_mat = np.vstack([pa, pb, pc, pd_]).T\n",
                                     "        ensemble_preds = letters[probs_mat.argmax(axis=1)].tolist()\n",
                                     "    else:\n",
                                     "        # Majority Voting fallback\n",
                                     "        ensemble_preds = []\n",
                                     "        for i in range(len(test_df)):\n",
                                     "            votes = [pred.iloc[i][\u0027answer\u0027] for pred in predictions_all]\n",
                                     "            most_common = Counter(votes).most_common(1)[0][0]\n",
                                     "            ensemble_preds.append(most_common)\n",
                                     "\n",
                                     "    # 최종 제출 파일 생성\n",
                                     "    final_submission = pd.DataFrame({\n",
                                     "        \u0027id\u0027: test_df[\u0027id\u0027],\n",
                                     "        \u0027answer\u0027: ensemble_preds\n",
                                     "    })\n",
                                     "    final_path = f\"{cfg.OUTPUT_DIR}/submission_ensemble.csv\"\n",
                                     "    final_submission.to_csv(final_path, index=False)\n",
                                     "    print(f\"✅ Ensemble submission saved to {final_path}\")\n",
                                     "    print(\"\\nAnswer Distribution:\")\n",
                                     "    print(final_submission[\u0027answer\u0027].value_counts().sort_index())\n",
                                     "else:\n",
                                     "    print(\"\\nℹ️ Single model - No ensemble needed\")\n",
                                     "    final_submission = predictions_all[0]\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 📊 12. 결과 분석 및 시각화"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# 답변 분포 시각화\n",
                                     "fig, ax = plt.subplots(figsize=(10, 5))\n",
                                     "\n",
                                     "answer_counts = final_submission[\u0027answer\u0027].value_counts().sort_index()\n",
                                     "sns.barplot(x=answer_counts.index, y=answer_counts.values, palette=\u0027viridis\u0027, ax=ax)\n",
                                     "ax.set_title(\u0027Final Submission Answer Distribution\u0027, fontsize=14, weight=\u0027bold\u0027)\n",
                                     "ax.set_xlabel(\u0027Answer\u0027)\n",
                                     "ax.set_ylabel(\u0027Count\u0027)\n",
                                     "ax.grid(axis=\u0027y\u0027, alpha=0.3)\n",
                                     "\n",
                                     "# 비율 표시\n",
                                     "for i, (ans, count) in enumerate(answer_counts.items()):\n",
                                     "    percentage = count / len(final_submission) * 100\n",
                                     "    ax.text(i, count + 10, f\"{percentage:.1f}%\", ha=\u0027center\u0027, fontsize=10)\n",
                                     "\n",
                                     "plt.tight_layout()\n",
                                     "plt.show()\n",
                                     "\n",
                                     "# 통계 출력\n",
                                     "print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "print(\"Final Statistics\")\n",
                                     "print(f\"{\u0027=\u0027*60}\")\n",
                                     "print(f\"Total predictions: {len(final_submission)}\")\n",
                                     "print(f\"\\nAnswer counts:\")\n",
                                     "for ans, count in answer_counts.items():\n",
                                     "    print(f\"  {ans}: {count:5d} ({count/len(final_submission)*100:5.1f}%)\")\n",
                                     "\n",
                                     "# 제출 파일 샘플\n",
                                     "print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "print(\"Sample Predictions\")\n",
                                     "print(f\"{\u0027=\u0027*60}\")\n",
                                     "print(final_submission.head(10))"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ✅ 13. 최종 정리\n",
                                     "\n",
                                     "### 🎉 완료된 작업\n",
                                     "\n",
                                     "1. ✅ **환경 설정** - 패키지 설치 및 임포트\n",
                                     "2. ✅ **Config** - 하이퍼파라미터 통합 관리\n",
                                     "3. ✅ **데이터 로드 \u0026 EDA** - 탐색적 분석\n",
                                     "4. ✅ **Stratified K-Fold** - CV Splits 생성\n",
                                     "5. ✅ **Dataset \u0026 DataLoader** - 라벨 정렬 교정 적용\n",
                                     "6. ✅ **Model \u0026 Processor** - QLoRA 모델 로드 (T4 호환)\n",
                                     "7. ✅ **Training Loop** - AMP, EMA, SWA, Cosine Warmup 적용\n",
                                     "8. ✅ **Inference** - TTA 지원 추론\n",
                                     "9. ✅ **Ensemble** - Majority Voting\n",
                                     "10. ✅ **Results** - 시각화 및 통계\n",
                                     "\n",
                                     "### 🚀 다음 단계\n",
                                     "\n",
                                     "1. **하이퍼파라미터 튜닝**\n",
                                     "   - Learning rate, LoRA rank 조정\n",
                                     "   - Batch size, Grad accumulation 최적화\n",
                                     "\n",
                                     "2. **모델 크기 확대**\n",
                                     "   - 7B 모델 사용 (더 높은 정확도)\n",
                                     "   - Image size 증가 (512, 768)\n",
                                     "\n",
                                     "3. **고급 기법 활성화**\n",
                                     "   - TTA scales 추가\n",
                                     "   - SWA 적용\n",
                                     "   - 데이터 증강 활성화\n",
                                     "\n",
                                     "4. **에폭 증가**\n",
                                     "   - NUM_EPOCHS = 3~5\n",
                                     "\n",
                                     "### 📌 Important Notes\n",
                                     "\n",
                                     "- **T4 호환**: Float16, SDPA attention 사용\n",
                                     "- **라벨 정렬**: Assistant 메시지에 정답 포함 (핵심!)\n",
                                     "- **재현성**: Seed 42 고정\n",
                                     "- **메모리**: Gradient checkpointing, 4-bit QLoRA\n",
                                     "\n",
                                     "---\n",
                                     "\n",
                                     "**🤖 Generated for SSAFY AI Project 2025**\n",
                                     "\n",
                                     "**📧 Contact**: GitHub Issues\n",
                                     "\n",
                                     "**⭐ 행운을 빕니다!**"
                                 ]
                  }
              ],
    "metadata":  {
                     "kernelspec":  {
                                        "display_name":  "Python 3",
                                        "language":  "python",
                                        "name":  "python3"
                                    },
                     "language_info":  {
                                           "codemirror_mode":  {
                                                                   "name":  "ipython",
                                                                   "version":  3
                                                               },
                                           "file_extension":  ".py",
                                           "mimetype":  "text/x-python",
                                           "name":  "python",
                                           "nbconvert_exporter":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.8.10"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  4
}
