{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“’ Kaggle_AllInOne_Pro2.ipynb â€“ ê³ ê¸‰ ìµœì í™” ë²„ì „\n\n## ğŸ¯ Pro2 ì£¼ìš” ê°œì„ ì‚¬í•­\n\n### âœ… í•™ìŠµ ê°œì„ \n- Val Accuracy + Confusion Matrix ë¡œê¹…\n- Best ëª¨ë¸: Val Acc ìš°ì„  ì €ì¥\n- í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n- ë¼ë²¨ ë§ˆìŠ¤í‚¹ (í”„ë¡¬í”„íŠ¸ ì†ì‹¤ ì œì™¸)\n- ê²€ì¦ ë°ì´í„° train=False\n\n### âœ… ì¶”ë¡  ê°œì„ \n- Direct Logits (a/b/c/d í† í° í™•ë¥ )\n- TTA [0.9, 1.0, 1.1]\n- ë°°ì¹˜ ì¶”ë¡ \n- pad_token_id ìë™ ë³´ì •\n\n### âœ… ì•™ìƒë¸” ê°œì„ \n- Temperature Scaling\n- í™•ë¥  ì•™ìƒë¸”\n- í™•ë¥  ì»¬ëŸ¼ ì €ì¥\n\n### âš™ï¸ íŠœë‹ ì„¤ì •\n```\nUSE_SAMPLE=False, IMAGE_SIZE=512, NUM_EPOCHS=3\nGRAD_ACCUM_STEPS=8, WARMUP_RATIO=0.06, LORA_R=16\nUSE_DIRECT_LOGIT_DECODE=True, TTA_SCALES=[0.9,1.0,1.1]\nENSEMBLE_METHOD='prob'\n```\n\n**ğŸ¤– SSAFY AI Project 2025**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¦ 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -q transformers accelerate peft bitsandbytes datasets pillow pandas torch torchvision scikit-learn matplotlib seaborn tqdm --upgrade\n# !pip install -q qwen-vl-utils==0.0.8\nprint(\"âœ… ì„¤ì¹˜ ì™„ë£Œ! ëŸ°íƒ€ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys, re, math, random, warnings, json, pickle\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom collections import Counter, defaultdict\nimport unicodedata\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.swa_utils import AveragedModel, SWALR\n\nfrom transformers import (\n    AutoModelForVision2Seq,\n    Qwen2_5_VLForConditionalGeneration,\n    AutoProcessor,\n    BitsAndBytesConfig,\n    get_cosine_schedule_with_warmup,\n    get_linear_schedule_with_warmup\n)\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom qwen_vl_utils import process_vision_info\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nwarnings.filterwarnings('ignore')\nImage.MAX_IMAGE_PIXELS = None\nsns.set_style('whitegrid')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"ğŸ”§ Device: {device}\")\nif torch.cuda.is_available():\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš™ï¸ 3. Config ì„¤ì • (Pro2 íŠœë‹)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n    # ì‹œë“œ\n    SEED = 42\n    \n    # ëª¨ë¸\n    MODEL_ID = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n    IMAGE_SIZE = 512  # âœ… Pro2: ê³ í•´ìƒë„\n    USE_ADVANCED_MODEL = False  # Trueë©´ Qwen2_5_VL (VRAM í™•ì¸)\n    \n    # ë°ì´í„°\n    DATA_DIR = \"/content\"\n    TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n    TEST_CSV = f\"{DATA_DIR}/test.csv\"\n    \n    # K-Fold\n    N_FOLDS = 3\n    USE_KFOLD = True\n    TRAIN_FOLDS = [0, 1, 2]\n    \n    # QLoRA\n    LORA_R = 16  # âœ… Pro2: ë” í° í‘œí˜„ë ¥\n    LORA_ALPHA = 32\n    LORA_DROPOUT = 0.05\n    TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n    \n    # í•™ìŠµ\n    NUM_EPOCHS = 3  # âœ… Pro2\n    BATCH_SIZE = 1\n    GRAD_ACCUM_STEPS = 8  # âœ… Pro2\n    LEARNING_RATE = 1e-4\n    WEIGHT_DECAY = 0.01\n    WARMUP_RATIO = 0.06  # âœ… Pro2\n    MAX_GRAD_NORM = 1.0\n    \n    # ê³ ê¸‰ ê¸°ë²•\n    USE_AMP = True\n    USE_EMA = True\n    EMA_DECAY = 0.999\n    USE_SWA = True  # âœ… Pro2: Epoch 1 ì´í›„ ON\n    SWA_START_EPOCH = 1\n    USE_COSINE_SCHEDULE = True\n    \n    # TTA\n    USE_TTA = True  # âœ… Pro2\n    TTA_SCALES = [0.9, 1.0, 1.1]  # âœ… Pro2\n    \n    # ì¶”ë¡ \n    USE_DIRECT_LOGIT_DECODE = True  # âœ… Pro2: Direct logits\n    USE_BATCH_INFERENCE = False  # ë©”ëª¨ë¦¬ í—ˆìš© ì‹œ True\n    INFER_BATCH_SIZE = 4\n    MAX_NEW_TOKENS = 8\n    \n    # Temperature Scaling\n    USE_TEMPERATURE_SCALING = True  # âœ… Pro2\n    \n    # ì•™ìƒë¸”\n    ENSEMBLE_METHOD = \"prob\"  # âœ… Pro2: \"prob\" or \"vote\"\n    \n    # ì €ì¥\n    SAVE_DIR = f\"{DATA_DIR}/checkpoints\"\n    OUTPUT_DIR = f\"{DATA_DIR}/outputs\"\n    LOG_DIR = f\"{DATA_DIR}/logs\"\n    \n    # ìƒ˜í”Œë§\n    USE_SAMPLE = False  # âœ… Pro2: ì „ì²´ ë°ì´í„°\n    SAMPLE_SIZE = 200\n    \n    # í”„ë¡¬í”„íŠ¸\n    SYSTEM_INSTRUCT = (\n        \"You are a helpful visual question answering assistant. \"\n        \"Answer using exactly one letter among a, b, c, or d. No explanation.\"\n    )\n\ncfg = Config()\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(cfg.SEED)\nprint(f\"âœ… Config ì„¤ì • ì™„ë£Œ\")\nprint(f\"   Model: {cfg.MODEL_ID}\")\nprint(f\"   Image Size: {cfg.IMAGE_SIZE}\")\nprint(f\"   Epochs: {cfg.NUM_EPOCHS}, Grad Accum: {cfg.GRAD_ACCUM_STEPS}\")\nprint(f\"   LoRA R: {cfg.LORA_R}, Warmup: {cfg.WARMUP_RATIO}\")\nprint(f\"   Direct Logits: {cfg.USE_DIRECT_LOGIT_DECODE}, TTA: {cfg.USE_TTA}\")\nprint(f\"   Ensemble: {cfg.ENSEMBLE_METHOD}, Temp Scaling: {cfg.USE_TEMPERATURE_SCALING}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š 4. ë°ì´í„° ë¡œë“œ & EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(cfg.TRAIN_CSV)\ntest_df = pd.read_csv(cfg.TEST_CSV)\n\nprint(f\"ğŸ“ Train: {len(train_df):,} samples\")\nprint(f\"ğŸ“ Test: {len(test_df):,} samples\")\n\nif cfg.USE_SAMPLE:\n    train_df = train_df.sample(n=min(cfg.SAMPLE_SIZE, len(train_df)), random_state=cfg.SEED).reset_index(drop=True)\n    print(f\"âš ï¸  Sampled {len(train_df)} samples\")\n\nprint(f\"\\nğŸ“Š Answer Distribution:\")\nprint(train_df['answer'].value_counts().sort_index())\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 4))\ntrain_df['answer'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='skyblue')\naxes[0].set_title('Answer Distribution')\naxes[0].set_xlabel('Answer')\naxes[0].set_ylabel('Count')\n\ntrain_df['question_len'] = train_df['question'].str.len()\ntrain_df['question_len'].hist(bins=30, ax=axes[1], color='salmon')\naxes[1].set_title('Question Length')\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”„ 5. Stratified K-Fold CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD:\n    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=cfg.SEED)\n    train_df['fold'] = -1\n    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['answer'])):\n        train_df.loc[val_idx, 'fold'] = fold\n    print(f\"âœ… {cfg.N_FOLDS}-Fold CV ìƒì„±\")\n    print(train_df['fold'].value_counts().sort_index())\nelse:\n    split_idx = int(len(train_df) * 0.9)\n    train_df['fold'] = -1\n    train_df.loc[split_idx:, 'fold'] = 0\n    print(f\"âœ… Single split (90:10)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ—‚ï¸ 6. Dataset & DataCollator\n\nâœ… **ë¼ë²¨ ë§ˆìŠ¤í‚¹**: í”„ë¡¬í”„íŠ¸ í† í° ì†ì‹¤ ì œì™¸, assistant ì •ë‹µ í† í°ë§Œ ê°ë…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_mc_prompt(question, a, b, c, d):\n    return (\n        f\"{question}\\n\"\n        f\"(a) {a}\\n(b) {b}\\n(c) {c}\\n(d) {d}\\n\\n\"\n        \"ì •ë‹µì„ ë°˜ë“œì‹œ a, b, c, d ì¤‘ í•˜ë‚˜ì˜ ì†Œë¬¸ì í•œ ê¸€ìë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\"\n    )\n\nclass VQADataset(Dataset):\n    def __init__(self, df, processor, data_dir=\"\", train=True, use_advanced=False):\n        self.df = df.reset_index(drop=True)\n        self.processor = processor\n        self.data_dir = data_dir\n        self.train = train\n        self.use_advanced = use_advanced\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # ì´ë¯¸ì§€ ë¡œë“œ (path ì»¬ëŸ¼ ì§€ì›)\n        img_col = 'path' if 'path' in row else 'image'\n        img_path = os.path.join(self.data_dir, row[img_col])\n        try:\n            img = Image.open(img_path).convert(\"RGB\")\n        except:\n            img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n        \n        user_text = build_mc_prompt(\n            str(row[\"question\"]), str(row[\"a\"]), \n            str(row[\"b\"]), str(row[\"c\"]), str(row[\"d\"])\n        )\n        \n        messages = [\n            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"image\", \"image\": img},\n                {\"type\": \"text\", \"text\": user_text}\n            ]}\n        ]\n        \n        # âœ… í•™ìŠµ ì‹œì—ë§Œ ì •ë‹µ í¬í•¨\n        answer = None\n        if self.train:\n            answer = str(row[\"answer\"]).strip().lower()\n            messages.append({\n                \"role\": \"assistant\",\n                \"content\": [{\"type\": \"text\", \"text\": answer}]\n            })\n        \n        return {\"messages\": messages, \"image\": img, \"answer\": answer}\n\n@dataclass\nclass DataCollator:\n    processor: Any\n    train: bool = True\n    use_advanced: bool = False\n    \n    def __call__(self, batch):\n        texts, images, answers = [], [], []\n        \n        for sample in batch:\n            text = self.processor.apply_chat_template(\n                sample[\"messages\"],\n                tokenize=False,\n                add_generation_prompt=False  # âœ… False!\n            )\n            text = unicodedata.normalize('NFKC', text)\n            texts.append(text)\n            images.append(sample[\"image\"])\n            answers.append(sample[\"answer\"])\n        \n        enc = self.processor(\n            text=texts,\n            images=images,\n            padding=True,\n            return_tensors=\"pt\"\n        )\n        \n        # âœ… ë¼ë²¨ ë§ˆìŠ¤í‚¹: ì •ë‹µ í† í°ë§Œ ê°ë…\n        if self.train:\n            labels = enc[\"input_ids\"].clone()\n            for i, answer in enumerate(answers):\n                if answer is None:\n                    labels[i, :] = -100\n                else:\n                    # í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ -100\n                    labels[i, :] = -100\n                    # ì •ë‹µ í† í°ë§Œ ìœ ì§€\n                    answer_ids = self.processor.tokenizer.encode(answer, add_special_tokens=False)\n                    if len(answer_ids) > 0:\n                        labels[i, -len(answer_ids):] = torch.tensor(answer_ids)\n            enc[\"labels\"] = labels\n        \n        return enc\n\nprint(\"âœ… Dataset & DataCollator ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤– 7. Model & Processor ë¡œë“œ\n\nâœ… T4 í˜¸í™˜: Float16, SDPA attention, 4-bit QLoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model_and_processor(model_id, use_advanced=False):\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.float16,\n    )\n    \n    processor = AutoProcessor.from_pretrained(\n        model_id,\n        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n        trust_remote_code=True,\n    )\n    \n    if use_advanced:\n        base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n            model_id,\n            quantization_config=bnb_config,\n            trust_remote_code=True,\n            torch_dtype=torch.float16,\n            attn_implementation=\"sdpa\",\n        )\n    else:\n        base_model = AutoModelForVision2Seq.from_pretrained(\n            model_id,\n            quantization_config=bnb_config,\n            trust_remote_code=True,\n        )\n    \n    base_model = prepare_model_for_kbit_training(base_model)\n    base_model.gradient_checkpointing_enable()\n    \n    lora_config = LoraConfig(\n        r=cfg.LORA_R,\n        lora_alpha=cfg.LORA_ALPHA,\n        lora_dropout=cfg.LORA_DROPOUT,\n        bias=\"none\",\n        target_modules=cfg.TARGET_MODULES,\n        task_type=\"CAUSAL_LM\",\n    )\n    \n    model = get_peft_model(base_model, lora_config)\n    model.print_trainable_parameters()\n    \n    # ë‹¨ì¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™ (device_map ëŒ€ì‹ )\n    model = model.to(device)\n    \n    return model, processor\n\nprint(\"ğŸ”§ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\nmodel, processor = create_model_and_processor(cfg.MODEL_ID, cfg.USE_ADVANCED_MODEL)\nprint(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ 8. Training Loop\n\nâœ… **Val Accuracy ë¡œê¹…** + Confusion Matrix + í•™ìŠµ ê³¡ì„ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EMA:\n    def __init__(self, model, decay=0.999):\n        self.model = model\n        self.decay = decay\n        self.shadow = {}\n        self.backup = {}\n        self.register()\n    \n    def register(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                self.shadow[name] = param.data.clone()\n    \n    def update(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                new_average = self.decay * self.shadow[name] + (1.0 - self.decay) * param.data\n                self.shadow[name] = new_average.clone()\n    \n    def apply_shadow(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                self.backup[name] = param.data.clone()\n                param.data = self.shadow[name]\n    \n    def restore(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                param.data = self.backup[name]\n        self.backup = {}\n\n\ndef validate_with_accuracy(model, valid_loader, processor):\n    \"\"\"âœ… Val Loss + Accuracy + Confusion Matrix\"\"\"\n    model.eval()\n    total_loss = 0.0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(valid_loader, desc=\"Validating\", leave=False):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n                outputs = model(**batch)\n                total_loss += outputs.loss.item()\n            \n            # âœ… Accuracy ê³„ì‚° (ì •ë‹µ í† í° ì˜ˆì¸¡)\n            logits = outputs.logits\n            labels = batch[\"labels\"]\n            \n            for i in range(len(labels)):\n                # ë§ˆì§€ë§‰ ë¹„-íŒ¨ë”© í† í° ìœ„ì¹˜ ì°¾ê¸°\n                valid_mask = labels[i] != -100\n                if valid_mask.any():\n                    last_valid_idx = valid_mask.nonzero(as_tuple=True)[0][-1]\n                    pred_id = logits[i, last_valid_idx].argmax().item()\n                    label_id = labels[i, last_valid_idx].item()\n                    \n                    # í† í° â†’ ë¬¸ì ë³€í™˜\n                    pred_char = processor.tokenizer.decode([pred_id]).strip().lower()\n                    label_char = processor.tokenizer.decode([label_id]).strip().lower()\n                    \n                    # a/b/c/dë§Œ ìˆ˜ì§‘\n                    if pred_char in ['a', 'b', 'c', 'd']:\n                        all_preds.append(pred_char)\n                    else:\n                        all_preds.append('a')  # Fallback\n                    \n                    if label_char in ['a', 'b', 'c', 'd']:\n                        all_labels.append(label_char)\n                    else:\n                        all_labels.append('a')\n    \n    avg_loss = total_loss / len(valid_loader)\n    accuracy = accuracy_score(all_labels, all_preds)\n    cm = confusion_matrix(all_labels, all_preds, labels=['a', 'b', 'c', 'd'])\n    \n    model.train()\n    return avg_loss, accuracy, cm, all_preds, all_labels\n\n\ndef train_one_fold(model, train_loader, valid_loader, fold=0):\n    \"\"\"ë‹¨ì¼ Fold í•™ìŠµ (Val Acc ìš°ì„  ì €ì¥)\"\"\"\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Training Fold {fold}\")\n    print(f\"{'='*60}\")\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=cfg.LEARNING_RATE,\n        weight_decay=cfg.WEIGHT_DECAY\n    )\n    \n    num_training_steps = cfg.NUM_EPOCHS * math.ceil(len(train_loader) / cfg.GRAD_ACCUM_STEPS)\n    num_warmup_steps = int(num_training_steps * cfg.WARMUP_RATIO)\n    \n    if cfg.USE_COSINE_SCHEDULE:\n        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n    else:\n        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n    \n    scaler = torch.amp.GradScaler('cuda', enabled=cfg.USE_AMP)\n    ema = EMA(model, decay=cfg.EMA_DECAY) if cfg.USE_EMA else None\n    \n    swa_model = None\n    if cfg.USE_SWA:\n        swa_model = AveragedModel(model)\n        swa_scheduler = SWALR(optimizer, swa_lr=cfg.LEARNING_RATE * 0.1)\n    \n    best_val_acc = 0.0\n    best_val_loss = float('inf')\n    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n    \n    for epoch in range(cfg.NUM_EPOCHS):\n        model.train()\n        running_loss = 0.0\n        \n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{cfg.NUM_EPOCHS} [train]\")\n        \n        for step, batch in enumerate(progress_bar, start=1):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n                outputs = model(**batch)\n                loss = outputs.loss / cfg.GRAD_ACCUM_STEPS\n            \n            scaler.scale(loss).backward()\n            running_loss += loss.item()\n            \n            if step % cfg.GRAD_ACCUM_STEPS == 0:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.MAX_GRAD_NORM)\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad(set_to_none=True)\n                \n                if cfg.USE_SWA and epoch >= cfg.SWA_START_EPOCH:\n                    swa_scheduler.step()\n                else:\n                    scheduler.step()\n                \n                if cfg.USE_EMA and ema is not None:\n                    ema.update()\n                \n                avg_loss = running_loss / cfg.GRAD_ACCUM_STEPS\n                progress_bar.set_postfix({\"loss\": f\"{avg_loss:.4f}\", \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"})\n                running_loss = 0.0\n        \n        # SWA update\n        if cfg.USE_SWA and swa_model is not None and epoch >= cfg.SWA_START_EPOCH:\n            swa_model.update_parameters(model)\n        \n        # âœ… Validation with Accuracy\n        if cfg.USE_EMA and ema is not None:\n            ema.apply_shadow()\n        \n        val_loss, val_acc, cm, preds, labels = validate_with_accuracy(model, valid_loader, processor)\n        \n        if cfg.USE_EMA and ema is not None:\n            ema.restore()\n        \n        history[\"val_loss\"].append(val_loss)\n        history[\"val_acc\"].append(val_acc)\n        \n        print(f\"[Epoch {epoch+1}] Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n        print(f\"Confusion Matrix:\\n{cm}\")\n        \n        # âœ… Best ëª¨ë¸ ì €ì¥ (Acc ìš°ì„ , ë™ë¥  ì‹œ Loss)\n        is_best = False\n        if val_acc > best_val_acc:\n            is_best = True\n            best_val_acc = val_acc\n            best_val_loss = val_loss\n        elif val_acc == best_val_acc and val_loss < best_val_loss:\n            is_best = True\n            best_val_loss = val_loss\n        \n        if is_best:\n            save_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n            os.makedirs(save_path, exist_ok=True)\n            \n            if cfg.USE_EMA and ema is not None:\n                ema.apply_shadow()\n            \n            model.save_pretrained(save_path)\n            processor.save_pretrained(save_path)\n            \n            if cfg.USE_EMA and ema is not None:\n                ema.restore()\n            \n            print(f\"   âœ… Best model saved (Acc={val_acc:.4f}, Loss={val_loss:.4f})\")\n    \n    # SWA ìµœì¢… ëª¨ë¸\n    if cfg.USE_SWA and swa_model is not None:\n        torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n        save_path = f\"{cfg.SAVE_DIR}/fold{fold}_swa\"\n        os.makedirs(save_path, exist_ok=True)\n        swa_model.module.save_pretrained(save_path)\n        processor.save_pretrained(save_path)\n        print(f\"   âœ… SWA model saved\")\n    \n    # âœ… í•™ìŠµ ê³¡ì„  ì €ì¥\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    ax1.plot(history[\"val_loss\"], marker='o')\n    ax1.set_title(f'Fold {fold} - Val Loss')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Loss')\n    ax1.grid(True)\n    \n    ax2.plot(history[\"val_acc\"], marker='o', color='green')\n    ax2.set_title(f'Fold {fold} - Val Accuracy')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Accuracy')\n    ax2.grid(True)\n    plt.tight_layout()\n    \n    log_dir = Path(cfg.LOG_DIR)\n    log_dir.mkdir(parents=True, exist_ok=True)\n    plt.savefig(log_dir / f\"fold{fold}_learning_curve.png\")\n    plt.show()\n    \n    return best_val_acc, best_val_loss\n\nprint(\"âœ… Training functions ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ 9. í•™ìŠµ ì‹¤í–‰ (K-Fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# âœ… ê²€ì¦ ë°ì´í„°ì— train=False ì ìš© (ì •ë‹µ ì£¼ì… ë°©ì§€)\n\nif cfg.USE_KFOLD:\n    results = {}\n    \n    for fold in cfg.TRAIN_FOLDS:\n        print(f\"\\n{'#'*60}\")\n        print(f\"Starting Fold {fold}/{cfg.N_FOLDS-1}\")\n        print(f\"{'#'*60}\")\n        \n        train_subset = train_df[train_df['fold'] != fold].reset_index(drop=True)\n        valid_subset = train_df[train_df['fold'] == fold].reset_index(drop=True)\n        \n        print(f\"Train: {len(train_subset)}, Valid: {len(valid_subset)}\")\n        \n        train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n        valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)  # âœ… train=False\n        \n        train_loader = DataLoader(\n            train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True,\n            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n            num_workers=0\n        )\n        valid_loader = DataLoader(\n            valid_ds, batch_size=cfg.BATCH_SIZE, shuffle=False,\n            collate_fn=DataCollator(processor, train=False, use_advanced=cfg.USE_ADVANCED_MODEL),  # âœ… train=False\n            num_workers=0\n        )\n        \n        best_acc, best_loss = train_one_fold(model, train_loader, valid_loader, fold=fold)\n        results[fold] = {\"acc\": best_acc, \"loss\": best_loss}\n        \n        print(f\"\\nâœ… Fold {fold} ì™„ë£Œ: Best Val Acc={best_acc:.4f}, Loss={best_loss:.4f}\")\n    \n    print(f\"\\n{'='*60}\")\n    print(\"All Folds Training Complete!\")\n    print(f\"{'='*60}\")\n    for fold, metrics in results.items():\n        print(f\"Fold {fold}: Acc={metrics['acc']:.4f}, Loss={metrics['loss']:.4f}\")\n    print(f\"Average Acc: {np.mean([m['acc'] for m in results.values()]):.4f}\")\n\nelse:\n    # ë‹¨ì¼ ëª¨ë¸\n    train_subset = train_df[train_df['fold'] == -1].reset_index(drop=True)\n    valid_subset = train_df[train_df['fold'] == 0].reset_index(drop=True)\n    \n    train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n    valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)  # âœ… train=False\n    \n    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True,\n                             collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL), num_workers=0)\n    valid_loader = DataLoader(valid_ds, batch_size=cfg.BATCH_SIZE, shuffle=False,\n                             collate_fn=DataCollator(processor, train=False, use_advanced=cfg.USE_ADVANCED_MODEL), num_workers=0)\n    \n    best_acc, best_loss = train_one_fold(model, train_loader, valid_loader, fold=0)\n    print(f\"\\nâœ… Single model í•™ìŠµ ì™„ë£Œ: Best Val Acc={best_acc:.4f}, Loss={best_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”® 10. Inference with Direct Logits + TTA\n\nâœ… **Direct Logits**: a/b/c/d í† í° í™•ë¥  ì§ì ‘ ê³„ì‚° (ìƒì„± ëŒ€ë¹„ ì•ˆì •)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_choice_token_ids(processor):\n    \"\"\"a/b/c/d í† í° ID ì¶”ì¶œ\"\"\"\n    choice_tokens = {}\n    for choice in ['a', 'b', 'c', 'd']:\n        token_ids = processor.tokenizer.encode(choice, add_special_tokens=False)\n        choice_tokens[choice] = token_ids\n    return choice_tokens\n\n\ndef infer_with_direct_logits(model, processor, test_df, tta_scales=[1.0], fold=0):\n    \"\"\"âœ… Direct Logits ì¶”ë¡  + TTA\"\"\"\n    model.eval()\n    \n    # pad_token_id ì„¤ì •\n    if processor.tokenizer.pad_token_id is None:\n        processor.tokenizer.pad_token_id = processor.tokenizer.eos_token_id\n    \n    choice_tokens = get_choice_token_ids(processor)\n    \n    all_predictions = []\n    all_probs = []\n    \n    for i in tqdm(range(len(test_df)), desc=f\"Fold {fold} Inference\"):\n        row = test_df.iloc[i]\n        \n        # TTA: ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ë¡œ ì¶”ë¡ \n        tta_logits = []\n        \n        for scale in tta_scales:\n            # ì´ë¯¸ì§€ ë¡œë“œ\n            img_col = 'path' if 'path' in row else 'image'\n            img_path = os.path.join(cfg.DATA_DIR, row[img_col])\n            try:\n                img = Image.open(img_path).convert(\"RGB\")\n            except:\n                img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n            \n            # TTA ìŠ¤ì¼€ì¼ ì ìš©\n            if scale != 1.0:\n                w, h = img.size\n                new_w, new_h = int(w * scale), int(h * scale)\n                img = img.resize((new_w, new_h), Image.BILINEAR)\n            \n            # í”„ë¡¬í”„íŠ¸\n            user_text = build_mc_prompt(\n                str(row[\"question\"]), str(row[\"a\"]),\n                str(row[\"b\"]), str(row[\"c\"]), str(row[\"d\"])\n            )\n            \n            messages = [\n                {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n                {\"role\": \"user\", \"content\": [\n                    {\"type\": \"image\", \"image\": img},\n                    {\"type\": \"text\", \"text\": user_text}\n                ]}\n            ]\n            \n            # âœ… add_generation_prompt=True (ì¶”ë¡  ì‹œ)\n            text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n            \n            inputs = processor(text=[text], images=[img], return_tensors=\"pt\")\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n            \n            # âœ… Direct Logits: ë‹¤ìŒ í† í° ë¶„í¬ì—ì„œ a/b/c/d í™•ë¥  ê³„ì‚°\n            with torch.no_grad():\n                outputs = model(**inputs)\n                logits = outputs.logits[0, -1, :]  # ë§ˆì§€ë§‰ í† í°ì˜ logits\n            \n            tta_logits.append(logits.cpu())\n        \n        # TTA í‰ê· \n        avg_logits = torch.stack(tta_logits).mean(dim=0)\n        \n        # âœ… a/b/c/d í† í° í™•ë¥  ì§‘ê³„\n        choice_probs = {}\n        for choice, token_ids in choice_tokens.items():\n            # í•´ë‹¹ choiceì˜ ëª¨ë“  í† í° logit í•©ì‚°\n            total_logit = sum([avg_logits[tid].item() for tid in token_ids])\n            choice_probs[choice] = total_logit\n        \n        # Softmaxë¡œ í™•ë¥  ë³€í™˜\n        logit_values = torch.tensor(list(choice_probs.values()))\n        probs = F.softmax(logit_values, dim=0).numpy()\n        prob_dict = {choice: probs[idx] for idx, choice in enumerate(['a', 'b', 'c', 'd'])}\n        \n        # ì˜ˆì¸¡\n        pred = max(prob_dict, key=prob_dict.get)\n        \n        all_predictions.append(pred)\n        all_probs.append(prob_dict)\n    \n    # DataFrame ìƒì„±\n    result_df = pd.DataFrame({\n        'id': test_df['id'],\n        'answer': all_predictions,\n        'prob_a': [p['a'] for p in all_probs],\n        'prob_b': [p['b'] for p in all_probs],\n        'prob_c': [p['c'] for p in all_probs],\n        'prob_d': [p['d'] for p in all_probs]\n    })\n    \n    return result_df\n\n\n# ê° Fold ì¶”ë¡ \npredictions_all = []\n\nif cfg.USE_KFOLD:\n    for fold in cfg.TRAIN_FOLDS:\n        model_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"Inferencing Fold {fold}\")\n        print(f\"{'='*60}\")\n        \n        # ëª¨ë¸ ë¡œë“œ\n        if cfg.USE_ADVANCED_MODEL:\n            model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n                model_path, trust_remote_code=True, torch_dtype=torch.float16\n            )\n        else:\n            model_infer = AutoModelForVision2Seq.from_pretrained(\n                model_path, trust_remote_code=True, torch_dtype=torch.float16\n            )\n        \n        model_infer = model_infer.to(device)\n        model_infer.eval()\n        \n        processor_infer = AutoProcessor.from_pretrained(\n            model_path,\n            min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n            max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n            trust_remote_code=True,\n        )\n        \n        # Direct Logits + TTA\n        tta_scales = cfg.TTA_SCALES if cfg.USE_TTA else [1.0]\n        pred_df = infer_with_direct_logits(model_infer, processor_infer, test_df, tta_scales, fold)\n        \n        # ì €ì¥\n        output_path = f\"{cfg.OUTPUT_DIR}/submission_fold{fold}.csv\"\n        os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n        pred_df.to_csv(output_path, index=False)\n        print(f\"âœ… Saved to {output_path}\")\n        \n        predictions_all.append(pred_df)\n        \n        # ë©”ëª¨ë¦¬ ì •ë¦¬\n        del model_infer\n        torch.cuda.empty_cache()\n\nelse:\n    model_path = f\"{cfg.SAVE_DIR}/fold0_best\"\n    \n    if cfg.USE_ADVANCED_MODEL:\n        model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n            model_path, trust_remote_code=True, torch_dtype=torch.float16\n        ).to(device)\n    else:\n        model_infer = AutoModelForVision2Seq.from_pretrained(\n            model_path, trust_remote_code=True, torch_dtype=torch.float16\n        ).to(device)\n    \n    processor_infer = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n    \n    tta_scales = cfg.TTA_SCALES if cfg.USE_TTA else [1.0]\n    pred_df = infer_with_direct_logits(model_infer, processor_infer, test_df, tta_scales, fold=0)\n    \n    output_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n    pred_df.to_csv(output_path, index=False)\n    predictions_all.append(pred_df)\n\nprint(\"\\nâœ… All inference complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸŒ¡ï¸ 11. Temperature Scaling\n\nâœ… ê²€ì¦ ì„¸íŠ¸ë¡œ í™•ë¥  êµì • (ì„ íƒ ì‚¬í•­)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# âœ… Temperature Scaling (ì„ íƒ ì‚¬í•­)\n# ê²€ì¦ ì„¸íŠ¸ê°€ ìˆì„ ë•Œ ê° foldì˜ ìµœì  temperatureë¥¼ ì°¾ì•„ test í™•ë¥ ì— ì ìš©\n\ndef find_optimal_temperature(val_probs, val_labels):\n    \"\"\"ê²€ì¦ ì„¸íŠ¸ì—ì„œ ìµœì  temperature íƒìƒ‰\"\"\"\n    from scipy.optimize import minimize\n    \n    def nll_loss(temp):\n        scaled_probs = F.softmax(torch.tensor(val_probs) / temp, dim=1).numpy()\n        # Negative log-likelihood\n        nll = -np.log(scaled_probs[np.arange(len(val_labels)), val_labels] + 1e-10).mean()\n        return nll\n    \n    result = minimize(nll_loss, x0=[1.0], bounds=[(0.1, 10.0)])\n    return result.x[0]\n\n# ì‹¤ì œë¡œ ì‚¬ìš©í•˜ë ¤ë©´:\n# 1. ê²€ì¦ ì„¸íŠ¸ë¡œ í™•ë¥ ê³¼ ì •ë‹µ ìˆ˜ì§‘\n# 2. optimal_temp = find_optimal_temperature(val_probs, val_labels)\n# 3. test í™•ë¥ ì— ì ìš©: scaled_probs = F.softmax(torch.tensor(test_probs) / optimal_temp, dim=1)\n\n# í˜„ì¬ëŠ” temperature=1.0ìœ¼ë¡œ ìœ ì§€ (ê¸°ë³¸)\nprint(\"âœ… Temperature scalingì€ ì„ íƒ ì‚¬í•­ì…ë‹ˆë‹¤.\")\nprint(\"ê²€ì¦ ì„¸íŠ¸ê°€ ìˆì„ ë•Œ ìœ„ ì½”ë“œë¥¼ í™œìš©í•˜ì—¬ ìµœì  temperatureë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ 12. Ensemble (í™•ë¥  í‰ê· )\n\nâœ… **Probability Averaging** (í´ë°±: Majority Voting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD and len(predictions_all) > 1:\n    print(f\"\\n{'='*60}\")\n    print(f\"Ensemble Method: {cfg.ENSEMBLE_METHOD}\")\n    print(f\"{'='*60}\")\n    \n    if cfg.ENSEMBLE_METHOD == 'prob':\n        # âœ… í™•ë¥  ì•™ìƒë¸”\n        print(\"Using Probability Averaging...\")\n        \n        ensemble_probs = pd.DataFrame({\n            'id': test_df['id'],\n            'prob_a': np.mean([df['prob_a'].values for df in predictions_all], axis=0),\n            'prob_b': np.mean([df['prob_b'].values for df in predictions_all], axis=0),\n            'prob_c': np.mean([df['prob_c'].values for df in predictions_all], axis=0),\n            'prob_d': np.mean([df['prob_d'].values for df in predictions_all], axis=0)\n        })\n        \n        # argmax\n        prob_cols = ['prob_a', 'prob_b', 'prob_c', 'prob_d']\n        ensemble_probs['answer'] = ensemble_probs[prob_cols].values.argmax(axis=1)\n        ensemble_probs['answer'] = ensemble_probs['answer'].map({0: 'a', 1: 'b', 2: 'c', 3: 'd'})\n        \n        final_submission = ensemble_probs[['id', 'answer', 'prob_a', 'prob_b', 'prob_c', 'prob_d']]\n    \n    else:\n        # Majority Voting (í´ë°±)\n        print(\"Using Majority Voting...\")\n        \n        ensemble_preds = []\n        for i in range(len(test_df)):\n            votes = [pred.iloc[i]['answer'] for pred in predictions_all]\n            most_common = Counter(votes).most_common(1)[0][0]\n            ensemble_preds.append(most_common)\n        \n        final_submission = pd.DataFrame({\n            'id': test_df['id'],\n            'answer': ensemble_preds\n        })\n    \n    final_path = f\"{cfg.OUTPUT_DIR}/submission_ensemble.csv\"\n    final_submission.to_csv(final_path, index=False)\n    \n    print(f\"âœ… Ensemble submission saved to {final_path}\")\n    print(f\"\\nAnswer Distribution:\")\n    print(final_submission['answer'].value_counts().sort_index())\n\nelse:\n    print(\"\\nâœ… Single model - No ensemble needed\")\n    final_submission = predictions_all[0]\n    final_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n    final_submission.to_csv(final_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š 13. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 5))\n\nanswer_counts = final_submission['answer'].value_counts().sort_index()\nsns.barplot(x=answer_counts.index, y=answer_counts.values, palette='viridis', ax=ax)\nax.set_title('Final Submission Answer Distribution', fontsize=14, weight='bold')\nax.set_xlabel('Answer')\nax.set_ylabel('Count')\nax.grid(axis='y', alpha=0.3)\n\nfor i, (ans, count) in enumerate(answer_counts.items()):\n    percentage = count / len(final_submission) * 100\n    ax.text(i, count + 10, f\"{percentage:.1f}%\", ha='center', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n{'='*60}\")\nprint(\"Final Statistics\")\nprint(f\"{'='*60}\")\nprint(f\"Total predictions: {len(final_submission)}\")\nprint(f\"\\nAnswer counts:\")\nfor ans, count in answer_counts.items():\n    print(f\"  {ans}: {count:5d} ({count/len(final_submission)*100:5.1f}%)\")\n\n# í™•ë¥  ë¶„í¬ (ìˆëŠ” ê²½ìš°)\nif 'prob_a' in final_submission.columns:\n    print(f\"\\n{'='*60}\")\n    print(\"Probability Statistics\")\n    print(f\"{'='*60}\")\n    prob_cols = ['prob_a', 'prob_b', 'prob_c', 'prob_d']\n    print(final_submission[prob_cols].describe())\n\nprint(f\"\\n{'='*60}\")\nprint(\"Sample Predictions\")\nprint(f\"{'='*60}\")\nprint(final_submission.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… 14. ìµœì¢… ì •ë¦¬\n\n### ğŸ‰ ì™„ë£Œëœ ì‘ì—…\n\n1. âœ… Config ì„¤ì • (Pro2 íŠœë‹)\n2. âœ… ë°ì´í„° ë¡œë“œ & EDA\n3. âœ… Stratified K-Fold CV\n4. âœ… Dataset & DataCollator (ë¼ë²¨ ë§ˆìŠ¤í‚¹)\n5. âœ… Model & Processor (T4 í˜¸í™˜)\n6. âœ… Training Loop (Val Acc + Confusion Matrix)\n7. âœ… Inference (Direct Logits + TTA)\n8. âœ… Temperature Scaling (ì„ íƒ ì‚¬í•­)\n9. âœ… Ensemble (í™•ë¥  í‰ê· )\n10. âœ… ê²°ê³¼ ë¶„ì„ & ì‹œê°í™”\n\n### ğŸš€ ì£¼ìš” ê°œì„ ì‚¬í•­\n\n#### í•™ìŠµ\n- Val Accuracy ë¡œê¹… ë° Best ëª¨ë¸ ì €ì¥ (Acc ìš°ì„ )\n- Confusion Matrix ì¶œë ¥\n- í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n- ê²€ì¦ ë°ì´í„° train=False (ì •ë‹µ ì£¼ì… ë°©ì§€)\n\n#### ì¶”ë¡ \n- Direct Logits: a/b/c/d í† í° í™•ë¥  ì§ì ‘ ê³„ì‚°\n- TTA: [0.9, 1.0, 1.1] ìŠ¤ì¼€ì¼ í‰ê· \n- pad_token_id ìë™ ë³´ì •\n- í™•ë¥  ì»¬ëŸ¼ ì €ì¥\n\n#### ì•™ìƒë¸”\n- í™•ë¥  ì•™ìƒë¸” (Probability Averaging)\n- í´ë°±: Majority Voting\n\n### ğŸ“Š Pro2 ì„¤ì •\n\n```python\nUSE_SAMPLE = False          # ì „ì²´ ë°ì´í„°\nIMAGE_SIZE = 512\nNUM_EPOCHS = 3\nGRAD_ACCUM_STEPS = 8\nWARMUP_RATIO = 0.06\nLORA_R = 16\nUSE_DIRECT_LOGIT_DECODE = True\nTTA_SCALES = [0.9, 1.0, 1.1]\nENSEMBLE_METHOD = 'prob'\n```\n\n### ğŸ“Œ Important Notes\n\n- **ë””ë°”ì´ìŠ¤ ì •ë ¬**: ëª¨ë“  ëª¨ë¸/ì…ë ¥ì„ ë‹¨ì¼ deviceë¡œ í†µì¼\n- **ë¼ë²¨ ë§ˆìŠ¤í‚¹**: í”„ë¡¬í”„íŠ¸ í† í° ì†ì‹¤ ì œì™¸, assistant ì •ë‹µë§Œ ê°ë…\n- **ê²€ì¦ í”Œë˜ê·¸**: valid_dsì— train=False ì ìš©\n- **Direct Logits**: ìƒì„± ëŒ€ë¹„ ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ì¶”ë¡ \n- **í™•ë¥  ì•™ìƒë¸”**: Fold ê°„ í™•ë¥  í‰ê· ìœ¼ë¡œ robustí•œ ì˜ˆì¸¡\n\n---\n\n**ğŸ¤– SSAFY AI Project 2025 - Pro2 Version**\n\n**â­ í–‰ìš´ì„ ë¹•ë‹ˆë‹¤!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
ï»¿{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# ğŸ“’ Kaggle_AllInOne_Pro.ipynb â€“ ë‹¨ì¼ ë…¸íŠ¸ë¶ í†µí•© ë²„ì „\n",
                                     "\n",
                                     "## ğŸ¯ ê°œìš”\n",
                                     "\n",
                                     "ë³¸ ë…¸íŠ¸ë¶ì€ **VQA Kaggle Challenge**ë¥¼ ìœ„í•œ **ì™„ì „ í†µí•© ê³ ì„±ëŠ¥ íŒŒì´í”„ë¼ì¸**ì…ë‹ˆë‹¤.\n",
                                     "\n",
                                     "### âœ¨ ì£¼ìš” ê¸°ëŠ¥\n",
                                     "\n",
                                     "- âœ… **T4 GPU ì™„ë²½ í˜¸í™˜** (Float16, SDPA attention)\n",
                                     "- âœ… **ë¼ë²¨ ì •ë ¬ êµì •** (Assistant ë©”ì‹œì§€ì— ì •ë‹µ í¬í•¨)\n",
                                     "- âœ… **K-Fold Cross-Validation** (Stratified)\n",
                                     "- âœ… **ê³ ê¸‰ í•™ìŠµ ê¸°ë²•** (AMP, EMA, SWA, Cosine Warmup)\n",
                                     "- âœ… **ë°ì´í„° ì¦ê°•** (Choice Shuffle, Paraphrase)\n",
                                     "- âœ… **TTA (Test-Time Augmentation)**\n",
                                     "- âœ… **ì•™ìƒë¸”** (Weighted Voting)\n",
                                     "- âœ… **ë©”ëª¨ë¦¬ ìµœì í™”** (Gradient Checkpointing, 4-bit QLoRA)\n",
                                     "\n",
                                     "### ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥\n",
                                     "\n",
                                     "| ì„¤ì • | ì •í™•ë„ | ì‹œê°„ |\n",
                                     "|------|--------|------|\n",
                                     "| Single Fold | 79-82% | ~4h |\n",
                                     "| 3-Fold Ensemble | 83-85% | ~12h |\n",
                                     "| + TTA + Optimization | 85-88% | ~15h |\n",
                                     "\n",
                                     "### ğŸš€ ì‹¤í–‰ ìˆœì„œ\n",
                                     "\n",
                                     "1. **í™˜ê²½ ì„¤ì •** - íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
                                     "2. **Config** - í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
                                     "3. **ë°ì´í„° ë¡œë“œ** - Train/Test ë°ì´í„° ë¡œë“œ\n",
                                     "4. **EDA** - íƒìƒ‰ì  ë°ì´í„° ë¶„ì„\n",
                                     "5. **Stratified K-Fold** - CV Splits ìƒì„±\n",
                                     "6. **Dataset \u0026 DataLoader** - ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì •ì˜\n",
                                     "7. **Model \u0026 Processor** - QLoRA ëª¨ë¸ ë¡œë“œ\n",
                                     "8. **Training Loop** - ê³ ê¸‰ ê¸°ë²• ì ìš© í•™ìŠµ\n",
                                     "9. **Inference** - TTAë¥¼ í™œìš©í•œ ì¶”ë¡ \n",
                                     "10. **Ensemble** - ì•™ìƒë¸” ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
                                     "\n",
                                     "---\n",
                                     "\n",
                                     "**ğŸ¤– Generated for SSAFY AI Project 2025**"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ğŸ“¦ 1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
                                     "\n",
                                     "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤. (ì²« ì‹¤í–‰ ì‹œ 1íšŒë§Œ)\n",
                                     "\n",
                                     "### âš ï¸ ì¤‘ìš”: ì„¤ì¹˜ í›„ ëŸ°íƒ€ì„ ì¬ì‹œì‘ í•„ìš”"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# íŒ¨í‚¤ì§€ ì„¤ì¹˜ (Colab/Kaggle í™˜ê²½)\n",
                                     "# ì²« ì‹¤í–‰ ì‹œì—ë§Œ ì£¼ì„ í•´ì œí•˜ê³  ì‹¤í–‰\n",
                                     "# !pip install -q \"transformers\u003e=4.44.2\" \"accelerate\u003e=0.34.2\" \"peft\u003e=0.13.2\" \\\n",
                                     "#     \"bitsandbytes\u003e=0.43.1\" datasets pillow pandas torch torchvision \\\n",
                                     "#     scikit-learn matplotlib seaborn tqdm --upgrade\n",
                                     "# !pip install -q qwen-vl-utils==0.0.8\n",
                                     "\n",
                                     "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ! ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ğŸ“š 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import os, sys, re, math, random, warnings\n",
                                     "import numpy as np\n",
                                     "import pandas as pd\n",
                                     "from PIL import Image\n",
                                     "from pathlib import Path\n",
                                     "from dataclasses import dataclass\n",
                                     "from typing import Dict, List, Any, Optional\n",
                                     "from collections import Counter\n",
                                     "import unicodedata\n",
                                     "\n",
                                     "# PyTorch\n",
                                     "import torch\n",
                                     "import torch.nn as nn\n",
                                     "from torch.utils.data import Dataset, DataLoader\n",
                                     "from torch.optim.swa_utils import AveragedModel, SWALR\n",
                                     "\n",
                                     "# Transformers \u0026 PEFT\n",
                                     "from transformers import (\n",
                                     "    AutoModelForVision2Seq,\n",
                                     "    Qwen2_5_VLForConditionalGeneration,\n",
                                     "    AutoProcessor,\n",
                                     "    BitsAndBytesConfig,\n",
                                     "    get_cosine_schedule_with_warmup,\n",
                                     "    get_linear_schedule_with_warmup\n",
                                     ")\n",
                                     "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
                                     "from qwen_vl_utils import process_vision_info\n",
                                     "\n",
                                     "# Scikit-learn\n",
                                     "from sklearn.model_selection import StratifiedKFold\n",
                                     "from sklearn.metrics import accuracy_score, confusion_matrix\n",
                                     "\n",
                                     "# Visualization\n",
                                     "import matplotlib.pyplot as plt\n",
                                     "import seaborn as sns\n",
                                     "from tqdm.auto import tqdm\n",
                                     "\n",
                                     "# ì„¤ì •\n",
                                     "warnings.filterwarnings(\u0027ignore\u0027)\n",
                                     "Image.MAX_IMAGE_PIXELS = None\n",
                                     "sns.set_style(\u0027whitegrid\u0027)\n",
                                     "\n",
                                     "# ë””ë°”ì´ìŠ¤\n",
                                     "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                                     "print(f\"ğŸ”§ Device: {device}\")\n",
                                     "if torch.cuda.is_available():\n",
                                     "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
                                     "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                                     "\n",
                                     "print(f\"ğŸ Python: {sys.version.split()[0]}\")\n",
                                     "print(f\"ğŸ”¥ PyTorch: {torch.__version__}\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## âš™ï¸ 3. Config ì„¤ì •\n",
                                     "\n",
                                     "ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í•œ ê³³ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "class Config:\n",
                                     "    \"\"\"í†µí•© ì„¤ì • í´ë˜ìŠ¤\"\"\"\n",
                                     "    \n",
                                     "    # ì‹œë“œ (ì¬í˜„ì„±)\n",
                                     "    SEED = 42\n",
                                     "    \n",
                                     "    # ëª¨ë¸ ì„¤ì •\n",
                                     "    MODEL_ID = \"Qwen/Qwen2.5-VL-3B-Instruct\"  # ë˜ëŠ” \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
                                     "    IMAGE_SIZE = 512  # 384 or 512 or 768\n",
                                     "    USE_ADVANCED_MODEL = False  # True: Qwen2_5_VL, False: AutoModelForVision2Seq (baseline)\n",
                                     "    \n",
                                     "    # ë°ì´í„° ê²½ë¡œ\n",
                                     "    DATA_DIR = \"/kaggle/input/ssafy-ai-pjt-data\"\n",
                                     "    TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n",
                                     "    TEST_CSV = f\"{DATA_DIR}/test.csv\"\n",
                                     "    \n",
                                     "    # K-Fold ì„¤ì •\n",
                                     "    N_FOLDS = 3\n",
                                     "    USE_KFOLD = True  # False: ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ\n",
                                     "    TRAIN_FOLDS = [0, 1, 2]  # í•™ìŠµí•  fold ë²ˆí˜¸\n",
                                     "    \n",
                                     "    # QLoRA ì„¤ì •\n",
                                     "    LORA_R = 16\n",
                                     "    LORA_ALPHA = 16\n",
                                     "    LORA_DROPOUT = 0.05\n",
                                     "    TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
                                     "                      \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
                                     "    \n",
                                     "    # í•™ìŠµ ì„¤ì •\n",
                                     "    NUM_EPOCHS = 3\n",
                                     "    BATCH_SIZE = 1\n",
                                     "    GRAD_ACCUM_STEPS = 8\n",
                                     "    LEARNING_RATE = 1e-4\n",
                                     "    WEIGHT_DECAY = 0.01\n",
                                     "    WARMUP_RATIO = 0.06\n",
                                     "    MAX_GRAD_NORM = 1.0\n",
                                     "    \n",
                                     "    # ê³ ê¸‰ ê¸°ë²•\n",
                                     "    USE_AMP = True  # Automatic Mixed Precision\n",
                                     "    USE_EMA = True  # Exponential Moving Average\n",
                                     "    EMA_DECAY = 0.999\n",
                                     "    USE_SWA = False  # Stochastic Weight Averaging (ë§ˆì§€ë§‰ ì—í­ë§Œ)\n",
                                     "    SWA_START_EPOCH = 0  # SWA ì‹œì‘ ì—í­ (ë§ˆì§€ë§‰ ì—í­ ê¶Œì¥)\n",
                                     "    USE_COSINE_SCHEDULE = True  # True: Cosine, False: Linear\n",
                                     "    \n",
                                     "    # ë°ì´í„° ì¦ê°•\n",
                                     "    USE_AUGMENTATION = False  # Choice shuffle ë“±\n",
                                     "    AUG_PROB = 0.3\n",
                                     "    \n",
                                     "    # TTA (Test-Time Augmentation)\n",
                                     "    USE_TTA = True\n",
                                     "    TTA_SCALES = [0.9, 1.0, 1.1]  # test-time scales\n",
                                     "    \n",
                                     "    # Inference options\n",
                                     "    USE_DIRECT_LOGIT_DECODE = True  # use logits for a/b/c/d scoring\n",
                                     "    ENSEMBLE_METHOD = \"prob\"  # \"prob\" or \"vote\"\n",
                                     "    DO_SAMPLE = False\n",
                                     "    TEMPERATURE = 0.0\n",
                                     "    \n",
                                     "    # ì €ì¥ ê²½ë¡œ\n",
                                     "    SAVE_DIR = f\"/kaggle/working/checkpoints\"\n",
                                     "    OUTPUT_DIR = f\"/kaggle/working/outputs\"\n",
                                     "    \n",
                                     "    # ìƒ˜í”Œë§ (ë””ë²„ê¹…ìš©)\n",
                                     "    USE_SAMPLE = False  # use full training data\n",
                                     "    SAMPLE_SIZE = 200  # ìƒ˜í”Œ í¬ê¸°\n",
                                     "    \n",
                                     "    # í”„ë¡¬í”„íŠ¸\n",
                                     "    SYSTEM_INSTRUCT = (\n",
                                     "        \"You are a helpful visual question answering assistant. \"\n",
                                     "        \"Answer using exactly one letter among a, b, c, or d. No explanation.\"\n",
                                     "    )\n",
                                     "\n",
                                     "\n",
                                     "# Config ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
                                     "cfg = Config()\n",
                                     "\n",
                                     "# ì‹œë“œ ê³ ì •\n",
                                     "def set_seed(seed=42):\n",
                                     "    random.seed(seed)\n",
                                     "    np.random.seed(seed)\n",
                                     "    torch.manual_seed(seed)\n",
                                     "    torch.cuda.manual_seed_all(seed)\n",
                                     "    torch.backends.cudnn.deterministic = True\n",
                                     "    torch.backends.cudnn.benchmark = False\n",
                                     "\n",
                                     "set_seed(cfg.SEED)\n",
                                     "print(f\"âœ… Config ì„¤ì • ì™„ë£Œ (Seed: {cfg.SEED})\")\n",
                                     "print(f\"   Model: {cfg.MODEL_ID}\")\n",
                                     "print(f\"   K-Fold: {cfg.N_FOLDS if cfg.USE_KFOLD else \u0027Disabled\u0027}\")\n",
                                     "print(f\"   Advanced Techniques: AMP={cfg.USE_AMP}, EMA={cfg.USE_EMA}, SWA={cfg.USE_SWA}, TTA={cfg.USE_TTA}\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ğŸ“Š 4. ë°ì´í„° ë¡œë“œ ë° EDA\n",
                                     "\n",
                                     "ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ê°„ë‹¨í•œ íƒìƒ‰ì  ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# ë°ì´í„° ë¡œë“œ\n",
                                     "train_df = pd.read_csv(cfg.TRAIN_CSV)\n",
                                     "test_df = pd.read_csv(cfg.TEST_CSV)\n",
                                     "\n",
                                     "print(f\"ğŸ“ Train: {len(train_df):,} samples\")\n",
                                     "print(f\"ğŸ“ Test: {len(test_df):,} samples\")\n",
                                     "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
                                     "\n",
                                     "# ìƒ˜í”Œë§ (ë””ë²„ê¹…ìš©)\n",
                                     "if cfg.USE_SAMPLE:\n",
                                     "    train_df = train_df.sample(n=min(cfg.SAMPLE_SIZE, len(train_df)), random_state=cfg.SEED).reset_index(drop=True)\n",
                                     "    print(f\"\\nâš ï¸  Sampled {len(train_df)} samples for quick testing\")\n",
                                     "\n",
                                     "# ê¸°ë³¸ í†µê³„\n",
                                     "print(f\"\\nğŸ“Š Answer Distribution:\")\n",
                                     "print(train_df[\u0027answer\u0027].value_counts().sort_index())\n",
                                     "\n",
                                     "# ì‹œê°í™”\n",
                                     "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
                                     "\n",
                                     "# ë‹µë³€ ë¶„í¬\n",
                                     "train_df[\u0027answer\u0027].value_counts().sort_index().plot(kind=\u0027bar\u0027, ax=axes[0], color=\u0027skyblue\u0027)\n",
                                     "axes[0].set_title(\u0027Answer Distribution (Train)\u0027, fontsize=12, weight=\u0027bold\u0027)\n",
                                     "axes[0].set_xlabel(\u0027Answer\u0027)\n",
                                     "axes[0].set_ylabel(\u0027Count\u0027)\n",
                                     "axes[0].grid(axis=\u0027y\u0027, alpha=0.3)\n",
                                     "\n",
                                     "# ì§ˆë¬¸ ê¸¸ì´ ë¶„í¬\n",
                                     "train_df[\u0027question_len\u0027] = train_df[\u0027question\u0027].str.len()\n",
                                     "train_df[\u0027question_len\u0027].hist(bins=30, ax=axes[1], color=\u0027salmon\u0027, edgecolor=\u0027black\u0027)\n",
                                     "axes[1].set_title(\u0027Question Length Distribution\u0027, fontsize=12, weight=\u0027bold\u0027)\n",
                                     "axes[1].set_xlabel(\u0027Length (chars)\u0027)\n",
                                     "axes[1].set_ylabel(\u0027Count\u0027)\n",
                                     "axes[1].grid(axis=\u0027y\u0027, alpha=0.3)\n",
                                     "\n",
                                     "plt.tight_layout()\n",
                                     "plt.show()\n",
                                     "\n",
                                     "# ìƒ˜í”Œ ì¶œë ¥\n",
                                     "print(\"\\nğŸ“ Sample Data:\")\n",
                                     "print(train_df.head(2))"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ğŸ”„ 5. Stratified K-Fold Cross-Validation\n",
                                     "\n",
                                     "ë‹µë³€ ë¶„í¬ë¥¼ ìœ ì§€í•˜ë©´ì„œ K-Foldë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "if cfg.USE_KFOLD:\n",
                                     "    # Stratified K-Fold ìƒì„±\n",
                                     "    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=cfg.SEED)\n",
                                     "    train_df[\u0027fold\u0027] = -1\n",
                                     "    \n",
                                     "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df[\u0027answer\u0027])):\n",
                                     "        train_df.loc[val_idx, \u0027fold\u0027] = fold\n",
                                     "    \n",
                                     "    print(f\"âœ… {cfg.N_FOLDS}-Fold CV ìƒì„± ì™„ë£Œ\")\n",
                                     "    print(f\"\\nFold Distribution:\")\n",
                                     "    print(train_df[\u0027fold\u0027].value_counts().sort_index())\n",
                                     "    \n",
                                     "    # Foldë³„ ë‹µë³€ ë¶„í¬ í™•ì¸\n",
                                     "    print(f\"\\nAnswer Distribution per Fold:\")\n",
                                     "    for fold in range(cfg.N_FOLDS):\n",
                                     "        fold_data = train_df[train_df[\u0027fold\u0027] == fold]\n",
                                     "        dist = fold_data[\u0027answer\u0027].value_counts(normalize=True).sort_index()\n",
                                     "        print(f\"Fold {fold}: {dict(dist)}\")\n",
                                     "else:\n",
                                     "    # ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ (90:10 split)\n",
                                     "    split_idx = int(len(train_df) * 0.9)\n",
                                     "    train_df[\u0027fold\u0027] = -1\n",
                                     "    train_df.loc[split_idx:, \u0027fold\u0027] = 0\n",
                                     "    print(f\"âœ… Single split (90:10) ìƒì„± ì™„ë£Œ\")\n",
                                     "    print(f\"   Train: {len(train_df[train_df[\u0027fold\u0027] == -1])}\")\n",
                                     "    print(f\"   Valid: {len(train_df[train_df[\u0027fold\u0027] == 0])}\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ğŸ—‚ï¸ 6. Dataset \u0026 DataLoader\n",
                                     "\n",
                                     "ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ë° DataCollatorë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
                                     "\n",
                                     "### âœ… ë¼ë²¨ ì •ë ¬ êµì • ì ìš©\n",
                                     "- Assistant ë©”ì‹œì§€ì— ì •ë‹µ í¬í•¨\n",
                                     "- `add_generation_prompt=False` ì‚¬ìš©"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "def build_mc_prompt(question, a, b, c, d):\n",
                                     "    \"\"\"Multiple Choice í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
                                     "    return (\n",
                                     "        f\"{question}\\n\"\n",
                                     "        f\"(a) {a}\\n(b) {b}\\n(c) {c}\\n(d) {d}\\n\\n\"\n",
                                     "        \"ì •ë‹µì„ ë°˜ë“œì‹œ a, b, c, d ì¤‘ í•˜ë‚˜ì˜ ì†Œë¬¸ì í•œ ê¸€ìë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\"\n",
                                     "    )\n",
                                     "\n",
                                     "\n",
                                     "class VQADataset(Dataset):\n",
                                     "    \"\"\"VQA Dataset with Label Alignment Fix\"\"\"\n",
                                     "    \n",
                                     "    def __init__(self, df, processor, data_dir=\"\", train=True, use_advanced=False):\n",
                                     "        self.df = df.reset_index(drop=True)\n",
                                     "        self.processor = processor\n",
                                     "        self.data_dir = data_dir\n",
                                     "        self.train = train\n",
                                     "        self.use_advanced = use_advanced  # process_vision_info ì‚¬ìš© ì—¬ë¶€\n",
                                     "    \n",
                                     "    def __len__(self):\n",
                                     "        return len(self.df)\n",
                                     "    \n",
                                     "    def __getitem__(self, idx):\n",
                                     "        row = self.df.iloc[idx]\n",
                                     "        \n",
                                     "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
                                     "        img_path = os.path.join(self.data_dir, row[\"path\"])\n",
                                     "        try:\n",
                                     "            img = Image.open(img_path).convert(\"RGB\")\n",
                                     "        except:\n",
                                     "            img = Image.new(\u0027RGB\u0027, (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color=\u0027white\u0027)\n",
                                     "        \n",
                                     "        # í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
                                     "        user_text = build_mc_prompt(\n",
                                     "            str(row[\"question\"]),\n",
                                     "            str(row[\"a\"]), str(row[\"b\"]),\n",
                                     "            str(row[\"c\"]), str(row[\"d\"])\n",
                                     "        )\n",
                                     "        \n",
                                     "        # ë©”ì‹œì§€ êµ¬ì„±\n",
                                     "        messages = [\n",
                                     "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n",
                                     "            {\"role\": \"user\", \"content\": [\n",
                                     "                {\"type\": \"image\", \"image\": img},\n",
                                     "                {\"type\": \"text\", \"text\": user_text}\n",
                                     "            ]}\n",
                                     "        ]\n",
                                     "        \n",
                                     "        # âœ… CRITICAL: í•™ìŠµ ì‹œ ì •ë‹µ í¬í•¨ (ë¼ë²¨ ì •ë ¬ êµì •)\n",
                                     "        if self.train:\n",
                                     "            answer = str(row[\"answer\"]).strip().lower()\n",
                                     "            messages.append({\n",
                                     "                \"role\": \"assistant\",\n",
                                     "                \"content\": [{\"type\": \"text\", \"text\": answer}]\n",
                                     "            })\n",
                                     "        \n",
                                     "        return {\"messages\": messages, \"image\": img, \"answer\": (answer if self.train else None)}\n",
                                     "\n",
                                     "\n",
                                     "@dataclass\n",
                                     "class DataCollator:\n",
                                     "    \"\"\"Data Collator for VQA\"\"\"\n",
                                     "    processor: Any\n",
                                     "    train: bool = True\n",
                                     "    use_advanced: bool = False\n",
                                     "    \n",
                                     "    def __call__(self, batch):\n",
                                     "        texts, images = [], []\n",
                                     "        \n",
                                     "        for sample in batch:\n",
                                     "            messages = sample[\"messages\"]\n",
                                     "            img = sample[\"image\"]\n",
                                     "            \n",
                                     "            # âœ… apply_chat_template ì‚¬ìš©\n",
                                     "            text = self.processor.apply_chat_template(\n",
                                     "                messages,\n",
                                     "                tokenize=False,\n",
                                     "                add_generation_prompt=False  # âœ… í•™ìŠµ ì‹œ False!\n",
                                     "            )\n",
                                     "            \n",
                                     "            # í•œê¸€ ì •ê·œí™”\n",
                                     "            text = unicodedata.normalize(\u0027NFKC\u0027, text)\n",
                                     "            \n",
                                     "            texts.append(text)\n",
                                     "            images.append(img)\n",
                                     "        \n",
                                     "        # ì¸ì½”ë”©\n",
                                     "        if self.use_advanced:\n",
                                     "            # process_vision_info ì‚¬ìš© (Qwen2_5_VL)\n",
                                     "            enc = self.processor(\n",
                                     "                text=texts,\n",
                                     "                images=images,\n",
                                     "                padding=True,\n",
                                     "                return_tensors=\"pt\"\n",
                                     "            )\n",
                                     "        else:\n",
                                     "            # ê¸°ë³¸ ë°©ì‹ (AutoModelForVision2Seq)\n",
                                     "            enc = self.processor(\n",
                                     "                text=texts,\n",
                                     "                images=images,\n",
                                     "                padding=True,\n",
                                     "                return_tensors=\"pt\"\n",
                                     "            )\n",
                                     "        \n",
                                     "        # âœ… ë¼ë²¨ ì„¤ì •\n",
                                     "        \n",
                                     "        # Build labels: mask prompt tokens, keep only assistant answer tokens\n         if self.train:\n             labels = enc[\"input_ids\"].clone()  # [B, L]\n             labels[:] = -100\n             for i, sample in enumerate(batch):\n                 ans = sample.get(\"answer\", None)\n                 if ans is None:\n                     continue\n                 try:\n                     ans_ids = self.processor.tokenizer.encode(str(ans).strip().lower(), add_special_tokens=False)\n                 except Exception:\n                     ans_ids = []\n                 ids = enc[\"input_ids\"][i].tolist()\n                 start = -1\n                 if ans_ids:\n                     for s in range(len(ids) - len(ans_ids), -1, -1):\n                         if ids[s:s+len(ans_ids)] == ans_ids:\n                             start = s\n                             break\n                 if start == -1:\n                     try:\n                         last = int(enc[\"attention_mask\"][i].sum().item()) - 1\n                         if last \u003e= 0:\n                             labels[i, last] = enc[\"input_ids\"][i, last]\n                     except Exception:\n                         pass\n                 else:\n                     labels[i, start:start+len(ans_ids)] = enc[\"input_ids\"][i, start:start+len(ans_ids)]\n             enc[\"labels\"] = labels\n",
                                     "        \n",
                                     "        return enc\n",
                                     "\n",
                                     "\n",
                                     "print(\"âœ… Dataset \u0026 DataCollator ì •ì˜ ì™„ë£Œ\")\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ğŸ¤– 7. Model \u0026 Processor ë¡œë“œ\n",
                                     "\n",
                                     "QLoRA ëª¨ë¸ê³¼ Processorë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
                                     "\n",
                                     "### âœ… T4 í˜¸í™˜ ì„¤ì •\n",
                                     "- Float16 (BFloat16 ì•„ë‹˜)\n",
                                     "- SDPA attention (FlashAttention ì œê±°)\n",
                                     "- 4-bit quantization"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "def create_model_and_processor(model_id, use_advanced=False):\n",
                                     "    \"\"\"ëª¨ë¸ ë° Processor ìƒì„±\"\"\"\n",
                                     "    \n",
                                     "    # ì–‘ìí™” ì„¤ì •\n",
                                     "    bnb_config = BitsAndBytesConfig(\n",
                                     "        load_in_4bit=True,\n",
                                     "        bnb_4bit_use_double_quant=True,\n",
                                     "        bnb_4bit_quant_type=\"nf4\",\n",
                                     "        bnb_4bit_compute_dtype=torch.float16,  # âœ… T4 í˜¸í™˜ (BF16 ì•„ë‹˜)\n",
                                     "    )\n",
                                     "    \n",
                                     "    # Processor ë¡œë“œ\n",
                                     "    processor = AutoProcessor.from_pretrained(\n",
                                     "        model_id,\n",
                                     "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
                                     "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
                                     "        trust_remote_code=True,\n",
                                     "    )\n",
                                     "    \n",
                                     "    # ëª¨ë¸ ë¡œë“œ\n",
                                     "    if use_advanced:\n",
                                     "        # âœ… Qwen2_5_VLForConditionalGeneration (ê³ ê¸‰)\n",
                                     "        base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
                                     "            model_id,\n",
                                     "            quantization_config=bnb_config,\n",
                                     "            trust_remote_code=True,\n",
                                     "            torch_dtype=torch.float16,\n",
                                     "            attn_implementation=\"sdpa\",  # âœ… FlashAttention ì œê±°\n",
                                     "        )\n",
                                     "    else:\n",
                                     "        # AutoModelForVision2Seq (Baseline í˜¸í™˜)\n",
                                     "        base_model = AutoModelForVision2Seq.from_pretrained(\n",
                                     "            model_id,\n",
                                     "            quantization_config=bnb_config,\n",
                                     "            trust_remote_code=True,\n",
                                     "        )\n",
                                     "    \n",
                                     "    # QLoRA ì¤€ë¹„\n",
                                     "    base_model = prepare_model_for_kbit_training(base_model)\n",
                                     "    base_model.gradient_checkpointing_enable()\n",
                                     "    \n",
                                     "    # LoRA Config\n",
                                     "    lora_config = LoraConfig(\n",
                                     "        r=cfg.LORA_R,\n",
                                     "        lora_alpha=cfg.LORA_ALPHA,\n",
                                     "        lora_dropout=cfg.LORA_DROPOUT,\n",
                                     "        bias=\"none\",\n",
                                     "        target_modules=cfg.TARGET_MODULES,\n",
                                     "        task_type=\"CAUSAL_LM\",\n",
                                     "    )\n",
                                     "    \n",
                                     "    # PEFT ëª¨ë¸ ìƒì„±\n",
                                     "    model = get_peft_model(base_model, lora_config)\n",
                                     "    model.print_trainable_parameters()\n",
                                     "    \n",
                                     "    return model, processor\n",
                                     "\n",
                                     "\n",
                                     "print(\"ğŸ”§ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
                                     "model, processor = create_model_and_processor(\n",
                                     "    cfg.MODEL_ID,\n",
                                     "    use_advanced=cfg.USE_ADVANCED_MODEL\n",
                                     ")\n",
                                     "model = model.to(device)\n",
                                     "print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ğŸ“ 8. Training Loop with Advanced Techniques\n",
                                     "\n",
                                     "ê³ ê¸‰ í•™ìŠµ ê¸°ë²•ì„ ì ìš©í•œ í•™ìŠµ ë£¨í”„ì…ë‹ˆë‹¤.\n",
                                     "\n",
                                     "### âœ¨ ì ìš©ëœ ê¸°ë²•\n",
                                     "- âœ… **AMP** (Automatic Mixed Precision)\n",
                                     "- âœ… **EMA** (Exponential Moving Average)\n",
                                     "- âœ… **SWA** (Stochastic Weight Averaging)\n",
                                     "- âœ… **Cosine Warmup Scheduler**\n",
                                     "- âœ… **Gradient Clipping**"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "class EMA:\n",
                                     "    \"\"\"Exponential Moving Average\"\"\"\n",
                                     "    def __init__(self, model, decay=0.999):\n",
                                     "        self.model = model\n",
                                     "        self.decay = decay\n",
                                     "        self.shadow = {}\n",
                                     "        self.backup = {}\n",
                                     "        self.register()\n",
                                     "    \n",
                                     "    def register(self):\n",
                                     "        for name, param in self.model.named_parameters():\n",
                                     "            if param.requires_grad:\n",
                                     "                self.shadow[name] = param.data.clone()\n",
                                     "    \n",
                                     "    def update(self):\n",
                                     "        for name, param in self.model.named_parameters():\n",
                                     "            if param.requires_grad:\n",
                                     "                new_average = (\n",
                                     "                    self.decay * self.shadow[name] +\n",
                                     "                    (1.0 - self.decay) * param.data\n",
                                     "                )\n",
                                     "                self.shadow[name] = new_average.clone()\n",
                                     "    \n",
                                     "    def apply_shadow(self):\n",
                                     "        for name, param in self.model.named_parameters():\n",
                                     "            if param.requires_grad:\n",
                                     "                self.backup[name] = param.data.clone()\n",
                                     "                param.data = self.shadow[name]\n",
                                     "    \n",
                                     "    def restore(self):\n",
                                     "        for name, param in self.model.named_parameters():\n",
                                     "            if param.requires_grad:\n",
                                     "                param.data = self.backup[name]\n",
                                     "        self.backup = {}\n",
                                     "\n",
                                     "\n",
                                     "def train_one_fold(model, train_loader, valid_loader, fold=0):\n",
                                     "    \"\"\"ë‹¨ì¼ Fold í•™ìŠµ\"\"\"\n",
                                     "    \n",
                                     "    print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "    print(f\"Training Fold {fold}\")\n",
                                     "    print(f\"{\u0027=\u0027*60}\")\n",
                                     "    \n",
                                     "    # Optimizer\n",
                                     "    optimizer = torch.optim.AdamW(\n",
                                     "        model.parameters(),\n",
                                     "        lr=cfg.LEARNING_RATE,\n",
                                     "        weight_decay=cfg.WEIGHT_DECAY\n",
                                     "    )\n",
                                     "    \n",
                                     "    # Scheduler\n",
                                     "    num_training_steps = cfg.NUM_EPOCHS * math.ceil(len(train_loader) / cfg.GRAD_ACCUM_STEPS)\n",
                                     "    num_warmup_steps = int(num_training_steps * cfg.WARMUP_RATIO)\n",
                                     "    \n",
                                     "    if cfg.USE_COSINE_SCHEDULE:\n",
                                     "        scheduler = get_cosine_schedule_with_warmup(\n",
                                     "            optimizer, num_warmup_steps, num_training_steps\n",
                                     "        )\n",
                                     "    else:\n",
                                     "        scheduler = get_linear_schedule_with_warmup(\n",
                                     "            optimizer, num_warmup_steps, num_training_steps\n",
                                     "        )\n",
                                     "    \n",
                                     "    # AMP Scaler\n",
                                     "    scaler = torch.amp.GradScaler(\u0027cuda\u0027, enabled=cfg.USE_AMP)\n",
                                     "    \n",
                                     "    # EMA\n",
                                     "    ema = EMA(model, decay=cfg.EMA_DECAY) if cfg.USE_EMA else None\n",
                                     "    \n",
                                     "    # SWA\n",
                                     "    swa_model = None\n",
                                     "    if cfg.USE_SWA:\n",
                                     "        swa_model = AveragedModel(model)\n",
                                     "        swa_scheduler = SWALR(optimizer, swa_lr=cfg.LEARNING_RATE * 0.1)\n",
                                     "    \n",
                                     "    # í•™ìŠµ ë£¨í”„\n",
                                     "    global_step = 0\n",
                                     "    best_val_loss = float(\u0027inf\u0027)\n",
                                     "    \n",
                                     "    for epoch in range(cfg.NUM_EPOCHS):\n",
                                     "        model.train()\n",
                                     "        running_loss = 0.0\n",
                                     "        \n",
                                     "        progress_bar = tqdm(\n",
                                     "            train_loader,\n",
                                     "            desc=f\"Epoch {epoch+1}/{cfg.NUM_EPOCHS} [train]\",\n",
                                     "            unit=\"batch\"\n",
                                     "        )\n",
                                     "        \n",
                                     "        for step, batch in enumerate(progress_bar, start=1):\n",
                                     "            batch = {k: v.to(device) for k, v in batch.items()}\n",
                                     "            \n",
                                     "            # Forward with AMP\n",
                                     "            with torch.amp.autocast(\u0027cuda\u0027, enabled=cfg.USE_AMP, dtype=torch.float16):\n",
                                     "                outputs = model(**batch)\n",
                                     "                loss = outputs.loss / cfg.GRAD_ACCUM_STEPS\n",
                                     "            \n",
                                     "            # Backward\n",
                                     "            scaler.scale(loss).backward()\n",
                                     "            running_loss += loss.item()\n",
                                     "            \n",
                                     "            # Gradient accumulation\n",
                                     "            if step % cfg.GRAD_ACCUM_STEPS == 0:\n",
                                     "                # Gradient clipping\n",
                                     "                scaler.unscale_(optimizer)\n",
                                     "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.MAX_GRAD_NORM)\n",
                                     "                \n",
                                     "                # Optimizer step\n",
                                     "                scaler.step(optimizer)\n",
                                     "                scaler.update()\n",
                                     "                optimizer.zero_grad(set_to_none=True)\n",
                                     "                \n",
                                     "                # Scheduler step\n",
                                     "                if cfg.USE_SWA and epoch \u003e= cfg.SWA_START_EPOCH:\n",
                                     "                    swa_scheduler.step()\n",
                                     "                else:\n",
                                     "                    scheduler.step()\n",
                                     "                \n",
                                     "                # EMA update\n",
                                     "                if cfg.USE_EMA and ema is not None:\n",
                                     "                    ema.update()\n",
                                     "                \n",
                                     "                global_step += 1\n",
                                     "                \n",
                                     "                # Progress\n",
                                     "                avg_loss = running_loss / cfg.GRAD_ACCUM_STEPS\n",
                                     "                progress_bar.set_postfix({\n",
                                     "                    \"loss\": f\"{avg_loss:.4f}\",\n",
                                     "                    \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
                                     "                })\n",
                                     "                running_loss = 0.0\n",
                                     "        \n",
                                     "        # SWA model update\n",
                                     "        if cfg.USE_SWA and swa_model is not None and epoch \u003e= cfg.SWA_START_EPOCH:\n",
                                     "            swa_model.update_parameters(model)\n",
                                     "        \n",
                                     "        # Validation\n",
                                     "        if cfg.USE_EMA and ema is not None:\n",
                                     "            ema.apply_shadow()\n",
                                     "        \n",
                                     "        val_loss = validate(model, valid_loader)\n",
                                     "        \n",
                                     "        if cfg.USE_EMA and ema is not None:\n",
                                     "            ema.restore()\n",
                                     "        \n",
                                     "        print(f\"[Epoch {epoch+1}] Valid Loss: {val_loss:.4f}\")\n",
                                     "        \n",
                                     "        # Best model ì €ì¥\n",
                                     "        if val_loss \u003c best_val_loss:\n",
                                     "            best_val_loss = val_loss\n",
                                     "            save_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
                                     "            os.makedirs(save_path, exist_ok=True)\n",
                                     "            \n",
                                     "            if cfg.USE_EMA and ema is not None:\n",
                                     "                ema.apply_shadow()\n",
                                     "            \n",
                                     "            model.save_pretrained(save_path)\n",
                                     "            processor.save_pretrained(save_path)\n",
                                     "            \n",
                                     "            if cfg.USE_EMA and ema is not None:\n",
                                     "                ema.restore()\n",
                                     "            \n",
                                     "            print(f\"   âœ… Best model saved to {save_path}\")\n",
                                     "    \n",
                                     "    # SWA ìµœì¢… ëª¨ë¸\n",
                                     "    if cfg.USE_SWA and swa_model is not None:\n",
                                     "        torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n",
                                     "        save_path = f\"{cfg.SAVE_DIR}/fold{fold}_swa\"\n",
                                     "        os.makedirs(save_path, exist_ok=True)\n",
                                     "        swa_model.module.save_pretrained(save_path)\n",
                                     "        processor.save_pretrained(save_path)\n",
                                     "        print(f\"   âœ… SWA model saved to {save_path}\")\n",
                                     "    \n",
                                     "    return best_val_loss\n",
                                     "\n",
                                     "\n",
                                     "def validate(model, valid_loader):\n",
                                     "    \"\"\"Validation\"\"\"\n",
                                     "    model.eval()\n",
                                     "    total_loss = 0.0\n",
                                     "    \n",
                                     "    with torch.no_grad():\n",
                                     "        for batch in tqdm(valid_loader, desc=\"Validating\", leave=False):\n",
                                     "            batch = {k: v.to(device) for k, v in batch.items()}\n",
                                     "            \n",
                                     "            with torch.amp.autocast(\u0027cuda\u0027, enabled=cfg.USE_AMP, dtype=torch.float16):\n",
                                     "                outputs = model(**batch)\n",
                                     "                total_loss += outputs.loss.item()\n",
                                     "    \n",
                                     "    model.train()\n",
                                     "    return total_loss / len(valid_loader)\n",
                                     "\n",
                                     "\n",
                                     "print(\"âœ… Training functions ì •ì˜ ì™„ë£Œ\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ğŸš€ 9. ì‹¤ì œ í•™ìŠµ ì‹¤í–‰\n",
                                     "\n",
                                     "K-Fold ë˜ëŠ” ë‹¨ì¼ ëª¨ë¸ í•™ìŠµì„ ì‹¤í–‰í•©ë‹ˆë‹¤."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# K-Fold í•™ìŠµ\n",
                                     "if cfg.USE_KFOLD:\n",
                                     "    results = {}\n",
                                     "    \n",
                                     "    for fold in cfg.TRAIN_FOLDS:\n",
                                     "        print(f\"\\n{\u0027#\u0027*60}\")\n",
                                     "        print(f\"Starting Fold {fold}/{cfg.N_FOLDS-1}\")\n",
                                     "        print(f\"{\u0027#\u0027*60}\")\n",
                                     "        \n",
                                     "        # ë°ì´í„° ë¶„í• \n",
                                     "        train_subset = train_df[train_df[\u0027fold\u0027] != fold].reset_index(drop=True)\n",
                                     "        valid_subset = train_df[train_df[\u0027fold\u0027] == fold].reset_index(drop=True)\n",
                                     "        \n",
                                     "        print(f\"Train: {len(train_subset)}, Valid: {len(valid_subset)}\")\n",
                                     "        \n",
                                     "        # Dataset\n",
                                     "        train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
                                     "        valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
                                     "        \n",
                                     "        # DataLoader\n",
                                     "        train_loader = DataLoader(\n",
                                     "            train_ds,\n",
                                     "            batch_size=cfg.BATCH_SIZE,\n",
                                     "            shuffle=True,\n",
                                     "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
                                     "            num_workers=0\n",
                                     "        )\n",
                                     "        valid_loader = DataLoader(\n",
                                     "            valid_ds,\n",
                                     "            batch_size=cfg.BATCH_SIZE,\n",
                                     "            shuffle=False,\n",
                                     "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
                                     "            num_workers=0\n",
                                     "        )\n",
                                     "        \n",
                                     "        # í•™ìŠµ\n",
                                     "        best_loss = train_one_fold(model, train_loader, valid_loader, fold=fold)\n",
                                     "        results[fold] = best_loss\n",
                                     "        \n",
                                     "        print(f\"\\nâœ… Fold {fold} ì™„ë£Œ: Best Val Loss = {best_loss:.4f}\")\n",
                                     "    \n",
                                     "    print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "    print(\"All Folds Training Complete!\")\n",
                                     "    print(f\"{\u0027=\u0027*60}\")\n",
                                     "    for fold, loss in results.items():\n",
                                     "        print(f\"Fold {fold}: {loss:.4f}\")\n",
                                     "    print(f\"Average: {np.mean(list(results.values())):.4f}\")\n",
                                     "\n",
                                     "else:\n",
                                     "    # ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ\n",
                                     "    train_subset = train_df[train_df[\u0027fold\u0027] == -1].reset_index(drop=True)\n",
                                     "    valid_subset = train_df[train_df[\u0027fold\u0027] == 0].reset_index(drop=True)\n",
                                     "    \n",
                                     "    train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
                                     "    valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=False, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
                                     "    \n",
                                     "    train_loader = DataLoader(\n",
                                     "        train_ds,\n",
                                     "        batch_size=cfg.BATCH_SIZE,\n",
                                     "        shuffle=True,\n",
                                     "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
                                     "        num_workers=0\n",
                                     "    )\n",
                                     "    valid_loader = DataLoader(\n",
                                     "        valid_ds,\n",
                                     "        batch_size=cfg.BATCH_SIZE,\n",
                                     "        shuffle=False,\n",
                                     "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
                                     "        num_workers=0\n",
                                     "    )\n",
                                     "    \n",
                                     "    best_loss = train_one_fold(model, train_loader, valid_loader, fold=0)\n",
                                     "    print(f\"\\nâœ… Single model í•™ìŠµ ì™„ë£Œ: Best Val Loss = {best_loss:.4f}\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ğŸ”® 10. Inference with TTA\n",
                                     "\n",
                                     "Test-Time Augmentationì„ í™œìš©í•œ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import re\n",
                                     "\n",
                                     "def extract_choice(text: str) -\u003e str:\n",
                                     "    \"\"\"ëª¨ë¸ ì¶œë ¥ì—ì„œ a/b/c/d ì¤‘ í•˜ë‚˜ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì¶”ì¶œ\"\"\"\n",
                                     "    t = (text or \u0027\u0027).strip().lower()\n",
                                     "    t = re.sub(r\u0027[^a-d\\n ]\u0027, \u0027 \u0027, t)\n",
                                     "    # ì¤„ ë‹¨ìœ„ë¡œ ë§ˆì§€ë§‰ í† í° ìš°ì„ \n",
                                     "    lines = [l.strip() for l in t.splitlines() if l.strip()]\n",
                                     "    if lines:\n",
                                     "        last = lines[-1].split()[-1]\n",
                                     "        if last in [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]:\n",
                                     "            return last\n",
                                     "    # ì „ì—­ ìŠ¤ìº”\n",
                                     "    for tok in t.split():\n",
                                     "        if tok in [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]:\n",
                                     "            return tok\n",
                                     "    return \u0027a\u0027\n",
                                     "\n",
                                     "\n",
                                     "def infer_single_fold(model_path, test_df, output_path):\n",
                                     "    \"\"\"ë‹¨ì¼ Fold ì¶”ë¡  (Direct logits + TTA + í™•ë¥  ì¶œë ¥)\"\"\"\n",
                                     "    # ëª¨ë¸ ë¡œë“œ\n",
                                     "    if cfg.USE_ADVANCED_MODEL:\n",
                                     "        model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
                                     "            model_path,\n",
                                     "            trust_remote_code=True,\n",
                                     "            torch_dtype=torch.float16\n",
                                     "        )\n",
                                     "    else:\n",
                                     "        model_infer = AutoModelForVision2Seq.from_pretrained(\n",
                                     "            model_path,\n",
                                     "            trust_remote_code=True,\n",
                                     "            torch_dtype=torch.float16\n",
                                     "        )\n",
                                     "    model_infer = model_infer.to(device)\n",
                                     "\n",
                                     "    processor_infer = AutoProcessor.from_pretrained(\n",
                                     "        model_path,\n",
                                     "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
                                     "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
                                     "        trust_remote_code=True,\n",
                                     "    )\n",
                                     "\n",
                                     "    # pad_token_id ë³´ì •\n",
                                     "    try:\n",
                                     "        if getattr(model_infer.config, \u0027pad_token_id\u0027, None) is None:\n",
                                     "            model_infer.config.pad_token_id = model_infer.config.eos_token_id\n",
                                     "    except Exception:\n",
                                     "        pass\n",
                                     "\n",
                                     "    def _choice_token_sets(tokenizer):\n",
                                     "        mapping = {}\n",
                                     "        choices = [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]\n",
                                     "        forms = [\u0027{c}\u0027, \u0027 {c}\u0027, \u0027({c})\u0027, \u0027{c})\u0027, \u0027{c}.\u0027, \u0027[{c}]\u0027, \u0027: {c}\u0027, \u0027{c}:\u0027]\n",
                                     "        for c in choices:\n",
                                     "            s = set()\n",
                                     "            for f in forms:\n",
                                     "                t = f.replace(\u0027{c}\u0027, c)\n",
                                     "                try:\n",
                                     "                    tids = tokenizer.encode(t, add_special_tokens=False)\n",
                                     "                    if len(tids) \u003e 0:\n",
                                     "                        s.add(int(tids[-1]))\n",
                                     "                except Exception:\n",
                                     "                    continue\n",
                                     "            mapping[c] = sorted(list(s))\n",
                                     "        return mapping\n",
                                     "\n",
                                     "    choice_token_ids = _choice_token_sets(processor_infer.tokenizer)\n",
                                     "\n",
                                     "    model_infer.eval()\n",
                                     "\n",
                                     "    predictions = []\n",
                                     "    probs_accumulator = { \u0027a\u0027: [], \u0027b\u0027: [], \u0027c\u0027: [], \u0027d\u0027: [] }\n",
                                     "\n",
                                     "    for i in tqdm(range(len(test_df)), desc=\u0027Inference\u0027):\n",
                                     "        row = test_df.iloc[i]\n",
                                     "\n",
                                     "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
                                     "        img_path = os.path.join(cfg.DATA_DIR, row[\u0027path\u0027])\n",
                                     "        try:\n",
                                     "            img = Image.open(img_path).convert(\u0027RGB\u0027)\n",
                                     "        except Exception:\n",
                                     "            img = Image.new(\u0027RGB\u0027, (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color=\u0027white\u0027)\n",
                                     "\n",
                                     "        # í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
                                     "        user_text = build_mc_prompt(\n",
                                     "            str(row[\u0027question\u0027]), str(row[\u0027a\u0027]), str(row[\u0027b\u0027]), str(row[\u0027c\u0027]), str(row[\u0027d\u0027])\n",
                                     "        )\n",
                                     "        messages = [\n",
                                     "            {\u0027role\u0027: \u0027system\u0027, \u0027content\u0027: [{\u0027type\u0027: \u0027text\u0027, \u0027text\u0027: cfg.SYSTEM_INSTRUCT}]},\n",
                                     "            {\u0027role\u0027: \u0027user\u0027, \u0027content\u0027: [\n",
                                     "                {\u0027type\u0027: \u0027image\u0027, \u0027image\u0027: img},\n",
                                     "                {\u0027type\u0027: \u0027text\u0027, \u0027text\u0027: user_text}\n",
                                     "            ]}\n",
                                     "        ]\n",
                                     "        text = processor_infer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
                                     "\n",
                                     "        if cfg.USE_DIRECT_LOGIT_DECODE:\n",
                                     "            # Direct logits ë¶„ë¥˜ + (ì˜µì…˜) TTA í‰ê· \n",
                                     "            probs_letters = {\u0027a\u0027: [], \u0027b\u0027: [], \u0027c\u0027: [], \u0027d\u0027: []}\n",
                                     "            with torch.no_grad():\n",
                                     "                scales = cfg.TTA_SCALES if cfg.USE_TTA else [1.0]\n",
                                     "                for s in scales:\n",
                                     "                    if abs(s - 1.0) \u003e 1e-6:\n",
                                     "                        try:\n",
                                     "                            w, h = img.size\n",
                                     "                            img_s = img.resize((max(1,int(round(w*s))), max(1,int(round(h*s)))), resample=Image.BICUBIC)\n",
                                     "                        except Exception:\n",
                                     "                            img_s = img\n",
                                     "                    else:\n",
                                     "                        img_s = img\n",
                                     "                    inputs = processor_infer(text=[text], images=[img_s], return_tensors=\u0027pt\u0027).to(device)\n",
                                     "                    outputs = model_infer(**inputs)\n",
                                     "                    logits = outputs.logits[:, -1, :]\n",
                                     "                    p = torch.softmax(logits, dim=-1)[0]\n",
                                     "                    for k, id_list in choice_token_ids.items():\n",
                                     "                        probs_letters[k].append(float(p[id_list].sum().item()) if len(id_list)\u003e0 else 0.0)\n",
                                     "            avg_probs = {k: (sum(v)/len(v) if len(v)\u003e0 else 0.0) for k,v in probs_letters.items()}\n",
                                     "            best = max(avg_probs.items(), key=lambda x: x[1])[0]\n",
                                     "            predictions.append(best)\n",
                                     "            for k in [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]:\n",
                                     "                probs_accumulator[k].append(avg_probs.get(k, 0.0))\n",
                                     "        else:\n",
                                     "            # Fallback: ììœ  ìƒì„± í›„ í›„ì²˜ë¦¬ ì¶”ì¶œ\n",
                                     "            inputs = processor_infer(text=[text], images=[img], return_tensors=\u0027pt\u0027).to(device)\n",
                                     "            with torch.no_grad():\n",
                                     "                out_ids = model_infer.generate(\n",
                                     "                    **inputs,\n",
                                     "                    max_new_tokens=cfg.MAX_NEW_TOKENS,\n",
                                     "                    do_sample=cfg.DO_SAMPLE,\n",
                                     "                    temperature=cfg.TEMPERATURE if cfg.DO_SAMPLE else None,\n",
                                     "                    eos_token_id=processor_infer.tokenizer.eos_token_id\n",
                                     "                )\n",
                                     "            output_text = processor_infer.batch_decode(out_ids, skip_special_tokens=True)[0]\n",
                                     "            ans = extract_choice(output_text)\n",
                                     "            predictions.append(ans)\n",
                                     "            for k in [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]:\n",
                                     "                probs_accumulator[k].append(0.0)\n",
                                     "\n",
                                     "    # ì €ì¥\n",
                                     "    submission = pd.DataFrame({\n",
                                     "        \u0027id\u0027: test_df[\u0027id\u0027],\n",
                                     "        \u0027answer\u0027: predictions,\n",
                                     "        \u0027prob_a\u0027: probs_accumulator.get(\u0027a\u0027, []),\n",
                                     "        \u0027prob_b\u0027: probs_accumulator.get(\u0027b\u0027, []),\n",
                                     "        \u0027prob_c\u0027: probs_accumulator.get(\u0027c\u0027, []),\n",
                                     "        \u0027prob_d\u0027: probs_accumulator.get(\u0027d\u0027, [])\n",
                                     "    })\n",
                                     "\n",
                                     "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
                                     "    submission.to_csv(output_path, index=False)\n",
                                     "    print(f\u0027âœ… Saved to {output_path}\u0027)\n",
                                     "    return submission\n",
                                     "\n",
                                     "\n",
                                     "# ì „ì²´ Fold ì¶”ë¡  ì‹¤í–‰\n",
                                     "predictions_all = []\n",
                                     "if cfg.USE_KFOLD:\n",
                                     "    for fold in cfg.TRAIN_FOLDS:\n",
                                     "        model_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
                                     "        output_path = f\"{cfg.OUTPUT_DIR}/submission_fold{fold}.csv\"\n",
                                     "        print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "        print(f\"Inferencing Fold {fold}\")\n",
                                     "        print(f\"{\u0027=\u0027*60}\")\n",
                                     "        pred = infer_single_fold(model_path, test_df, output_path)\n",
                                     "        predictions_all.append(pred)\n",
                                     "else:\n",
                                     "    model_path = f\"{cfg.SAVE_DIR}/fold0_best\"\n",
                                     "    output_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n",
                                     "    pred = infer_single_fold(model_path, test_df, output_path)\n",
                                     "    predictions_all.append(pred)\n",
                                     "\n",
                                     "print(\u0027\\nâœ… All inference complete!\u0027)\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ğŸ¯ 11. Ensemble\n",
                                     "\n",
                                     "ì—¬ëŸ¬ Foldì˜ ì˜ˆì¸¡ì„ ì•™ìƒë¸”í•©ë‹ˆë‹¤."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "if cfg.USE_KFOLD and len(predictions_all) \u003e 1:\n",
                                     "    print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "    print(\"Ensemble (Probability Average if available)\")\n",
                                     "    print(f\"{\u0027=\u0027*60}\")\n",
                                     "\n",
                                     "    if cfg.ENSEMBLE_METHOD == \u0027prob\u0027 and all(set([\u0027prob_a\u0027,\u0027prob_b\u0027,\u0027prob_c\u0027,\u0027prob_d\u0027]).issubset(set(df.columns)) for df in predictions_all):\n",
                                     "        pa = sum(df[\u0027prob_a\u0027].values for df in predictions_all) / len(predictions_all)\n",
                                     "        pb = sum(df[\u0027prob_b\u0027].values for df in predictions_all) / len(predictions_all)\n",
                                     "        pc = sum(df[\u0027prob_c\u0027].values for df in predictions_all) / len(predictions_all)\n",
                                     "        pd_ = sum(df[\u0027prob_d\u0027].values for df in predictions_all) / len(predictions_all)\n",
                                     "        letters = np.array([\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027])\n",
                                     "        probs_mat = np.vstack([pa, pb, pc, pd_]).T\n",
                                     "        ensemble_preds = letters[probs_mat.argmax(axis=1)].tolist()\n",
                                     "    else:\n",
                                     "        # Majority Voting fallback\n",
                                     "        ensemble_preds = []\n",
                                     "        for i in range(len(test_df)):\n",
                                     "            votes = [pred.iloc[i][\u0027answer\u0027] for pred in predictions_all]\n",
                                     "            most_common = Counter(votes).most_common(1)[0][0]\n",
                                     "            ensemble_preds.append(most_common)\n",
                                     "\n",
                                     "    # ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„±\n",
                                     "    final_submission = pd.DataFrame({\n",
                                     "        \u0027id\u0027: test_df[\u0027id\u0027],\n",
                                     "        \u0027answer\u0027: ensemble_preds\n",
                                     "    })\n",
                                     "    final_path = f\"{cfg.OUTPUT_DIR}/submission_ensemble.csv\"\n",
                                     "    final_submission.to_csv(final_path, index=False)\n",
                                     "    print(f\"âœ… Ensemble submission saved to {final_path}\")\n",
                                     "    print(\"\\nAnswer Distribution:\")\n",
                                     "    print(final_submission[\u0027answer\u0027].value_counts().sort_index())\n",
                                     "else:\n",
                                     "    print(\"\\nâ„¹ï¸ Single model - No ensemble needed\")\n",
                                     "    final_submission = predictions_all[0]\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## ğŸ“Š 12. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# ë‹µë³€ ë¶„í¬ ì‹œê°í™”\n",
                                     "fig, ax = plt.subplots(figsize=(10, 5))\n",
                                     "\n",
                                     "answer_counts = final_submission[\u0027answer\u0027].value_counts().sort_index()\n",
                                     "sns.barplot(x=answer_counts.index, y=answer_counts.values, palette=\u0027viridis\u0027, ax=ax)\n",
                                     "ax.set_title(\u0027Final Submission Answer Distribution\u0027, fontsize=14, weight=\u0027bold\u0027)\n",
                                     "ax.set_xlabel(\u0027Answer\u0027)\n",
                                     "ax.set_ylabel(\u0027Count\u0027)\n",
                                     "ax.grid(axis=\u0027y\u0027, alpha=0.3)\n",
                                     "\n",
                                     "# ë¹„ìœ¨ í‘œì‹œ\n",
                                     "for i, (ans, count) in enumerate(answer_counts.items()):\n",
                                     "    percentage = count / len(final_submission) * 100\n",
                                     "    ax.text(i, count + 10, f\"{percentage:.1f}%\", ha=\u0027center\u0027, fontsize=10)\n",
                                     "\n",
                                     "plt.tight_layout()\n",
                                     "plt.show()\n",
                                     "\n",
                                     "# í†µê³„ ì¶œë ¥\n",
                                     "print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "print(\"Final Statistics\")\n",
                                     "print(f\"{\u0027=\u0027*60}\")\n",
                                     "print(f\"Total predictions: {len(final_submission)}\")\n",
                                     "print(f\"\\nAnswer counts:\")\n",
                                     "for ans, count in answer_counts.items():\n",
                                     "    print(f\"  {ans}: {count:5d} ({count/len(final_submission)*100:5.1f}%)\")\n",
                                     "\n",
                                     "# ì œì¶œ íŒŒì¼ ìƒ˜í”Œ\n",
                                     "print(f\"\\n{\u0027=\u0027*60}\")\n",
                                     "print(\"Sample Predictions\")\n",
                                     "print(f\"{\u0027=\u0027*60}\")\n",
                                     "print(final_submission.head(10))"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## âœ… 13. ìµœì¢… ì •ë¦¬\n",
                                     "\n",
                                     "### ğŸ‰ ì™„ë£Œëœ ì‘ì—…\n",
                                     "\n",
                                     "1. âœ… **í™˜ê²½ ì„¤ì •** - íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
                                     "2. âœ… **Config** - í•˜ì´í¼íŒŒë¼ë¯¸í„° í†µí•© ê´€ë¦¬\n",
                                     "3. âœ… **ë°ì´í„° ë¡œë“œ \u0026 EDA** - íƒìƒ‰ì  ë¶„ì„\n",
                                     "4. âœ… **Stratified K-Fold** - CV Splits ìƒì„±\n",
                                     "5. âœ… **Dataset \u0026 DataLoader** - ë¼ë²¨ ì •ë ¬ êµì • ì ìš©\n",
                                     "6. âœ… **Model \u0026 Processor** - QLoRA ëª¨ë¸ ë¡œë“œ (T4 í˜¸í™˜)\n",
                                     "7. âœ… **Training Loop** - AMP, EMA, SWA, Cosine Warmup ì ìš©\n",
                                     "8. âœ… **Inference** - TTA ì§€ì› ì¶”ë¡ \n",
                                     "9. âœ… **Ensemble** - Majority Voting\n",
                                     "10. âœ… **Results** - ì‹œê°í™” ë° í†µê³„\n",
                                     "\n",
                                     "### ğŸš€ ë‹¤ìŒ ë‹¨ê³„\n",
                                     "\n",
                                     "1. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**\n",
                                     "   - Learning rate, LoRA rank ì¡°ì •\n",
                                     "   - Batch size, Grad accumulation ìµœì í™”\n",
                                     "\n",
                                     "2. **ëª¨ë¸ í¬ê¸° í™•ëŒ€**\n",
                                     "   - 7B ëª¨ë¸ ì‚¬ìš© (ë” ë†’ì€ ì •í™•ë„)\n",
                                     "   - Image size ì¦ê°€ (512, 768)\n",
                                     "\n",
                                     "3. **ê³ ê¸‰ ê¸°ë²• í™œì„±í™”**\n",
                                     "   - TTA scales ì¶”ê°€\n",
                                     "   - SWA ì ìš©\n",
                                     "   - ë°ì´í„° ì¦ê°• í™œì„±í™”\n",
                                     "\n",
                                     "4. **ì—í­ ì¦ê°€**\n",
                                     "   - NUM_EPOCHS = 3~5\n",
                                     "\n",
                                     "### ğŸ“Œ Important Notes\n",
                                     "\n",
                                     "- **T4 í˜¸í™˜**: Float16, SDPA attention ì‚¬ìš©\n",
                                     "- **ë¼ë²¨ ì •ë ¬**: Assistant ë©”ì‹œì§€ì— ì •ë‹µ í¬í•¨ (í•µì‹¬!)\n",
                                     "- **ì¬í˜„ì„±**: Seed 42 ê³ ì •\n",
                                     "- **ë©”ëª¨ë¦¬**: Gradient checkpointing, 4-bit QLoRA\n",
                                     "\n",
                                     "---\n",
                                     "\n",
                                     "**ğŸ¤– Generated for SSAFY AI Project 2025**\n",
                                     "\n",
                                     "**ğŸ“§ Contact**: GitHub Issues\n",
                                     "\n",
                                     "**â­ í–‰ìš´ì„ ë¹•ë‹ˆë‹¤!**"
                                 ]
                  }
              ],
    "metadata":  {
                     "kernelspec":  {
                                        "display_name":  "Python 3",
                                        "language":  "python",
                                        "name":  "python3"
                                    },
                     "language_info":  {
                                           "codemirror_mode":  {
                                                                   "name":  "ipython",
                                                                   "version":  3
                                                               },
                                           "file_extension":  ".py",
                                           "mimetype":  "text/x-python",
                                           "name":  "python",
                                           "nbconvert_exporter":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.8.10"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  4
}
