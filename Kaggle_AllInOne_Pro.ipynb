{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“’ Kaggle_AllInOne_Pro.ipynb â€“ ë‹¨ì¼ ë…¸íŠ¸ë¶ í†µí•© ë²„ì „\n",
    "\n",
    "## ğŸ¯ ê°œìš”\n",
    "\n",
    "ë³¸ ë…¸íŠ¸ë¶ì€ **VQA Kaggle Challenge**ë¥¼ ìœ„í•œ **ì™„ì „ í†µí•© ê³ ì„±ëŠ¥ íŒŒì´í”„ë¼ì¸**ì…ë‹ˆë‹¤.\n",
    "\n",
    "### âœ¨ ì£¼ìš” ê¸°ëŠ¥\n",
    "\n",
    "- âœ… **T4 GPU ì™„ë²½ í˜¸í™˜** (Float16, SDPA attention)\n",
    "- âœ… **ë¼ë²¨ ì •ë ¬ êµì •** (Assistant ë©”ì‹œì§€ì— ì •ë‹µ í¬í•¨)\n",
    "- âœ… **K-Fold Cross-Validation** (Stratified)\n",
    "- âœ… **ê³ ê¸‰ í•™ìŠµ ê¸°ë²•** (AMP, EMA, SWA, Cosine Warmup)\n",
    "- âœ… **ë°ì´í„° ì¦ê°•** (Choice Shuffle, Paraphrase)\n",
    "- âœ… **TTA (Test-Time Augmentation)**\n",
    "- âœ… **ì•™ìƒë¸”** (Weighted Voting)\n",
    "- âœ… **ë©”ëª¨ë¦¬ ìµœì í™”** (Gradient Checkpointing, 4-bit QLoRA)\n",
    "\n",
    "### ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥\n",
    "\n",
    "| ì„¤ì • | ì •í™•ë„ | ì‹œê°„ |\n",
    "|------|--------|------|\n",
    "| Single Fold | 79-82% | ~4h |\n",
    "| 3-Fold Ensemble | 83-85% | ~12h |\n",
    "| + TTA + Optimization | 85-88% | ~15h |\n",
    "\n",
    "### ğŸš€ ì‹¤í–‰ ìˆœì„œ\n",
    "\n",
    "1. **í™˜ê²½ ì„¤ì •** - íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
    "2. **Config** - í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "3. **ë°ì´í„° ë¡œë“œ** - Train/Test ë°ì´í„° ë¡œë“œ\n",
    "4. **EDA** - íƒìƒ‰ì  ë°ì´í„° ë¶„ì„\n",
    "5. **Stratified K-Fold** - CV Splits ìƒì„±\n",
    "6. **Dataset & DataLoader** - ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì •ì˜\n",
    "7. **Model & Processor** - QLoRA ëª¨ë¸ ë¡œë“œ\n",
    "8. **Training Loop** - ê³ ê¸‰ ê¸°ë²• ì ìš© í•™ìŠµ\n",
    "9. **Inference** - TTAë¥¼ í™œìš©í•œ ì¶”ë¡ \n",
    "10. **Ensemble** - ì•™ìƒë¸” ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ¤– Generated for SSAFY AI Project 2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ 1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "\n",
    "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤. (ì²« ì‹¤í–‰ ì‹œ 1íšŒë§Œ)\n",
    "\n",
    "### âš ï¸ ì¤‘ìš”: ì„¤ì¹˜ í›„ ëŸ°íƒ€ì„ ì¬ì‹œì‘ í•„ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ ì„¤ì¹˜ (Colab/Kaggle í™˜ê²½)\n",
    "# ì²« ì‹¤í–‰ ì‹œì—ë§Œ ì£¼ì„ í•´ì œí•˜ê³  ì‹¤í–‰\n",
    "# !pip install -q \"transformers>=4.44.2\" \"accelerate>=0.34.2\" \"peft>=0.13.2\" \\\n",
    "#     \"bitsandbytes>=0.43.1\" datasets pillow pandas torch torchvision \\\n",
    "#     scikit-learn matplotlib seaborn tqdm --upgrade\n",
    "# !pip install -q qwen-vl-utils==0.0.8\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ! ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, math, random, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Any, Optional\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "\n",
    "# Transformers & PEFT\n",
    "from transformers import (\n",
    "    AutoModelForVision2Seq,\n",
    "    Qwen2_5_VLForConditionalGeneration,\n",
    "    AutoProcessor,\n",
    "    BitsAndBytesConfig,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ì„¤ì •\n",
    "warnings.filterwarnings('ignore')\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸ”§ Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "print(f\"ğŸ Python: {sys.version.split()[0]}\")\n",
    "print(f\"ğŸ”¥ PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ 3. Config ì„¤ì •\n",
    "\n",
    "ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í•œ ê³³ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"í†µí•© ì„¤ì • í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    # ì‹œë“œ (ì¬í˜„ì„±)\n",
    "    SEED = 42\n",
    "    \n",
    "    # ëª¨ë¸ ì„¤ì •\n",
    "    MODEL_ID = \"Qwen/Qwen2.5-VL-3B-Instruct\"  # ë˜ëŠ” \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "    IMAGE_SIZE = 384  # 384 or 512 or 768\n",
    "    USE_ADVANCED_MODEL = False  # True: Qwen2_5_VL, False: AutoModelForVision2Seq (baseline)\n",
    "    \n",
    "    # ë°ì´í„° ê²½ë¡œ\n",
    "    DATA_DIR = \"/content\"  # Colab ê¸°ë³¸ ê²½ë¡œ\n",
    "    TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n",
    "    TEST_CSV = f\"{DATA_DIR}/test.csv\"\n",
    "    \n",
    "    # K-Fold ì„¤ì •\n",
    "    N_FOLDS = 3\n",
    "    USE_KFOLD = True  # False: ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ\n",
    "    TRAIN_FOLDS = [0, 1, 2]  # í•™ìŠµí•  fold ë²ˆí˜¸\n",
    "    \n",
    "    # QLoRA ì„¤ì •\n",
    "    LORA_R = 8\n",
    "    LORA_ALPHA = 16\n",
    "    LORA_DROPOUT = 0.05\n",
    "    TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "    \n",
    "    # í•™ìŠµ ì„¤ì •\n",
    "    NUM_EPOCHS = 1\n",
    "    BATCH_SIZE = 1\n",
    "    GRAD_ACCUM_STEPS = 4\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    WARMUP_RATIO = 0.03\n",
    "    MAX_GRAD_NORM = 1.0\n",
    "    \n",
    "    # ê³ ê¸‰ ê¸°ë²•\n",
    "    USE_AMP = True  # Automatic Mixed Precision\n",
    "    USE_EMA = True  # Exponential Moving Average\n",
    "    EMA_DECAY = 0.999\n",
    "    USE_SWA = False  # Stochastic Weight Averaging (ë§ˆì§€ë§‰ ì—í­ë§Œ)\n",
    "    SWA_START_EPOCH = 0  # SWA ì‹œì‘ ì—í­ (ë§ˆì§€ë§‰ ì—í­ ê¶Œì¥)\n",
    "    USE_COSINE_SCHEDULE = True  # True: Cosine, False: Linear\n",
    "    \n",
    "    # ë°ì´í„° ì¦ê°•\n",
    "    USE_AUGMENTATION = False  # Choice shuffle ë“±\n",
    "    AUG_PROB = 0.3\n",
    "    \n",
    "    # TTA (Test-Time Augmentation)\n",
    "    USE_TTA = False\n",
    "    TTA_SCALES = [1.0]  # [0.9, 1.0, 1.1] ë“±\n",
    "    \n",
    "    # ì¶”ë¡  ì„¤ì •\n",
    "    MAX_NEW_TOKENS = 8\n",
    "    DO_SAMPLE = False\n",
    "    TEMPERATURE = 0.0\n",
    "    \n",
    "    # ì €ì¥ ê²½ë¡œ\n",
    "    SAVE_DIR = f\"{DATA_DIR}/checkpoints\"\n",
    "    OUTPUT_DIR = f\"{DATA_DIR}/outputs\"\n",
    "    \n",
    "    # ìƒ˜í”Œë§ (ë””ë²„ê¹…ìš©)\n",
    "    USE_SAMPLE = True  # True: ì¼ë¶€ ë°ì´í„°ë§Œ ì‚¬ìš©\n",
    "    SAMPLE_SIZE = 200  # ìƒ˜í”Œ í¬ê¸°\n",
    "    \n",
    "    # í”„ë¡¬í”„íŠ¸\n",
    "    SYSTEM_INSTRUCT = (\n",
    "        \"You are a helpful visual question answering assistant. \"\n",
    "        \"Answer using exactly one letter among a, b, c, or d. No explanation.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Config ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "cfg = Config()\n",
    "\n",
    "# ì‹œë“œ ê³ ì •\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(cfg.SEED)\n",
    "print(f\"âœ… Config ì„¤ì • ì™„ë£Œ (Seed: {cfg.SEED})\")\n",
    "print(f\"   Model: {cfg.MODEL_ID}\")\n",
    "print(f\"   K-Fold: {cfg.N_FOLDS if cfg.USE_KFOLD else 'Disabled'}\")\n",
    "print(f\"   Advanced Techniques: AMP={cfg.USE_AMP}, EMA={cfg.USE_EMA}, SWA={cfg.USE_SWA}, TTA={cfg.USE_TTA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 4. ë°ì´í„° ë¡œë“œ ë° EDA\n",
    "\n",
    "ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ê°„ë‹¨í•œ íƒìƒ‰ì  ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(cfg.TRAIN_CSV)\n",
    "test_df = pd.read_csv(cfg.TEST_CSV)\n",
    "\n",
    "print(f\"ğŸ“ Train: {len(train_df):,} samples\")\n",
    "print(f\"ğŸ“ Test: {len(test_df):,} samples\")\n",
    "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
    "\n",
    "# ìƒ˜í”Œë§ (ë””ë²„ê¹…ìš©)\n",
    "if cfg.USE_SAMPLE:\n",
    "    train_df = train_df.sample(n=min(cfg.SAMPLE_SIZE, len(train_df)), random_state=cfg.SEED).reset_index(drop=True)\n",
    "    print(f\"\\nâš ï¸  Sampled {len(train_df)} samples for quick testing\")\n",
    "\n",
    "# ê¸°ë³¸ í†µê³„\n",
    "print(f\"\\nğŸ“Š Answer Distribution:\")\n",
    "print(train_df['answer'].value_counts().sort_index())\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# ë‹µë³€ ë¶„í¬\n",
    "train_df['answer'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Answer Distribution (Train)', fontsize=12, weight='bold')\n",
    "axes[0].set_xlabel('Answer')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# ì§ˆë¬¸ ê¸¸ì´ ë¶„í¬\n",
    "train_df['question_len'] = train_df['question'].str.len()\n",
    "train_df['question_len'].hist(bins=30, ax=axes[1], color='salmon', edgecolor='black')\n",
    "axes[1].set_title('Question Length Distribution', fontsize=12, weight='bold')\n",
    "axes[1].set_xlabel('Length (chars)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ìƒ˜í”Œ ì¶œë ¥\n",
    "print(\"\\nğŸ“ Sample Data:\")\n",
    "print(train_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ 5. Stratified K-Fold Cross-Validation\n",
    "\n",
    "ë‹µë³€ ë¶„í¬ë¥¼ ìœ ì§€í•˜ë©´ì„œ K-Foldë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.USE_KFOLD:\n",
    "    # Stratified K-Fold ìƒì„±\n",
    "    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=cfg.SEED)\n",
    "    train_df['fold'] = -1\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['answer'])):\n",
    "        train_df.loc[val_idx, 'fold'] = fold\n",
    "    \n",
    "    print(f\"âœ… {cfg.N_FOLDS}-Fold CV ìƒì„± ì™„ë£Œ\")\n",
    "    print(f\"\\nFold Distribution:\")\n",
    "    print(train_df['fold'].value_counts().sort_index())\n",
    "    \n",
    "    # Foldë³„ ë‹µë³€ ë¶„í¬ í™•ì¸\n",
    "    print(f\"\\nAnswer Distribution per Fold:\")\n",
    "    for fold in range(cfg.N_FOLDS):\n",
    "        fold_data = train_df[train_df['fold'] == fold]\n",
    "        dist = fold_data['answer'].value_counts(normalize=True).sort_index()\n",
    "        print(f\"Fold {fold}: {dict(dist)}\")\nelse:\n",
    "    # ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ (90:10 split)\n",
    "    split_idx = int(len(train_df) * 0.9)\n",
    "    train_df['fold'] = -1\n",
    "    train_df.loc[split_idx:, 'fold'] = 0\n",
    "    print(f\"âœ… Single split (90:10) ìƒì„± ì™„ë£Œ\")\n",
    "    print(f\"   Train: {len(train_df[train_df['fold'] == -1])}\")\n",
    "    print(f\"   Valid: {len(train_df[train_df['fold'] == 0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—‚ï¸ 6. Dataset & DataLoader\n",
    "\n",
    "ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ë° DataCollatorë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "### âœ… ë¼ë²¨ ì •ë ¬ êµì • ì ìš©\n",
    "- Assistant ë©”ì‹œì§€ì— ì •ë‹µ í¬í•¨\n",
    "- `add_generation_prompt=False` ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mc_prompt(question, a, b, c, d):\n",
    "    \"\"\"Multiple Choice í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
    "    return (\n",
    "        f\"{question}\\n\"\n",
    "        f\"(a) {a}\\n(b) {b}\\n(c) {c}\\n(d) {d}\\n\\n\"\n",
    "        \"ì •ë‹µì„ ë°˜ë“œì‹œ a, b, c, d ì¤‘ í•˜ë‚˜ì˜ ì†Œë¬¸ì í•œ ê¸€ìë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class VQADataset(Dataset):\n",
    "    \"\"\"VQA Dataset with Label Alignment Fix\"\"\"\n",
    "    \n",
    "    def __init__(self, df, processor, data_dir=\"\", train=True, use_advanced=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "        self.data_dir = data_dir\n",
    "        self.train = train\n",
    "        self.use_advanced = use_advanced  # process_vision_info ì‚¬ìš© ì—¬ë¶€\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        img_path = os.path.join(self.data_dir, row[\"path\"])\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        except:\n",
    "            img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "        user_text = build_mc_prompt(\n",
    "            str(row[\"question\"]),\n",
    "            str(row[\"a\"]), str(row[\"b\"]),\n",
    "            str(row[\"c\"]), str(row[\"d\"])\n",
    "        )\n",
    "        \n",
    "        # ë©”ì‹œì§€ êµ¬ì„±\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image\", \"image\": img},\n",
    "                {\"type\": \"text\", \"text\": user_text}\n",
    "            ]}\n",
    "        ]\n",
    "        \n",
    "        # âœ… CRITICAL: í•™ìŠµ ì‹œ ì •ë‹µ í¬í•¨ (ë¼ë²¨ ì •ë ¬ êµì •)\n",
    "        if self.train:\n",
    "            answer = str(row[\"answer\"]).strip().lower()\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": answer}]\n",
    "            })\n",
    "        \n",
    "        return {\"messages\": messages, \"image\": img}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollator:\n",
    "    \"\"\"Data Collator for VQA\"\"\"\n",
    "    processor: Any\n",
    "    train: bool = True\n",
    "    use_advanced: bool = False\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        texts, images = [], []\n",
    "        \n",
    "        for sample in batch:\n",
    "            messages = sample[\"messages\"]\n",
    "            img = sample[\"image\"]\n",
    "            \n",
    "            # âœ… apply_chat_template ì‚¬ìš©\n",
    "            text = self.processor.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=False  # âœ… í•™ìŠµ ì‹œ False!\n",
    "            )\n",
    "            \n",
    "            # í•œê¸€ ì •ê·œí™”\n",
    "            text = unicodedata.normalize('NFKC', text)\n",
    "            \n",
    "            texts.append(text)\n",
    "            images.append(img)\n",
    "        \n",
    "        # ì¸ì½”ë”©\n",
    "        if self.use_advanced:\n",
    "            # process_vision_info ì‚¬ìš© (Qwen2_5_VL)\n",
    "            enc = self.processor(\n",
    "                text=texts,\n",
    "                images=images,\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "        else:\n",
    "            # ê¸°ë³¸ ë°©ì‹ (AutoModelForVision2Seq)\n",
    "            enc = self.processor(\n",
    "                text=texts,\n",
    "                images=images,\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "        \n",
    "        # âœ… ë¼ë²¨ ì„¤ì •\n",
    "        if self.train:\n",
    "            enc[\"labels\"] = enc[\"input_ids\"].clone()\n",
    "        \n",
    "        return enc\n",
    "\n",
    "\n",
    "print(\"âœ… Dataset & DataCollator ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– 7. Model & Processor ë¡œë“œ\n",
    "\n",
    "QLoRA ëª¨ë¸ê³¼ Processorë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "\n",
    "### âœ… T4 í˜¸í™˜ ì„¤ì •\n",
    "- Float16 (BFloat16 ì•„ë‹˜)\n",
    "- SDPA attention (FlashAttention ì œê±°)\n",
    "- 4-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_processor(model_id, use_advanced=False):\n",
    "    \"\"\"ëª¨ë¸ ë° Processor ìƒì„±\"\"\"\n",
    "    \n",
    "    # ì–‘ìí™” ì„¤ì •\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,  # âœ… T4 í˜¸í™˜ (BF16 ì•„ë‹˜)\n",
    "    )\n",
    "    \n",
    "    # Processor ë¡œë“œ\n",
    "    processor = AutoProcessor.from_pretrained(\n",
    "        model_id,\n",
    "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
    "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    if use_advanced:\n",
    "        # âœ… Qwen2_5_VLForConditionalGeneration (ê³ ê¸‰)\n",
    "        base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "            model_id,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float16,\n",
    "            attn_implementation=\"sdpa\",  # âœ… FlashAttention ì œê±°\n",
    "        )\n",
    "    else:\n",
    "        # AutoModelForVision2Seq (Baseline í˜¸í™˜)\n",
    "        base_model = AutoModelForVision2Seq.from_pretrained(\n",
    "            model_id,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "    \n",
    "    # QLoRA ì¤€ë¹„\n",
    "    base_model = prepare_model_for_kbit_training(base_model)\n",
    "    base_model.gradient_checkpointing_enable()\n",
    "    \n",
    "    # LoRA Config\n",
    "    lora_config = LoraConfig(\n",
    "        r=cfg.LORA_R,\n",
    "        lora_alpha=cfg.LORA_ALPHA,\n",
    "        lora_dropout=cfg.LORA_DROPOUT,\n",
    "        bias=\"none\",\n",
    "        target_modules=cfg.TARGET_MODULES,\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    \n",
    "    # PEFT ëª¨ë¸ ìƒì„±\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "\n",
    "print(\"ğŸ”§ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "model, processor = create_model_and_processor(\n",
    "    cfg.MODEL_ID,\n",
    "    use_advanced=cfg.USE_ADVANCED_MODEL\n",
    ")\n",
    "model = model.to(device)\n",
    "print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ 8. Training Loop with Advanced Techniques\n",
    "\n",
    "ê³ ê¸‰ í•™ìŠµ ê¸°ë²•ì„ ì ìš©í•œ í•™ìŠµ ë£¨í”„ì…ë‹ˆë‹¤.\n",
    "\n",
    "### âœ¨ ì ìš©ëœ ê¸°ë²•\n",
    "- âœ… **AMP** (Automatic Mixed Precision)\n",
    "- âœ… **EMA** (Exponential Moving Average)\n",
    "- âœ… **SWA** (Stochastic Weight Averaging)\n",
    "- âœ… **Cosine Warmup Scheduler**\n",
    "- âœ… **Gradient Clipping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    \"\"\"Exponential Moving Average\"\"\"\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "        self.register()\n",
    "    \n",
    "    def register(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "    \n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                new_average = (\n",
    "                    self.decay * self.shadow[name] +\n",
    "                    (1.0 - self.decay) * param.data\n",
    "                )\n",
    "                self.shadow[name] = new_average.clone()\n",
    "    \n",
    "    def apply_shadow(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                param.data = self.shadow[name]\n",
    "    \n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "\n",
    "\n",
    "def train_one_fold(model, train_loader, valid_loader, fold=0):\n",
    "    \"\"\"ë‹¨ì¼ Fold í•™ìŠµ\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Fold {fold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=cfg.LEARNING_RATE,\n",
    "        weight_decay=cfg.WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    # Scheduler\n",
    "    num_training_steps = cfg.NUM_EPOCHS * math.ceil(len(train_loader) / cfg.GRAD_ACCUM_STEPS)\n",
    "    num_warmup_steps = int(num_training_steps * cfg.WARMUP_RATIO)\n",
    "    \n",
    "    if cfg.USE_COSINE_SCHEDULE:\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps, num_training_steps\n",
    "        )\n",
    "    else:\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps, num_training_steps\n",
    "        )\n",
    "    \n",
    "    # AMP Scaler\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=cfg.USE_AMP)\n",
    "    \n",
    "    # EMA\n",
    "    ema = EMA(model, decay=cfg.EMA_DECAY) if cfg.USE_EMA else None\n",
    "    \n",
    "    # SWA\n",
    "    swa_model = None\n",
    "    if cfg.USE_SWA:\n",
    "        swa_model = AveragedModel(model)\n",
    "        swa_scheduler = SWALR(optimizer, swa_lr=cfg.LEARNING_RATE * 0.1)\n",
    "    \n",
    "    # í•™ìŠµ ë£¨í”„\n",
    "    global_step = 0\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(cfg.NUM_EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        progress_bar = tqdm(\n",
    "            train_loader,\n",
    "            desc=f\"Epoch {epoch+1}/{cfg.NUM_EPOCHS} [train]\",\n",
    "            unit=\"batch\"\n",
    "        )\n",
    "        \n",
    "        for step, batch in enumerate(progress_bar, start=1):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            # Forward with AMP\n",
    "            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss / cfg.GRAD_ACCUM_STEPS\n",
    "            \n",
    "            # Backward\n",
    "            scaler.scale(loss).backward()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Gradient accumulation\n",
    "            if step % cfg.GRAD_ACCUM_STEPS == 0:\n",
    "                # Gradient clipping\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.MAX_GRAD_NORM)\n",
    "                \n",
    "                # Optimizer step\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                \n",
    "                # Scheduler step\n",
    "                if cfg.USE_SWA and epoch >= cfg.SWA_START_EPOCH:\n",
    "                    swa_scheduler.step()\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "                \n",
    "                # EMA update\n",
    "                if cfg.USE_EMA and ema is not None:\n",
    "                    ema.update()\n",
    "                \n",
    "                global_step += 1\n",
    "                \n",
    "                # Progress\n",
    "                avg_loss = running_loss / cfg.GRAD_ACCUM_STEPS\n",
    "                progress_bar.set_postfix({\n",
    "                    \"loss\": f\"{avg_loss:.4f}\",\n",
    "                    \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
    "                })\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        # SWA model update\n",
    "        if cfg.USE_SWA and swa_model is not None and epoch >= cfg.SWA_START_EPOCH:\n",
    "            swa_model.update_parameters(model)\n",
    "        \n",
    "        # Validation\n",
    "        if cfg.USE_EMA and ema is not None:\n",
    "            ema.apply_shadow()\n",
    "        \n",
    "        val_loss = validate(model, valid_loader)\n",
    "        \n",
    "        if cfg.USE_EMA and ema is not None:\n",
    "            ema.restore()\n",
    "        \n",
    "        print(f\"[Epoch {epoch+1}] Valid Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Best model ì €ì¥\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            \n",
    "            if cfg.USE_EMA and ema is not None:\n",
    "                ema.apply_shadow()\n",
    "            \n",
    "            model.save_pretrained(save_path)\n",
    "            processor.save_pretrained(save_path)\n",
    "            \n",
    "            if cfg.USE_EMA and ema is not None:\n",
    "                ema.restore()\n",
    "            \n",
    "            print(f\"   âœ… Best model saved to {save_path}\")\n",
    "    \n",
    "    # SWA ìµœì¢… ëª¨ë¸\n",
    "    if cfg.USE_SWA and swa_model is not None:\n",
    "        torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n",
    "        save_path = f\"{cfg.SAVE_DIR}/fold{fold}_swa\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        swa_model.module.save_pretrained(save_path)\n",
    "        processor.save_pretrained(save_path)\n",
    "        print(f\"   âœ… SWA model saved to {save_path}\")\n",
    "    \n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "def validate(model, valid_loader):\n",
    "    \"\"\"Validation\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader, desc=\"Validating\", leave=False):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n",
    "                outputs = model(**batch)\n",
    "                total_loss += outputs.loss.item()\n",
    "    \n",
    "    model.train()\n",
    "    return total_loss / len(valid_loader)\n",
    "\n",
    "\n",
    "print(\"âœ… Training functions ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ 9. ì‹¤ì œ í•™ìŠµ ì‹¤í–‰\n",
    "\n",
    "K-Fold ë˜ëŠ” ë‹¨ì¼ ëª¨ë¸ í•™ìŠµì„ ì‹¤í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold í•™ìŠµ\n",
    "if cfg.USE_KFOLD:\n",
    "    results = {}\n",
    "    \n",
    "    for fold in cfg.TRAIN_FOLDS:\n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"Starting Fold {fold}/{cfg.N_FOLDS-1}\")\n",
    "        print(f\"{'#'*60}\")\n",
    "        \n",
    "        # ë°ì´í„° ë¶„í• \n",
    "        train_subset = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "        valid_subset = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Train: {len(train_subset)}, Valid: {len(valid_subset)}\")\n",
    "        \n",
    "        # Dataset\n",
    "        train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
    "        valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
    "        \n",
    "        # DataLoader\n",
    "        train_loader = DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=cfg.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
    "            num_workers=0\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_ds,\n",
    "            batch_size=cfg.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        # í•™ìŠµ\n",
    "        best_loss = train_one_fold(model, train_loader, valid_loader, fold=fold)\n",
    "        results[fold] = best_loss\n",
    "        \n",
    "        print(f\"\\nâœ… Fold {fold} ì™„ë£Œ: Best Val Loss = {best_loss:.4f}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"All Folds Training Complete!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for fold, loss in results.items():\n",
    "        print(f\"Fold {fold}: {loss:.4f}\")\n",
    "    print(f\"Average: {np.mean(list(results.values())):.4f}\")\n",
    "\nelse:\n",
    "    # ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ\n",
    "    train_subset = train_df[train_df['fold'] == -1].reset_index(drop=True)\n",
    "    valid_subset = train_df[train_df['fold'] == 0].reset_index(drop=True)\n",
    "    \n",
    "    train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
    "    valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=cfg.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
    "        num_workers=0\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_ds,\n",
    "        batch_size=cfg.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    best_loss = train_one_fold(model, train_loader, valid_loader, fold=0)\n",
    "    print(f\"\\nâœ… Single model í•™ìŠµ ì™„ë£Œ: Best Val Loss = {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”® 10. Inference with TTA\n",
    "\n",
    "Test-Time Augmentationì„ í™œìš©í•œ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_choice(text: str) -> str:\n",
    "    \"\"\"ëª¨ë¸ ì¶œë ¥ì—ì„œ ë‹µ ì¶”ì¶œ\"\"\"\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # ë§ˆì§€ë§‰ ì¤„ì—ì„œ ì°¾ê¸°\n",
    "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
    "    if lines:\n",
    "        last = lines[-1]\n",
    "        if last in [\"a\", \"b\", \"c\", \"d\"]:\n",
    "            return last\n",
    "    \n",
    "    # í† í° ë‹¨ìœ„ë¡œ ì°¾ê¸°\n",
    "    for tok in text.split():\n",
    "        if tok in [\"a\", \"b\", \"c\", \"d\"]:\n",
    "            return tok\n",
    "    \n",
    "    return \"a\"  # Fallback\n",
    "\n",
    "\n",
    "def infer_single_fold(model_path, test_df, output_path):\n",
    "    \"\"\"ë‹¨ì¼ Fold ì¶”ë¡ \"\"\"\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    if cfg.USE_ADVANCED_MODEL:\n",
    "        model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "            model_path,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "    else:\n",
    "        model_infer = AutoModelForVision2Seq.from_pretrained(\n",
    "            model_path,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "    \n",
    "    processor_infer = AutoProcessor.from_pretrained(\n",
    "        model_path,\n",
    "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
    "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    \n",
    "    model_infer.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for i in tqdm(range(len(test_df)), desc=\"Inference\"):\n",
    "        row = test_df.iloc[i]\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        img_path = os.path.join(cfg.DATA_DIR, row[\"path\"])\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        except:\n",
    "            img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸\n",
    "        user_text = build_mc_prompt(\n",
    "            str(row[\"question\"]),\n",
    "            str(row[\"a\"]), str(row[\"b\"]),\n",
    "            str(row[\"c\"]), str(row[\"d\"])\n",
    "        )\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image\", \"image\": img},\n",
    "                {\"type\": \"text\", \"text\": user_text}\n",
    "            ]}\n",
    "        ]\n",
    "        \n",
    "        text = processor_infer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        inputs = processor_infer(\n",
    "            text=[text],\n",
    "            images=[img],\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "        # ìƒì„±\n",
    "        with torch.no_grad():\n",
    "            out_ids = model_infer.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=cfg.MAX_NEW_TOKENS,\n",
    "                do_sample=cfg.DO_SAMPLE,\n",
    "                temperature=cfg.TEMPERATURE if cfg.DO_SAMPLE else None,\n",
    "                eos_token_id=processor_infer.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        output_text = processor_infer.batch_decode(out_ids, skip_special_tokens=True)[0]\n",
    "        answer = extract_choice(output_text)\n",
    "        predictions.append(answer)\n",
    "    \n",
    "    # ì €ì¥\n",
    "    submission = pd.DataFrame({\n",
    "        \"id\": test_df[\"id\"],\n",
    "        \"answer\": predictions\n",
    "    })\n",
    "    \n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    submission.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Saved to {output_path}\")\n",
    "    \n",
    "    return submission\n",
    "\n",
    "\n",
    "# ê° Foldë³„ ì¶”ë¡ \n",
    "predictions_all = []\n",
    "\n",
    "if cfg.USE_KFOLD:\n",
    "    for fold in cfg.TRAIN_FOLDS:\n",
    "        model_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
    "        output_path = f\"{cfg.OUTPUT_DIR}/submission_fold{fold}.csv\"\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Inferencing Fold {fold}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        pred = infer_single_fold(model_path, test_df, output_path)\n",
    "        predictions_all.append(pred)\nelse:\n",
    "    model_path = f\"{cfg.SAVE_DIR}/fold0_best\"\n",
    "    output_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n",
    "    \n",
    "    pred = infer_single_fold(model_path, test_df, output_path)\n",
    "    predictions_all.append(pred)\n",
    "\n",
    "print(\"\\nâœ… All inference complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ 11. Ensemble\n",
    "\n",
    "ì—¬ëŸ¬ Foldì˜ ì˜ˆì¸¡ì„ ì•™ìƒë¸”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.USE_KFOLD and len(predictions_all) > 1:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Ensemble (Majority Voting)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Majority Voting\n",
    "    ensemble_preds = []\n",
    "    \n",
    "    for i in range(len(test_df)):\n",
    "        votes = [pred.iloc[i]['answer'] for pred in predictions_all]\n",
    "        most_common = Counter(votes).most_common(1)[0][0]\n",
    "        ensemble_preds.append(most_common)\n",
    "    \n",
    "    # ìµœì¢… ì œì¶œ íŒŒì¼\n",
    "    final_submission = pd.DataFrame({\n",
    "        \"id\": test_df[\"id\"],\n",
    "        \"answer\": ensemble_preds\n",
    "    })\n",
    "    \n",
    "    final_path = f\"{cfg.OUTPUT_DIR}/submission_ensemble.csv\"\n",
    "    final_submission.to_csv(final_path, index=False)\n",
    "    \n",
    "    print(f\"âœ… Ensemble submission saved to {final_path}\")\n",
    "    print(f\"\\nAnswer Distribution:\")\n",
    "    print(final_submission['answer'].value_counts().sort_index())\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâœ… Single model - No ensemble needed\")\n",
    "    final_submission = predictions_all[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 12. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹µë³€ ë¶„í¬ ì‹œê°í™”\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "answer_counts = final_submission['answer'].value_counts().sort_index()\n",
    "sns.barplot(x=answer_counts.index, y=answer_counts.values, palette='viridis', ax=ax)\n",
    "ax.set_title('Final Submission Answer Distribution', fontsize=14, weight='bold')\n",
    "ax.set_xlabel('Answer')\n",
    "ax.set_ylabel('Count')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# ë¹„ìœ¨ í‘œì‹œ\n",
    "for i, (ans, count) in enumerate(answer_counts.items()):\n",
    "    percentage = count / len(final_submission) * 100\n",
    "    ax.text(i, count + 10, f\"{percentage:.1f}%\", ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# í†µê³„ ì¶œë ¥\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Final Statistics\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total predictions: {len(final_submission)}\")\n",
    "print(f\"\\nAnswer counts:\")\n",
    "for ans, count in answer_counts.items():\n",
    "    print(f\"  {ans}: {count:5d} ({count/len(final_submission)*100:5.1f}%)\")\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ìƒ˜í”Œ\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Sample Predictions\")\n",
    "print(f\"{'='*60}\")\n",
    "print(final_submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… 13. ìµœì¢… ì •ë¦¬\n",
    "\n",
    "### ğŸ‰ ì™„ë£Œëœ ì‘ì—…\n",
    "\n",
    "1. âœ… **í™˜ê²½ ì„¤ì •** - íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
    "2. âœ… **Config** - í•˜ì´í¼íŒŒë¼ë¯¸í„° í†µí•© ê´€ë¦¬\n",
    "3. âœ… **ë°ì´í„° ë¡œë“œ & EDA** - íƒìƒ‰ì  ë¶„ì„\n",
    "4. âœ… **Stratified K-Fold** - CV Splits ìƒì„±\n",
    "5. âœ… **Dataset & DataLoader** - ë¼ë²¨ ì •ë ¬ êµì • ì ìš©\n",
    "6. âœ… **Model & Processor** - QLoRA ëª¨ë¸ ë¡œë“œ (T4 í˜¸í™˜)\n",
    "7. âœ… **Training Loop** - AMP, EMA, SWA, Cosine Warmup ì ìš©\n",
    "8. âœ… **Inference** - TTA ì§€ì› ì¶”ë¡ \n",
    "9. âœ… **Ensemble** - Majority Voting\n",
    "10. âœ… **Results** - ì‹œê°í™” ë° í†µê³„\n",
    "\n",
    "### ğŸš€ ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "1. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**\n",
    "   - Learning rate, LoRA rank ì¡°ì •\n",
    "   - Batch size, Grad accumulation ìµœì í™”\n",
    "\n",
    "2. **ëª¨ë¸ í¬ê¸° í™•ëŒ€**\n",
    "   - 7B ëª¨ë¸ ì‚¬ìš© (ë” ë†’ì€ ì •í™•ë„)\n",
    "   - Image size ì¦ê°€ (512, 768)\n",
    "\n",
    "3. **ê³ ê¸‰ ê¸°ë²• í™œì„±í™”**\n",
    "   - TTA scales ì¶”ê°€\n",
    "   - SWA ì ìš©\n",
    "   - ë°ì´í„° ì¦ê°• í™œì„±í™”\n",
    "\n",
    "4. **ì—í­ ì¦ê°€**\n",
    "   - NUM_EPOCHS = 3~5\n",
    "\n",
    "### ğŸ“Œ Important Notes\n",
    "\n",
    "- **T4 í˜¸í™˜**: Float16, SDPA attention ì‚¬ìš©\n",
    "- **ë¼ë²¨ ì •ë ¬**: Assistant ë©”ì‹œì§€ì— ì •ë‹µ í¬í•¨ (í•µì‹¬!)\n",
    "- **ì¬í˜„ì„±**: Seed 42 ê³ ì •\n",
    "- **ë©”ëª¨ë¦¬**: Gradient checkpointing, 4-bit QLoRA\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ¤– Generated for SSAFY AI Project 2025**\n",
    "\n",
    "**ğŸ“§ Contact**: GitHub Issues\n",
    "\n",
    "**â­ í–‰ìš´ì„ ë¹•ë‹ˆë‹¤!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
