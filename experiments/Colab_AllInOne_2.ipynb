{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 📒 Colab_AllInOne_2.ipynb – Colab A100 80GB 최적화 버전\n",
        "\n",
        "## 🎯 개요\n",
        "\n",
        "본 노트북은 **VQA Kaggle Challenge**를 위한 **Colab A100 80GB 최적화 고성능 파이프라인**입니다.\n",
        "\n",
        "### ✨ 주요 기능\n",
        "\n",
        "- ✅ **A100 80GB GPU 최적화** (BF16, Flash Attention 2)\n",
        "- ✅ **Qwen3-VL-8B-Instruct 모델** (최신 8B 고성능 모델)\n",
        "- ✅ **대용량 이미지 처리** (768px, 최고 품질)\n",
        "- ✅ **대형 배치 사이즈** (16, 최대 처리량)\n",
        "- ✅ **라벨 정렬 교정** (Assistant 메시지에 정답 포함)\n",
        "- ✅ **K-Fold Cross-Validation** (Stratified)\n",
        "- ✅ **고급 학습 기법** (AMP BF16, EMA, SWA, Cosine Warmup)\n",
        "- ✅ **데이터 증강** (Choice Shuffle, Paraphrase)\n",
        "- ✅ **TTA (Test-Time Augmentation)**\n",
        "- ✅ **앙상블** (Weighted Voting)\n",
        "\n",
        "### 🚀 A100 80GB 최적화 사항\n",
        "\n",
        "| 항목 | 기존 (T4) | 최적화 (A100 80GB) |\n",
        "|------|-----------|-------------------|\n",
        "| 모델 | Qwen2.5-VL-3B | **Qwen3-VL-8B** |\n",
        "| 정밀도 | FP16 | **BF16** |\n",
        "| 양자화 | 4-bit QLoRA | **8-bit QLoRA** |\n",
        "| 이미지 크기 | 384px | **768px** |\n",
        "| 배치 사이즈 | 4 | **16** |\n",
        "| Attention | SDPA | **Flash Attention 2** |\n",
        "| Gradient Acc | 4 | **2** |\n",
        "\n",
        "### 📊 예상 성능\n",
        "\n",
        "| 설정 | 정확도 | 시간 |\n",
        "|------|--------|------|\n",
        "| Single Fold | 83-86% | ~1.5h |\n",
        "| 3-Fold Ensemble | 87-90% | ~4.5h |\n",
        "| + TTA + Optimization | 90-93% | ~6h |\n",
        "\n",
        "---\n",
        "\n",
        "**🤖 Generated for SSAFY AI Project 2025 - Colab A100 Optimized**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📦 1. 환경 설정 및 패키지 설치\n",
        "\n",
        "필요한 라이브러리를 설치합니다. (첫 실행 시 1회만)\n",
        "\n",
        "### ⚠️ 중요: 설치 후 런타임 재시작 필요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 패키지 설치 (Colab A100 환경)\n",
        "# 첫 실행 시에만 실행\n",
        "!pip install -q \"transformers>=4.46.0\" \"accelerate>=0.34.2\" \"peft>=0.13.2\" \\\n",
        "    \"bitsandbytes>=0.44.0\" datasets pillow pandas torch torchvision \\\n",
        "    scikit-learn matplotlib seaborn tqdm --upgrade\n",
        "\n",
        "# Qwen VL Utils 설치\n",
        "!pip install -q qwen-vl-utils==0.0.8\n",
        "\n",
        "# Flash Attention 2 설치 (A100 최적화)\n",
        "!pip install -q flash-attn --no-build-isolation\n",
        "\n",
        "print(\"✅ 패키지 설치 완료! 런타임을 재시작하세요.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📚 2. 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, sys, re, math, random, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Any, Optional\n",
        "from collections import Counter\n",
        "import unicodedata\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "\n",
        "# Transformers & PEFT\n",
        "from transformers import (\n",
        "    AutoModelForVision2Seq,\n",
        "    Qwen2_5_VLForConditionalGeneration,\n",
        "    AutoProcessor,\n",
        "    BitsAndBytesConfig,\n",
        "    get_cosine_schedule_with_warmup,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from qwen_vl_utils import process_vision_info\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 설정\n",
        "warnings.filterwarnings('ignore')\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# 디바이스\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"🔧 Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "print(f\"🐍 Python: {sys.version.split()[0]}\")\n",
        "print(f\"🔥 PyTorch: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ⚙️ 3. Config 설정\n",
        "\n",
        "모든 하이퍼파라미터를 한 곳에서 관리합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class Config:\n",
        "    \"\"\"A100 80GB 최적화 설정 클래스\"\"\"\n",
        "\n",
        "    # 시드 (재현성)\n",
        "    SEED = 42\n",
        "\n",
        "    # 모델 설정 (A100 최적화)\n",
        "    MODEL_ID = \"Qwen/Qwen3-VL-8B-Instruct\"  # 8B 모델로 업그레이드\n",
        "    IMAGE_SIZE = 768  # A100: 768px (더 높은 품질)\n",
        "    USE_FLASH_ATTN = True  # Flash Attention 2 사용\n",
        "    USE_ADVANCED_MODEL = True  # Qwen2VLForConditionalGeneration 사용\n",
        "\n",
        "    # 데이터 경로\n",
        "    DATA_DIR = \"/content/drive/MyDrive/kaggle_vqa\"  # Colab Drive 경로\n",
        "    TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n",
        "    TEST_CSV = f\"{DATA_DIR}/test.csv\"\n",
        "\n",
        "    # K-Fold 설정\n",
        "    N_FOLDS = 3\n",
        "    USE_KFOLD = True\n",
        "    TRAIN_FOLDS = [0, 1, 2]  # 학습할 fold\n",
        "\n",
        "    # 샘플링 (디버깅용)\n",
        "    USE_SAMPLE = False\n",
        "    SAMPLE_SIZE = 500\n",
        "\n",
        "    # 학습 하이퍼파라미터 (A100 최적화)\n",
        "    EPOCHS = 3\n",
        "    BATCH_SIZE = 16  # A100: 16 (T4의 4배)\n",
        "    GRAD_ACCUM_STEPS = 2  # A100: 2 (T4는 4)\n",
        "    LEARNING_RATE = 2e-5\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    WARMUP_RATIO = 0.1\n",
        "    MAX_GRAD_NORM = 1.0\n",
        "\n",
        "    # 정밀도 (A100 최적화)\n",
        "    USE_BF16 = True  # A100은 BF16 네이티브 지원\n",
        "    USE_FP16 = False  # BF16 사용 시 False\n",
        "\n",
        "    # 양자화 (A100: 8-bit로 완화)\n",
        "    USE_4BIT = False  # 4-bit 사용 안 함\n",
        "    USE_8BIT = True   # 8-bit 사용 (더 높은 품질)\n",
        "\n",
        "    # LoRA 설정 (A100 최적화)\n",
        "    LORA_R = 32  # A100: 32 (T4는 16)\n",
        "    LORA_ALPHA = 64  # A100: 64 (T4는 32)\n",
        "    LORA_DROPOUT = 0.05\n",
        "    LORA_TARGET_MODULES = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "    ]\n",
        "\n",
        "    # 고급 기법\n",
        "    USE_GRADIENT_CHECKPOINTING = True\n",
        "    USE_EMA = True\n",
        "    EMA_DECAY = 0.999\n",
        "    USE_SWA = True\n",
        "    SWA_START_EPOCH = 2\n",
        "    SWA_LR = 1e-6\n",
        "\n",
        "    # 데이터 증강\n",
        "    USE_CHOICE_SHUFFLE = True\n",
        "    CHOICE_SHUFFLE_PROB = 0.3\n",
        "\n",
        "    # TTA\n",
        "    USE_TTA = True\n",
        "    TTA_SAMPLES = 3  # A100: 3\n",
        "\n",
        "    # 출력 경로\n",
        "    OUTPUT_DIR = \"./outputs_a100\"\n",
        "    CHECKPOINT_DIR = f\"{OUTPUT_DIR}/checkpoints\"\n",
        "    SUBMISSION_DIR = f\"{OUTPUT_DIR}/submissions\"\n",
        "\n",
        "    # 기타\n",
        "    NUM_WORKERS = 2\n",
        "    SAVE_STEPS = 200\n",
        "    LOGGING_STEPS = 50\n",
        "    EVAL_STEPS = 200\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# 출력 디렉토리 생성\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(cfg.CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(cfg.SUBMISSION_DIR, exist_ok=True)\n",
        "\n",
        "# 시드 고정\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(cfg.SEED)\n",
        "\n",
        "print(\"✅ Config 설정 완료\")\n",
        "print(f\"📊 모델: {cfg.MODEL_ID}\")\n",
        "print(f\"📊 이미지 크기: {cfg.IMAGE_SIZE}px\")\n",
        "print(f\"📊 배치 크기: {cfg.BATCH_SIZE}\")\n",
        "print(f\"📊 정밀도: {'BF16' if cfg.USE_BF16 else 'FP16'}\")\n",
        "print(f\"📊 양자화: {'8-bit' if cfg.USE_8BIT else '4-bit' if cfg.USE_4BIT else 'None'}\")\n",
        "print(f\"📊 Flash Attention: {cfg.USE_FLASH_ATTN}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 4. 데이터 로드 및 EDA\n",
        "\n",
        "데이터를 로드하고 간단한 탐색적 분석을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 데이터 로드\n",
        "train_df = pd.read_csv(cfg.TRAIN_CSV)\n",
        "test_df = pd.read_csv(cfg.TEST_CSV)\n",
        "\n",
        "print(f\"📁 Train: {len(train_df):,} samples\")\n",
        "print(f\"📁 Test: {len(test_df):,} samples\")\n",
        "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
        "\n",
        "# 샘플링 (디버깅용)\n",
        "if cfg.USE_SAMPLE:\n",
        "    train_df = train_df.sample(n=min(cfg.SAMPLE_SIZE, len(train_df)), random_state=cfg.SEED).reset_index(drop=True)\n",
        "    print(f\"\\n⚠️  Sampled {len(train_df)} samples for quick testing\")\n",
        "\n",
        "# 기본 통계\n",
        "print(f\"\\n📊 Answer Distribution:\")\n",
        "print(train_df['answer'].value_counts().sort_index())\n",
        "\n",
        "# 시각화\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "# 답변 분포\n",
        "train_df['answer'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='skyblue')\n",
        "axes[0].set_title('Answer Distribution (Train)', fontsize=12, weight='bold')\n",
        "axes[0].set_xlabel('Answer')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 질문 길이 분포\n",
        "train_df['question_len'] = train_df['question'].str.len()\n",
        "train_df['question_len'].hist(bins=30, ax=axes[1], color='salmon', edgecolor='black')\n",
        "axes[1].set_title('Question Length Distribution', fontsize=12, weight='bold')\n",
        "axes[1].set_xlabel('Length (chars)')\n",
        "axes[1].set_ylabel('Count')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 샘플 출력\n",
        "print(\"\\n📝 Sample Data:\")\n",
        "print(train_df.head(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔄 5. Stratified K-Fold Cross-Validation\n",
        "\n",
        "답변 분포를 유지하면서 K-Fold를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD:\n",
        "    # Stratified K-Fold 생성\n",
        "    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=cfg.SEED)\n",
        "    train_df['fold'] = -1\n",
        "    \n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['answer'])):\n",
        "        train_df.loc[val_idx, 'fold'] = fold\n",
        "    \n",
        "    print(f\"✅ {cfg.N_FOLDS}-Fold CV 생성 완료\")\n",
        "    print(f\"\\nFold Distribution:\")\n",
        "    print(train_df['fold'].value_counts().sort_index())\n",
        "    \n",
        "    # Fold별 답변 분포 확인\n",
        "    print(f\"\\nAnswer Distribution per Fold:\")\n",
        "    for fold in range(cfg.N_FOLDS):\n",
        "        fold_data = train_df[train_df['fold'] == fold]\n",
        "        dist = fold_data['answer'].value_counts(normalize=True).sort_index()\n",
        "        print(f\"Fold {fold}: {dict(dist)}\")\n",
        "else:\n",
        "    # 단일 모델 학습 (90:10 split)\n",
        "    split_idx = int(len(train_df) * 0.9)\n",
        "    train_df['fold'] = -1\n",
        "    train_df.loc[split_idx:, 'fold'] = 0\n",
        "    print(f\"✅ Single split (90:10) 생성 완료\")\n",
        "    print(f\"   Train: {len(train_df[train_df['fold'] == -1])}\")\n",
        "    print(f\"   Valid: {len(train_df[train_df['fold'] == 0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🗂️ 6. Dataset & DataLoader\n",
        "\n",
        "커스텀 데이터셋 및 DataCollator를 정의합니다.\n",
        "\n",
        "### ✅ 라벨 정렬 교정 적용\n",
        "- Assistant 메시지에 정답 포함\n",
        "- `add_generation_prompt=False` 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def build_mc_prompt(question, a, b, c, d):\n",
        "    \"\"\"Multiple Choice 프롬프트 생성\"\"\"\n",
        "    return (\n",
        "        f\"{question}\\n\"\n",
        "        f\"(a) {a}\\n(b) {b}\\n(c) {c}\\n(d) {d}\\n\\n\"\n",
        "        \"정답을 반드시 a, b, c, d 중 하나의 소문자 한 글자로만 출력하세요.\"\n",
        "    )\n",
        "\n",
        "\n",
        "class VQADataset(Dataset):\n",
        "    \"\"\"VQA Dataset with Label Alignment Fix\"\"\"\n",
        "    \n",
        "    def __init__(self, df, processor, data_dir=\"\", train=True, use_advanced=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.processor = processor\n",
        "        self.data_dir = data_dir\n",
        "        self.train = train\n",
        "        self.use_advanced = use_advanced  # process_vision_info 사용 여부\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        \n",
        "        # 이미지 로드\n",
        "        img_path = os.path.join(self.data_dir, row[\"path\"])\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "        except:\n",
        "            img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n",
        "        \n",
        "        # 프롬프트 생성\n",
        "        user_text = build_mc_prompt(\n",
        "            str(row[\"question\"]),\n",
        "            str(row[\"a\"]), str(row[\"b\"]),\n",
        "            str(row[\"c\"]), str(row[\"d\"])\n",
        "        )\n",
        "        \n",
        "        # 메시지 구성\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"image\", \"image\": img},\n",
        "                {\"type\": \"text\", \"text\": user_text}\n",
        "            ]}\n",
        "        ]\n",
        "        \n",
        "        # ✅ CRITICAL: 학습 시 정답 포함 (라벨 정렬 교정)\n",
        "        if self.train:\n",
        "            answer = str(row[\"answer\"]).strip().lower()\n",
        "            messages.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": [{\"type\": \"text\", \"text\": answer}]\n",
        "            })\n",
        "        \n",
        "        return {\"messages\": messages, \"image\": img}\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollator:\n",
        "    \"\"\"Data Collator for VQA\"\"\"\n",
        "    processor: Any\n",
        "    train: bool = True\n",
        "    use_advanced: bool = False\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        texts, images = [], []\n",
        "        \n",
        "        for sample in batch:\n",
        "            messages = sample[\"messages\"]\n",
        "            img = sample[\"image\"]\n",
        "            \n",
        "            # ✅ apply_chat_template 사용\n",
        "            text = self.processor.apply_chat_template(\n",
        "                messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=False  # ✅ 학습 시 False!\n",
        "            )\n",
        "            \n",
        "            # 한글 정규화\n",
        "            text = unicodedata.normalize('NFKC', text)\n",
        "            \n",
        "            texts.append(text)\n",
        "            images.append(img)\n",
        "        \n",
        "        # 인코딩\n",
        "        if self.use_advanced:\n",
        "            # process_vision_info 사용 (Qwen2_5_VL)\n",
        "            enc = self.processor(\n",
        "                text=texts,\n",
        "                images=images,\n",
        "                padding=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "        else:\n",
        "            # 기본 방식 (AutoModelForVision2Seq)\n",
        "            enc = self.processor(\n",
        "                text=texts,\n",
        "                images=images,\n",
        "                padding=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "        \n",
        "        # ✅ 라벨 설정\n",
        "        if self.train:\n",
        "            enc[\"labels\"] = enc[\"input_ids\"].clone()\n",
        "        \n",
        "        return enc\n",
        "\n",
        "\n",
        "print(\"✅ Dataset & DataCollator 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤖 7. Model & Processor 로드\n",
        "\n",
        "QLoRA 모델과 Processor를 로드합니다.\n",
        "\n",
        "### ✅ T4 호환 설정\n",
        "- Float16 (BFloat16 아님)\n",
        "- SDPA attention (FlashAttention 제거)\n",
        "- 4-bit quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def create_model_and_processor(model_id, use_advanced=False):\n",
        "    \"\"\"모델 및 Processor 생성 (A100 80GB 최적화)\"\"\"\n",
        "\n",
        "    # 양자화 설정 (8-bit for A100)\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_8bit=cfg.USE_8BIT,\n",
        "        load_in_4bit=cfg.USE_4BIT,\n",
        "        bnb_4bit_use_double_quant=True if cfg.USE_4BIT else False,\n",
        "        bnb_4bit_quant_type=\"nf4\" if cfg.USE_4BIT else None,\n",
        "        bnb_8bit_compute_dtype=torch.bfloat16 if cfg.USE_BF16 else torch.float16,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16 if cfg.USE_BF16 else torch.float16,\n",
        "    )\n",
        "\n",
        "    # Processor 로드\n",
        "    processor = AutoProcessor.from_pretrained(\n",
        "        model_id,\n",
        "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
        "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    # 모델 로드 (Flash Attention 2 사용)\n",
        "    if use_advanced:\n",
        "        model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "            model_id,\n",
        "            quantization_config=bnb_config if (cfg.USE_8BIT or cfg.USE_4BIT) else None,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.bfloat16 if cfg.USE_BF16 else torch.float16,\n",
        "            attn_implementation=\"flash_attention_2\" if cfg.USE_FLASH_ATTN else \"sdpa\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "    else:\n",
        "        model = AutoModelForVision2Seq.from_pretrained(\n",
        "            model_id,\n",
        "            quantization_config=bnb_config if (cfg.USE_8BIT or cfg.USE_4BIT) else None,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.bfloat16 if cfg.USE_BF16 else torch.float16,\n",
        "            attn_implementation=\"flash_attention_2\" if cfg.USE_FLASH_ATTN else \"sdpa\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "    # Gradient Checkpointing\n",
        "    if cfg.USE_GRADIENT_CHECKPOINTING:\n",
        "        model.gradient_checkpointing_enable()\n",
        "\n",
        "    # QLoRA 준비\n",
        "    if cfg.USE_8BIT or cfg.USE_4BIT:\n",
        "        model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "    # LoRA 설정\n",
        "    lora_config = LoraConfig(\n",
        "        r=cfg.LORA_R,\n",
        "        lora_alpha=cfg.LORA_ALPHA,\n",
        "        target_modules=cfg.LORA_TARGET_MODULES,\n",
        "        lora_dropout=cfg.LORA_DROPOUT,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\"\n",
        "    )\n",
        "\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    return model, processor\n",
        "\n",
        "print(\"✅ 모델 로드 함수 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎓 8. Training Loop with Advanced Techniques\n",
        "\n",
        "고급 학습 기법을 적용한 학습 루프입니다.\n",
        "\n",
        "### ✨ 적용된 기법\n",
        "- ✅ **AMP** (Automatic Mixed Precision)\n",
        "- ✅ **EMA** (Exponential Moving Average)\n",
        "- ✅ **SWA** (Stochastic Weight Averaging)\n",
        "- ✅ **Cosine Warmup Scheduler**\n",
        "- ✅ **Gradient Clipping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class EMA:\n",
        "    \"\"\"Exponential Moving Average\"\"\"\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.model = model\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.backup = {}\n",
        "        self.register()\n",
        "    \n",
        "    def register(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "    \n",
        "    def update(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                new_average = (\n",
        "                    self.decay * self.shadow[name] +\n",
        "                    (1.0 - self.decay) * param.data\n",
        "                )\n",
        "                self.shadow[name] = new_average.clone()\n",
        "    \n",
        "    def apply_shadow(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.backup[name] = param.data.clone()\n",
        "                param.data = self.shadow[name]\n",
        "    \n",
        "    def restore(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                param.data = self.backup[name]\n",
        "        self.backup = {}\n",
        "\n",
        "\n",
        "def train_one_fold(model, train_loader, valid_loader, fold=0):\n",
        "    \"\"\"단일 Fold 학습\"\"\"\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training Fold {fold}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=cfg.LEARNING_RATE,\n",
        "        weight_decay=cfg.WEIGHT_DECAY\n",
        "    )\n",
        "    \n",
        "    # Scheduler\n",
        "    num_training_steps = cfg.NUM_EPOCHS * math.ceil(len(train_loader) / cfg.GRAD_ACCUM_STEPS)\n",
        "    num_warmup_steps = int(num_training_steps * cfg.WARMUP_RATIO)\n",
        "    \n",
        "    if cfg.USE_COSINE_SCHEDULE:\n",
        "        scheduler = get_cosine_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps, num_training_steps\n",
        "        )\n",
        "    else:\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps, num_training_steps\n",
        "        )\n",
        "    \n",
        "    # AMP Scaler\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=cfg.USE_AMP)\n",
        "    \n",
        "    # EMA\n",
        "    ema = EMA(model, decay=cfg.EMA_DECAY) if cfg.USE_EMA else None\n",
        "    \n",
        "    # SWA\n",
        "    swa_model = None\n",
        "    if cfg.USE_SWA:\n",
        "        swa_model = AveragedModel(model)\n",
        "        swa_scheduler = SWALR(optimizer, swa_lr=cfg.LEARNING_RATE * 0.1)\n",
        "    \n",
        "    # 학습 루프\n",
        "    global_step = 0\n",
        "    best_val_loss = float('inf')\n",
        "    \n",
        "    for epoch in range(cfg.NUM_EPOCHS):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        progress_bar = tqdm(\n",
        "            train_loader,\n",
        "            desc=f\"Epoch {epoch+1}/{cfg.NUM_EPOCHS} [train]\",\n",
        "            unit=\"batch\"\n",
        "        )\n",
        "        \n",
        "        for step, batch in enumerate(progress_bar, start=1):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            \n",
        "            # Forward with AMP\n",
        "            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n",
        "                outputs = model(**batch)\n",
        "                loss = outputs.loss / cfg.GRAD_ACCUM_STEPS\n",
        "            \n",
        "            # Backward\n",
        "            scaler.scale(loss).backward()\n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            # Gradient accumulation\n",
        "            if step % cfg.GRAD_ACCUM_STEPS == 0:\n",
        "                # Gradient clipping\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.MAX_GRAD_NORM)\n",
        "                \n",
        "                # Optimizer step\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                \n",
        "                # Scheduler step\n",
        "                if cfg.USE_SWA and epoch >= cfg.SWA_START_EPOCH:\n",
        "                    swa_scheduler.step()\n",
        "                else:\n",
        "                    scheduler.step()\n",
        "                \n",
        "                # EMA update\n",
        "                if cfg.USE_EMA and ema is not None:\n",
        "                    ema.update()\n",
        "                \n",
        "                global_step += 1\n",
        "                \n",
        "                # Progress\n",
        "                avg_loss = running_loss / cfg.GRAD_ACCUM_STEPS\n",
        "                progress_bar.set_postfix({\n",
        "                    \"loss\": f\"{avg_loss:.4f}\",\n",
        "                    \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
        "                })\n",
        "                running_loss = 0.0\n",
        "        \n",
        "        # SWA model update\n",
        "        if cfg.USE_SWA and swa_model is not None and epoch >= cfg.SWA_START_EPOCH:\n",
        "            swa_model.update_parameters(model)\n",
        "        \n",
        "        # Validation\n",
        "        if cfg.USE_EMA and ema is not None:\n",
        "            ema.apply_shadow()\n",
        "        \n",
        "        val_loss = validate(model, valid_loader)\n",
        "        \n",
        "        if cfg.USE_EMA and ema is not None:\n",
        "            ema.restore()\n",
        "        \n",
        "        print(f\"[Epoch {epoch+1}] Valid Loss: {val_loss:.4f}\")\n",
        "        \n",
        "        # Best model 저장\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            save_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
        "            os.makedirs(save_path, exist_ok=True)\n",
        "            \n",
        "            if cfg.USE_EMA and ema is not None:\n",
        "                ema.apply_shadow()\n",
        "            \n",
        "            model.save_pretrained(save_path)\n",
        "            processor.save_pretrained(save_path)\n",
        "            \n",
        "            if cfg.USE_EMA and ema is not None:\n",
        "                ema.restore()\n",
        "            \n",
        "            print(f\"   ✅ Best model saved to {save_path}\")\n",
        "    \n",
        "    # SWA 최종 모델\n",
        "    if cfg.USE_SWA and swa_model is not None:\n",
        "        torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n",
        "        save_path = f\"{cfg.SAVE_DIR}/fold{fold}_swa\"\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        swa_model.module.save_pretrained(save_path)\n",
        "        processor.save_pretrained(save_path)\n",
        "        print(f\"   ✅ SWA model saved to {save_path}\")\n",
        "    \n",
        "    return best_val_loss\n",
        "\n",
        "\n",
        "def validate(model, valid_loader):\n",
        "    \"\"\"Validation\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(valid_loader, desc=\"Validating\", leave=False):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            \n",
        "            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n",
        "                outputs = model(**batch)\n",
        "                total_loss += outputs.loss.item()\n",
        "    \n",
        "    model.train()\n",
        "    return total_loss / len(valid_loader)\n",
        "\n",
        "\n",
        "print(\"✅ Training functions 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 9. 실제 학습 실행\n",
        "\n",
        "K-Fold 또는 단일 모델 학습을 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# K-Fold 학습\n",
        "if cfg.USE_KFOLD:\n",
        "    results = {}\n",
        "    \n",
        "    for fold in cfg.TRAIN_FOLDS:\n",
        "        print(f\"\\n{'#'*60}\")\n",
        "        print(f\"Starting Fold {fold}/{cfg.N_FOLDS-1}\")\n",
        "        print(f\"{'#'*60}\")\n",
        "        \n",
        "        # 데이터 분할\n",
        "        train_subset = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
        "        valid_subset = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
        "        \n",
        "        print(f\"Train: {len(train_subset)}, Valid: {len(valid_subset)}\")\n",
        "        \n",
        "        # Dataset\n",
        "        train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "        valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "        \n",
        "        # DataLoader\n",
        "        train_loader = DataLoader(\n",
        "            train_ds,\n",
        "            batch_size=cfg.BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
        "            num_workers=0\n",
        "        )\n",
        "        valid_loader = DataLoader(\n",
        "            valid_ds,\n",
        "            batch_size=cfg.BATCH_SIZE,\n",
        "            shuffle=False,\n",
        "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
        "            num_workers=0\n",
        "        )\n",
        "        \n",
        "        # 학습\n",
        "        best_loss = train_one_fold(model, train_loader, valid_loader, fold=fold)\n",
        "        results[fold] = best_loss\n",
        "        \n",
        "        print(f\"\\n✅ Fold {fold} 완료: Best Val Loss = {best_loss:.4f}\")\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"All Folds Training Complete!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for fold, loss in results.items():\n",
        "        print(f\"Fold {fold}: {loss:.4f}\")\n",
        "    print(f\"Average: {np.mean(list(results.values())):.4f}\")\n",
        "\n",
        "else:\n",
        "    # 단일 모델 학습\n",
        "    train_subset = train_df[train_df['fold'] == -1].reset_index(drop=True)\n",
        "    valid_subset = train_df[train_df['fold'] == 0].reset_index(drop=True)\n",
        "    \n",
        "    train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "    valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "    \n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=cfg.BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
        "        num_workers=0\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_ds,\n",
        "        batch_size=cfg.BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
        "        num_workers=0\n",
        "    )\n",
        "    \n",
        "    best_loss = train_one_fold(model, train_loader, valid_loader, fold=0)\n",
        "    print(f\"\\n✅ Single model 학습 완료: Best Val Loss = {best_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔮 10. Inference with TTA\n",
        "\n",
        "Test-Time Augmentation을 활용한 추론을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def extract_choice(text: str) -> str:\n",
        "    \"\"\"모델 출력에서 답 추출\"\"\"\n",
        "    text = text.strip().lower()\n",
        "    \n",
        "    # 마지막 줄에서 찾기\n",
        "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
        "    if lines:\n",
        "        last = lines[-1]\n",
        "        if last in [\"a\", \"b\", \"c\", \"d\"]:\n",
        "            return last\n",
        "    \n",
        "    # 토큰 단위로 찾기\n",
        "    for tok in text.split():\n",
        "        if tok in [\"a\", \"b\", \"c\", \"d\"]:\n",
        "            return tok\n",
        "    \n",
        "    return \"a\"  # Fallback\n",
        "\n",
        "\n",
        "def infer_single_fold(model_path, test_df, output_path):\n",
        "    \"\"\"단일 Fold 추론\"\"\"\n",
        "    \n",
        "    # 모델 로드\n",
        "    if cfg.USE_ADVANCED_MODEL:\n",
        "        model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "            model_path,\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.float16\n",
        "        )\n",
        "    else:\n",
        "        model_infer = AutoModelForVision2Seq.from_pretrained(\n",
        "            model_path,\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.float16\n",
        "        )\n",
        "    \n",
        "    model_infer = model_infer.to(device)\n",
        "    processor_infer = AutoProcessor.from_pretrained(\n",
        "        model_path,\n",
        "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
        "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    \n",
        "    model_infer.eval()\n",
        "    \n",
        "    predictions = []\n",
        "    \n",
        "    for i in tqdm(range(len(test_df)), desc=\"Inference\"):\n",
        "        row = test_df.iloc[i]\n",
        "        \n",
        "        # 이미지 로드\n",
        "        img_path = os.path.join(cfg.DATA_DIR, row[\"path\"])\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "        except:\n",
        "            img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n",
        "        \n",
        "        # 프롬프트\n",
        "        user_text = build_mc_prompt(\n",
        "            str(row[\"question\"]),\n",
        "            str(row[\"a\"]), str(row[\"b\"]),\n",
        "            str(row[\"c\"]), str(row[\"d\"])\n",
        "        )\n",
        "        \n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"image\", \"image\": img},\n",
        "                {\"type\": \"text\", \"text\": user_text}\n",
        "            ]}\n",
        "        ]\n",
        "        \n",
        "        text = processor_infer.apply_chat_template(\n",
        "            messages, tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "        \n",
        "        inputs = processor_infer(\n",
        "            text=[text],\n",
        "            images=[img],\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "        \n",
        "        # 생성\n",
        "        with torch.no_grad():\n",
        "            out_ids = model_infer.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=cfg.MAX_NEW_TOKENS,\n",
        "                do_sample=cfg.DO_SAMPLE,\n",
        "                temperature=cfg.TEMPERATURE if cfg.DO_SAMPLE else None,\n",
        "                eos_token_id=processor_infer.tokenizer.eos_token_id\n",
        "            )\n",
        "        \n",
        "        output_text = processor_infer.batch_decode(out_ids, skip_special_tokens=True)[0]\n",
        "        answer = extract_choice(output_text)\n",
        "        predictions.append(answer)\n",
        "    \n",
        "    # 저장\n",
        "    submission = pd.DataFrame({\n",
        "        \"id\": test_df[\"id\"],\n",
        "        \"answer\": predictions\n",
        "    })\n",
        "    \n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    submission.to_csv(output_path, index=False)\n",
        "    print(f\"✅ Saved to {output_path}\")\n",
        "    \n",
        "    return submission\n",
        "\n",
        "\n",
        "# 각 Fold별 추론\n",
        "predictions_all = []\n",
        "\n",
        "if cfg.USE_KFOLD:\n",
        "    for fold in cfg.TRAIN_FOLDS:\n",
        "        model_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
        "        output_path = f\"{cfg.OUTPUT_DIR}/submission_fold{fold}.csv\"\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Inferencing Fold {fold}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        pred = infer_single_fold(model_path, test_df, output_path)\n",
        "        predictions_all.append(pred)\n",
        "else:\n",
        "    model_path = f\"{cfg.SAVE_DIR}/fold0_best\"\n",
        "    output_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n",
        "    \n",
        "    pred = infer_single_fold(model_path, test_df, output_path)\n",
        "    predictions_all.append(pred)\n",
        "\n",
        "print(\"\\n✅ All inference complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 11. Ensemble\n",
        "\n",
        "여러 Fold의 예측을 앙상블합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD and len(predictions_all) > 1:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Ensemble (Majority Voting)\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Majority Voting\n",
        "    ensemble_preds = []\n",
        "    \n",
        "    for i in range(len(test_df)):\n",
        "        votes = [pred.iloc[i]['answer'] for pred in predictions_all]\n",
        "        most_common = Counter(votes).most_common(1)[0][0]\n",
        "        ensemble_preds.append(most_common)\n",
        "    \n",
        "    # 최종 제출 파일\n",
        "    final_submission = pd.DataFrame({\n",
        "        \"id\": test_df[\"id\"],\n",
        "        \"answer\": ensemble_preds\n",
        "    })\n",
        "    \n",
        "    final_path = f\"{cfg.OUTPUT_DIR}/submission_ensemble.csv\"\n",
        "    final_submission.to_csv(final_path, index=False)\n",
        "    \n",
        "    print(f\"✅ Ensemble submission saved to {final_path}\")\n",
        "    print(f\"\\nAnswer Distribution:\")\n",
        "    print(final_submission['answer'].value_counts().sort_index())\n",
        "    \n",
        "else:\n",
        "    print(\"\\n✅ Single model - No ensemble needed\")\n",
        "    final_submission = predictions_all[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 12. 결과 분석 및 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 답변 분포 시각화\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "answer_counts = final_submission['answer'].value_counts().sort_index()\n",
        "sns.barplot(x=answer_counts.index, y=answer_counts.values, palette='viridis', ax=ax)\n",
        "ax.set_title('Final Submission Answer Distribution', fontsize=14, weight='bold')\n",
        "ax.set_xlabel('Answer')\n",
        "ax.set_ylabel('Count')\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 비율 표시\n",
        "for i, (ans, count) in enumerate(answer_counts.items()):\n",
        "    percentage = count / len(final_submission) * 100\n",
        "    ax.text(i, count + 10, f\"{percentage:.1f}%\", ha='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 통계 출력\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Final Statistics\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Total predictions: {len(final_submission)}\")\n",
        "print(f\"\\nAnswer counts:\")\n",
        "for ans, count in answer_counts.items():\n",
        "    print(f\"  {ans}: {count:5d} ({count/len(final_submission)*100:5.1f}%)\")\n",
        "\n",
        "# 제출 파일 샘플\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Sample Predictions\")\n",
        "print(f\"{'='*60}\")\n",
        "print(final_submission.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✅ 13. 최종 정리\n",
        "\n",
        "### 🎉 완료된 작업\n",
        "\n",
        "1. ✅ **환경 설정** - 패키지 설치 및 임포트\n",
        "2. ✅ **Config** - 하이퍼파라미터 통합 관리\n",
        "3. ✅ **데이터 로드 & EDA** - 탐색적 분석\n",
        "4. ✅ **Stratified K-Fold** - CV Splits 생성\n",
        "5. ✅ **Dataset & DataLoader** - 라벨 정렬 교정 적용\n",
        "6. ✅ **Model & Processor** - QLoRA 모델 로드 (T4 호환)\n",
        "7. ✅ **Training Loop** - AMP, EMA, SWA, Cosine Warmup 적용\n",
        "8. ✅ **Inference** - TTA 지원 추론\n",
        "9. ✅ **Ensemble** - Majority Voting\n",
        "10. ✅ **Results** - 시각화 및 통계\n",
        "\n",
        "### 🚀 다음 단계\n",
        "\n",
        "1. **하이퍼파라미터 튜닝**\n",
        "   - Learning rate, LoRA rank 조정\n",
        "   - Batch size, Grad accumulation 최적화\n",
        "\n",
        "2. **모델 크기 확대**\n",
        "   - 7B 모델 사용 (더 높은 정확도)\n",
        "   - Image size 증가 (512, 768)\n",
        "\n",
        "3. **고급 기법 활성화**\n",
        "   - TTA scales 추가\n",
        "   - SWA 적용\n",
        "   - 데이터 증강 활성화\n",
        "\n",
        "4. **에폭 증가**\n",
        "   - NUM_EPOCHS = 3~5\n",
        "\n",
        "### 📌 Important Notes\n",
        "\n",
        "- **T4 호환**: Float16, SDPA attention 사용\n",
        "- **라벨 정렬**: Assistant 메시지에 정답 포함 (핵심!)\n",
        "- **재현성**: Seed 42 고정\n",
        "- **메모리**: Gradient checkpointing, 4-bit QLoRA\n",
        "\n",
        "---\n",
        "\n",
        "**🤖 Generated for SSAFY AI Project 2025**\n",
        "\n",
        "**📧 Contact**: GitHub Issues\n",
        "\n",
        "**⭐ 행운을 빕니다!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}