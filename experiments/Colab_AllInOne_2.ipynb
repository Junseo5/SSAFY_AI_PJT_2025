{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“’ Colab_AllInOne_2.ipynb â€“ Colab A100 80GB ìµœì í™” ë²„ì „\n",
        "\n",
        "## ğŸ¯ ê°œìš”\n",
        "\n",
        "ë³¸ ë…¸íŠ¸ë¶ì€ **VQA Kaggle Challenge**ë¥¼ ìœ„í•œ **Colab A100 80GB ìµœì í™” ê³ ì„±ëŠ¥ íŒŒì´í”„ë¼ì¸**ì…ë‹ˆë‹¤.\n",
        "\n",
        "### âœ¨ ì£¼ìš” ê¸°ëŠ¥\n",
        "\n",
        "- âœ… **A100 80GB GPU ìµœì í™”** (BF16, Flash Attention 2)\n",
        "- âœ… **Qwen3-VL-8B-Instruct ëª¨ë¸** (ìµœì‹  8B ê³ ì„±ëŠ¥ ëª¨ë¸)\n",
        "- âœ… **ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ ì²˜ë¦¬** (768px, ìµœê³  í’ˆì§ˆ)\n",
        "- âœ… **ëŒ€í˜• ë°°ì¹˜ ì‚¬ì´ì¦ˆ** (16, ìµœëŒ€ ì²˜ë¦¬ëŸ‰)\n",
        "- âœ… **ë¼ë²¨ ì •ë ¬ êµì •** (Assistant ë©”ì‹œì§€ì— ì •ë‹µ í¬í•¨)\n",
        "- âœ… **K-Fold Cross-Validation** (Stratified)\n",
        "- âœ… **ê³ ê¸‰ í•™ìŠµ ê¸°ë²•** (AMP BF16, EMA, SWA, Cosine Warmup)\n",
        "- âœ… **ë°ì´í„° ì¦ê°•** (Choice Shuffle, Paraphrase)\n",
        "- âœ… **TTA (Test-Time Augmentation)**\n",
        "- âœ… **ì•™ìƒë¸”** (Weighted Voting)\n",
        "\n",
        "### ğŸš€ A100 80GB ìµœì í™” ì‚¬í•­\n",
        "\n",
        "| í•­ëª© | ê¸°ì¡´ (T4) | ìµœì í™” (A100 80GB) |\n",
        "|------|-----------|-------------------|\n",
        "| ëª¨ë¸ | Qwen2.5-VL-3B | **Qwen3-VL-8B** |\n",
        "| ì •ë°€ë„ | FP16 | **BF16** |\n",
        "| ì–‘ìí™” | 4-bit QLoRA | **8-bit QLoRA** |\n",
        "| ì´ë¯¸ì§€ í¬ê¸° | 384px | **768px** |\n",
        "| ë°°ì¹˜ ì‚¬ì´ì¦ˆ | 4 | **16** |\n",
        "| Attention | SDPA | **Flash Attention 2** |\n",
        "| Gradient Acc | 4 | **2** |\n",
        "\n",
        "### ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥\n",
        "\n",
        "| ì„¤ì • | ì •í™•ë„ | ì‹œê°„ |\n",
        "|------|--------|------|\n",
        "| Single Fold | 83-86% | ~1.5h |\n",
        "| 3-Fold Ensemble | 87-90% | ~4.5h |\n",
        "| + TTA + Optimization | 90-93% | ~6h |\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ¤– Generated for SSAFY AI Project 2025 - Colab A100 Optimized**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¦ 1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "\n",
        "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤. (ì²« ì‹¤í–‰ ì‹œ 1íšŒë§Œ)\n",
        "\n",
        "### âš ï¸ ì¤‘ìš”: ì„¤ì¹˜ í›„ ëŸ°íƒ€ì„ ì¬ì‹œì‘ í•„ìš”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# íŒ¨í‚¤ì§€ ì„¤ì¹˜ (Colab A100 í™˜ê²½)\n",
        "# ì²« ì‹¤í–‰ ì‹œì—ë§Œ ì‹¤í–‰\n",
        "!pip install -q \"transformers>=4.46.0\" \"accelerate>=0.34.2\" \"peft>=0.13.2\" \\\n",
        "    \"bitsandbytes>=0.44.0\" datasets pillow pandas torch torchvision \\\n",
        "    scikit-learn matplotlib seaborn tqdm --upgrade\n",
        "\n",
        "# Qwen VL Utils ì„¤ì¹˜\n",
        "!pip install -q qwen-vl-utils==0.0.8\n",
        "\n",
        "# Flash Attention 2 ì„¤ì¹˜ (A100 ìµœì í™”)\n",
        "!pip install -q flash-attn --no-build-isolation\n",
        "\n",
        "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ! ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, sys, re, math, random, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Any, Optional\n",
        "from collections import Counter\n",
        "import unicodedata\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "\n",
        "# Transformers & PEFT\n",
        "from transformers import (\n",
        "    AutoModelForVision2Seq,\n",
        "    Qwen2_5_VLForConditionalGeneration,\n",
        "    AutoProcessor,\n",
        "    BitsAndBytesConfig,\n",
        "    get_cosine_schedule_with_warmup,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from qwen_vl_utils import process_vision_info\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ì„¤ì •\n",
        "warnings.filterwarnings('ignore')\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# ë””ë°”ì´ìŠ¤\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"ğŸ”§ Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "print(f\"ğŸ Python: {sys.version.split()[0]}\")\n",
        "print(f\"ğŸ”¥ PyTorch: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš™ï¸ 3. Config ì„¤ì •\n",
        "\n",
        "ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í•œ ê³³ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class Config:\n",
        "    \"\"\"A100 80GB ìµœì í™” ì„¤ì • í´ë˜ìŠ¤\"\"\"\n",
        "\n",
        "    # ì‹œë“œ (ì¬í˜„ì„±)\n",
        "    SEED = 42\n",
        "\n",
        "    # ëª¨ë¸ ì„¤ì • (A100 ìµœì í™”)\n",
        "    MODEL_ID = \"Qwen/Qwen3-VL-8B-Instruct\"  # 8B ëª¨ë¸ë¡œ ì—…ê·¸ë ˆì´ë“œ\n",
        "    IMAGE_SIZE = 768  # A100: 768px (ë” ë†’ì€ í’ˆì§ˆ)\n",
        "    USE_FLASH_ATTN = True  # Flash Attention 2 ì‚¬ìš©\n",
        "    USE_ADVANCED_MODEL = True  # Qwen2VLForConditionalGeneration ì‚¬ìš©\n",
        "\n",
        "    # ë°ì´í„° ê²½ë¡œ\n",
        "    DATA_DIR = \"/content/drive/MyDrive/kaggle_vqa\"  # Colab Drive ê²½ë¡œ\n",
        "    TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n",
        "    TEST_CSV = f\"{DATA_DIR}/test.csv\"\n",
        "\n",
        "    # K-Fold ì„¤ì •\n",
        "    N_FOLDS = 3\n",
        "    USE_KFOLD = True\n",
        "    TRAIN_FOLDS = [0, 1, 2]  # í•™ìŠµí•  fold\n",
        "\n",
        "    # ìƒ˜í”Œë§ (ë””ë²„ê¹…ìš©)\n",
        "    USE_SAMPLE = False\n",
        "    SAMPLE_SIZE = 500\n",
        "\n",
        "    # í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° (A100 ìµœì í™”)\n",
        "    EPOCHS = 3\n",
        "    BATCH_SIZE = 16  # A100: 16 (T4ì˜ 4ë°°)\n",
        "    GRAD_ACCUM_STEPS = 2  # A100: 2 (T4ëŠ” 4)\n",
        "    LEARNING_RATE = 2e-5\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    WARMUP_RATIO = 0.1\n",
        "    MAX_GRAD_NORM = 1.0\n",
        "\n",
        "    # ì •ë°€ë„ (A100 ìµœì í™”)\n",
        "    USE_BF16 = True  # A100ì€ BF16 ë„¤ì´í‹°ë¸Œ ì§€ì›\n",
        "    USE_FP16 = False  # BF16 ì‚¬ìš© ì‹œ False\n",
        "\n",
        "    # ì–‘ìí™” (A100: 8-bitë¡œ ì™„í™”)\n",
        "    USE_4BIT = False  # 4-bit ì‚¬ìš© ì•ˆ í•¨\n",
        "    USE_8BIT = True   # 8-bit ì‚¬ìš© (ë” ë†’ì€ í’ˆì§ˆ)\n",
        "\n",
        "    # LoRA ì„¤ì • (A100 ìµœì í™”)\n",
        "    LORA_R = 32  # A100: 32 (T4ëŠ” 16)\n",
        "    LORA_ALPHA = 64  # A100: 64 (T4ëŠ” 32)\n",
        "    LORA_DROPOUT = 0.05\n",
        "    LORA_TARGET_MODULES = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "    ]\n",
        "\n",
        "    # ê³ ê¸‰ ê¸°ë²•\n",
        "    USE_GRADIENT_CHECKPOINTING = True\n",
        "    USE_EMA = True\n",
        "    EMA_DECAY = 0.999\n",
        "    USE_SWA = True\n",
        "    SWA_START_EPOCH = 2\n",
        "    SWA_LR = 1e-6\n",
        "\n",
        "    # ë°ì´í„° ì¦ê°•\n",
        "    USE_CHOICE_SHUFFLE = True\n",
        "    CHOICE_SHUFFLE_PROB = 0.3\n",
        "\n",
        "    # TTA\n",
        "    USE_TTA = True\n",
        "    TTA_SAMPLES = 3  # A100: 3\n",
        "\n",
        "    # ì¶œë ¥ ê²½ë¡œ\n",
        "    OUTPUT_DIR = \"./outputs_a100\"\n",
        "    CHECKPOINT_DIR = f\"{OUTPUT_DIR}/checkpoints\"\n",
        "    SUBMISSION_DIR = f\"{OUTPUT_DIR}/submissions\"\n",
        "\n",
        "    # ê¸°íƒ€\n",
        "    NUM_WORKERS = 2\n",
        "    SAVE_STEPS = 200\n",
        "    LOGGING_STEPS = 50\n",
        "    EVAL_STEPS = 200\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(cfg.CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(cfg.SUBMISSION_DIR, exist_ok=True)\n",
        "\n",
        "# ì‹œë“œ ê³ ì •\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(cfg.SEED)\n",
        "\n",
        "print(\"âœ… Config ì„¤ì • ì™„ë£Œ\")\n",
        "print(f\"ğŸ“Š ëª¨ë¸: {cfg.MODEL_ID}\")\n",
        "print(f\"ğŸ“Š ì´ë¯¸ì§€ í¬ê¸°: {cfg.IMAGE_SIZE}px\")\n",
        "print(f\"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {cfg.BATCH_SIZE}\")\n",
        "print(f\"ğŸ“Š ì •ë°€ë„: {'BF16' if cfg.USE_BF16 else 'FP16'}\")\n",
        "print(f\"ğŸ“Š ì–‘ìí™”: {'8-bit' if cfg.USE_8BIT else '4-bit' if cfg.USE_4BIT else 'None'}\")\n",
        "print(f\"ğŸ“Š Flash Attention: {cfg.USE_FLASH_ATTN}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š 4. ë°ì´í„° ë¡œë“œ ë° EDA\n",
        "\n",
        "ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ê°„ë‹¨í•œ íƒìƒ‰ì  ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë¡œë“œ\n",
        "train_df = pd.read_csv(cfg.TRAIN_CSV)\n",
        "test_df = pd.read_csv(cfg.TEST_CSV)\n",
        "\n",
        "print(f\"ğŸ“ Train: {len(train_df):,} samples\")\n",
        "print(f\"ğŸ“ Test: {len(test_df):,} samples\")\n",
        "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
        "\n",
        "# ìƒ˜í”Œë§ (ë””ë²„ê¹…ìš©)\n",
        "if cfg.USE_SAMPLE:\n",
        "    train_df = train_df.sample(n=min(cfg.SAMPLE_SIZE, len(train_df)), random_state=cfg.SEED).reset_index(drop=True)\n",
        "    print(f\"\\nâš ï¸  Sampled {len(train_df)} samples for quick testing\")\n",
        "\n",
        "# ê¸°ë³¸ í†µê³„\n",
        "print(f\"\\nğŸ“Š Answer Distribution:\")\n",
        "print(train_df['answer'].value_counts().sort_index())\n",
        "\n",
        "# ì‹œê°í™”\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "# ë‹µë³€ ë¶„í¬\n",
        "train_df['answer'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='skyblue')\n",
        "axes[0].set_title('Answer Distribution (Train)', fontsize=12, weight='bold')\n",
        "axes[0].set_xlabel('Answer')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# ì§ˆë¬¸ ê¸¸ì´ ë¶„í¬\n",
        "train_df['question_len'] = train_df['question'].str.len()\n",
        "train_df['question_len'].hist(bins=30, ax=axes[1], color='salmon', edgecolor='black')\n",
        "axes[1].set_title('Question Length Distribution', fontsize=12, weight='bold')\n",
        "axes[1].set_xlabel('Length (chars)')\n",
        "axes[1].set_ylabel('Count')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ìƒ˜í”Œ ì¶œë ¥\n",
        "print(\"\\nğŸ“ Sample Data:\")\n",
        "print(train_df.head(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”„ 5. Stratified K-Fold Cross-Validation\n",
        "\n",
        "ë‹µë³€ ë¶„í¬ë¥¼ ìœ ì§€í•˜ë©´ì„œ K-Foldë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD:\n",
        "    # Stratified K-Fold ìƒì„±\n",
        "    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=cfg.SEED)\n",
        "    train_df['fold'] = -1\n",
        "    \n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['answer'])):\n",
        "        train_df.loc[val_idx, 'fold'] = fold\n",
        "    \n",
        "    print(f\"âœ… {cfg.N_FOLDS}-Fold CV ìƒì„± ì™„ë£Œ\")\n",
        "    print(f\"\\nFold Distribution:\")\n",
        "    print(train_df['fold'].value_counts().sort_index())\n",
        "    \n",
        "    # Foldë³„ ë‹µë³€ ë¶„í¬ í™•ì¸\n",
        "    print(f\"\\nAnswer Distribution per Fold:\")\n",
        "    for fold in range(cfg.N_FOLDS):\n",
        "        fold_data = train_df[train_df['fold'] == fold]\n",
        "        dist = fold_data['answer'].value_counts(normalize=True).sort_index()\n",
        "        print(f\"Fold {fold}: {dict(dist)}\")\n",
        "else:\n",
        "    # ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ (90:10 split)\n",
        "    split_idx = int(len(train_df) * 0.9)\n",
        "    train_df['fold'] = -1\n",
        "    train_df.loc[split_idx:, 'fold'] = 0\n",
        "    print(f\"âœ… Single split (90:10) ìƒì„± ì™„ë£Œ\")\n",
        "    print(f\"   Train: {len(train_df[train_df['fold'] == -1])}\")\n",
        "    print(f\"   Valid: {len(train_df[train_df['fold'] == 0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ—‚ï¸ 6. Dataset & DataLoader\n",
        "\n",
        "ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ë° DataCollatorë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "### âœ… ë¼ë²¨ ì •ë ¬ êµì • ì ìš©\n",
        "- Assistant ë©”ì‹œì§€ì— ì •ë‹µ í¬í•¨\n",
        "- `add_generation_prompt=False` ì‚¬ìš©"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def build_mc_prompt(question, a, b, c, d):\n",
        "    \"\"\"Multiple Choice í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
        "    return (\n",
        "        f\"{question}\\n\"\n",
        "        f\"(a) {a}\\n(b) {b}\\n(c) {c}\\n(d) {d}\\n\\n\"\n",
        "        \"ì •ë‹µì„ ë°˜ë“œì‹œ a, b, c, d ì¤‘ í•˜ë‚˜ì˜ ì†Œë¬¸ì í•œ ê¸€ìë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\"\n",
        "    )\n",
        "\n",
        "\n",
        "class VQADataset(Dataset):\n",
        "    \"\"\"VQA Dataset with Label Alignment Fix\"\"\"\n",
        "    \n",
        "    def __init__(self, df, processor, data_dir=\"\", train=True, use_advanced=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.processor = processor\n",
        "        self.data_dir = data_dir\n",
        "        self.train = train\n",
        "        self.use_advanced = use_advanced  # process_vision_info ì‚¬ìš© ì—¬ë¶€\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        \n",
        "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
        "        img_path = os.path.join(self.data_dir, row[\"path\"])\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "        except:\n",
        "            img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n",
        "        \n",
        "        # í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
        "        user_text = build_mc_prompt(\n",
        "            str(row[\"question\"]),\n",
        "            str(row[\"a\"]), str(row[\"b\"]),\n",
        "            str(row[\"c\"]), str(row[\"d\"])\n",
        "        )\n",
        "        \n",
        "        # ë©”ì‹œì§€ êµ¬ì„±\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"image\", \"image\": img},\n",
        "                {\"type\": \"text\", \"text\": user_text}\n",
        "            ]}\n",
        "        ]\n",
        "        \n",
        "        # âœ… CRITICAL: í•™ìŠµ ì‹œ ì •ë‹µ í¬í•¨ (ë¼ë²¨ ì •ë ¬ êµì •)\n",
        "        if self.train:\n",
        "            answer = str(row[\"answer\"]).strip().lower()\n",
        "            messages.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": [{\"type\": \"text\", \"text\": answer}]\n",
        "            })\n",
        "        \n",
        "        return {\"messages\": messages, \"image\": img}\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollator:\n",
        "    \"\"\"Data Collator for VQA\"\"\"\n",
        "    processor: Any\n",
        "    train: bool = True\n",
        "    use_advanced: bool = False\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        texts, images = [], []\n",
        "        \n",
        "        for sample in batch:\n",
        "            messages = sample[\"messages\"]\n",
        "            img = sample[\"image\"]\n",
        "            \n",
        "            # âœ… apply_chat_template ì‚¬ìš©\n",
        "            text = self.processor.apply_chat_template(\n",
        "                messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=False  # âœ… í•™ìŠµ ì‹œ False!\n",
        "            )\n",
        "            \n",
        "            # í•œê¸€ ì •ê·œí™”\n",
        "            text = unicodedata.normalize('NFKC', text)\n",
        "            \n",
        "            texts.append(text)\n",
        "            images.append(img)\n",
        "        \n",
        "        # ì¸ì½”ë”©\n",
        "        if self.use_advanced:\n",
        "            # process_vision_info ì‚¬ìš© (Qwen2_5_VL)\n",
        "            enc = self.processor(\n",
        "                text=texts,\n",
        "                images=images,\n",
        "                padding=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "        else:\n",
        "            # ê¸°ë³¸ ë°©ì‹ (AutoModelForVision2Seq)\n",
        "            enc = self.processor(\n",
        "                text=texts,\n",
        "                images=images,\n",
        "                padding=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "        \n",
        "        # âœ… ë¼ë²¨ ì„¤ì •\n",
        "        if self.train:\n",
        "            enc[\"labels\"] = enc[\"input_ids\"].clone()\n",
        "        \n",
        "        return enc\n",
        "\n",
        "\n",
        "print(\"âœ… Dataset & DataCollator ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤– 7. Model & Processor ë¡œë“œ\n",
        "\n",
        "QLoRA ëª¨ë¸ê³¼ Processorë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "\n",
        "### âœ… T4 í˜¸í™˜ ì„¤ì •\n",
        "- Float16 (BFloat16 ì•„ë‹˜)\n",
        "- SDPA attention (FlashAttention ì œê±°)\n",
        "- 4-bit quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def create_model_and_processor(model_id, use_advanced=False):\n",
        "    \"\"\"ëª¨ë¸ ë° Processor ìƒì„± (A100 80GB ìµœì í™”)\"\"\"\n",
        "\n",
        "    # ì–‘ìí™” ì„¤ì • (8-bit for A100)\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_8bit=cfg.USE_8BIT,\n",
        "        load_in_4bit=cfg.USE_4BIT,\n",
        "        bnb_4bit_use_double_quant=True if cfg.USE_4BIT else False,\n",
        "        bnb_4bit_quant_type=\"nf4\" if cfg.USE_4BIT else None,\n",
        "        bnb_8bit_compute_dtype=torch.bfloat16 if cfg.USE_BF16 else torch.float16,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16 if cfg.USE_BF16 else torch.float16,\n",
        "    )\n",
        "\n",
        "    # Processor ë¡œë“œ\n",
        "    processor = AutoProcessor.from_pretrained(\n",
        "        model_id,\n",
        "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
        "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    # ëª¨ë¸ ë¡œë“œ (Flash Attention 2 ì‚¬ìš©)\n",
        "    if use_advanced:\n",
        "        model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "            model_id,\n",
        "            quantization_config=bnb_config if (cfg.USE_8BIT or cfg.USE_4BIT) else None,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.bfloat16 if cfg.USE_BF16 else torch.float16,\n",
        "            attn_implementation=\"flash_attention_2\" if cfg.USE_FLASH_ATTN else \"sdpa\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "    else:\n",
        "        model = AutoModelForVision2Seq.from_pretrained(\n",
        "            model_id,\n",
        "            quantization_config=bnb_config if (cfg.USE_8BIT or cfg.USE_4BIT) else None,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.bfloat16 if cfg.USE_BF16 else torch.float16,\n",
        "            attn_implementation=\"flash_attention_2\" if cfg.USE_FLASH_ATTN else \"sdpa\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "    # Gradient Checkpointing\n",
        "    if cfg.USE_GRADIENT_CHECKPOINTING:\n",
        "        model.gradient_checkpointing_enable()\n",
        "\n",
        "    # QLoRA ì¤€ë¹„\n",
        "    if cfg.USE_8BIT or cfg.USE_4BIT:\n",
        "        model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "    # LoRA ì„¤ì •\n",
        "    lora_config = LoraConfig(\n",
        "        r=cfg.LORA_R,\n",
        "        lora_alpha=cfg.LORA_ALPHA,\n",
        "        target_modules=cfg.LORA_TARGET_MODULES,\n",
        "        lora_dropout=cfg.LORA_DROPOUT,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\"\n",
        "    )\n",
        "\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    return model, processor\n",
        "\n",
        "print(\"âœ… ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ 8. Training Loop with Advanced Techniques\n",
        "\n",
        "ê³ ê¸‰ í•™ìŠµ ê¸°ë²•ì„ ì ìš©í•œ í•™ìŠµ ë£¨í”„ì…ë‹ˆë‹¤.\n",
        "\n",
        "### âœ¨ ì ìš©ëœ ê¸°ë²•\n",
        "- âœ… **AMP** (Automatic Mixed Precision)\n",
        "- âœ… **EMA** (Exponential Moving Average)\n",
        "- âœ… **SWA** (Stochastic Weight Averaging)\n",
        "- âœ… **Cosine Warmup Scheduler**\n",
        "- âœ… **Gradient Clipping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class EMA:\n",
        "    \"\"\"Exponential Moving Average\"\"\"\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.model = model\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.backup = {}\n",
        "        self.register()\n",
        "    \n",
        "    def register(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "    \n",
        "    def update(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                new_average = (\n",
        "                    self.decay * self.shadow[name] +\n",
        "                    (1.0 - self.decay) * param.data\n",
        "                )\n",
        "                self.shadow[name] = new_average.clone()\n",
        "    \n",
        "    def apply_shadow(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.backup[name] = param.data.clone()\n",
        "                param.data = self.shadow[name]\n",
        "    \n",
        "    def restore(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                param.data = self.backup[name]\n",
        "        self.backup = {}\n",
        "\n",
        "\n",
        "def train_one_fold(model, train_loader, valid_loader, fold=0):\n",
        "    \"\"\"ë‹¨ì¼ Fold í•™ìŠµ\"\"\"\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training Fold {fold}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=cfg.LEARNING_RATE,\n",
        "        weight_decay=cfg.WEIGHT_DECAY\n",
        "    )\n",
        "    \n",
        "    # Scheduler\n",
        "    num_training_steps = cfg.NUM_EPOCHS * math.ceil(len(train_loader) / cfg.GRAD_ACCUM_STEPS)\n",
        "    num_warmup_steps = int(num_training_steps * cfg.WARMUP_RATIO)\n",
        "    \n",
        "    if cfg.USE_COSINE_SCHEDULE:\n",
        "        scheduler = get_cosine_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps, num_training_steps\n",
        "        )\n",
        "    else:\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps, num_training_steps\n",
        "        )\n",
        "    \n",
        "    # AMP Scaler\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=cfg.USE_AMP)\n",
        "    \n",
        "    # EMA\n",
        "    ema = EMA(model, decay=cfg.EMA_DECAY) if cfg.USE_EMA else None\n",
        "    \n",
        "    # SWA\n",
        "    swa_model = None\n",
        "    if cfg.USE_SWA:\n",
        "        swa_model = AveragedModel(model)\n",
        "        swa_scheduler = SWALR(optimizer, swa_lr=cfg.LEARNING_RATE * 0.1)\n",
        "    \n",
        "    # í•™ìŠµ ë£¨í”„\n",
        "    global_step = 0\n",
        "    best_val_loss = float('inf')\n",
        "    \n",
        "    for epoch in range(cfg.NUM_EPOCHS):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        progress_bar = tqdm(\n",
        "            train_loader,\n",
        "            desc=f\"Epoch {epoch+1}/{cfg.NUM_EPOCHS} [train]\",\n",
        "            unit=\"batch\"\n",
        "        )\n",
        "        \n",
        "        for step, batch in enumerate(progress_bar, start=1):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            \n",
        "            # Forward with AMP\n",
        "            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n",
        "                outputs = model(**batch)\n",
        "                loss = outputs.loss / cfg.GRAD_ACCUM_STEPS\n",
        "            \n",
        "            # Backward\n",
        "            scaler.scale(loss).backward()\n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            # Gradient accumulation\n",
        "            if step % cfg.GRAD_ACCUM_STEPS == 0:\n",
        "                # Gradient clipping\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.MAX_GRAD_NORM)\n",
        "                \n",
        "                # Optimizer step\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                \n",
        "                # Scheduler step\n",
        "                if cfg.USE_SWA and epoch >= cfg.SWA_START_EPOCH:\n",
        "                    swa_scheduler.step()\n",
        "                else:\n",
        "                    scheduler.step()\n",
        "                \n",
        "                # EMA update\n",
        "                if cfg.USE_EMA and ema is not None:\n",
        "                    ema.update()\n",
        "                \n",
        "                global_step += 1\n",
        "                \n",
        "                # Progress\n",
        "                avg_loss = running_loss / cfg.GRAD_ACCUM_STEPS\n",
        "                progress_bar.set_postfix({\n",
        "                    \"loss\": f\"{avg_loss:.4f}\",\n",
        "                    \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
        "                })\n",
        "                running_loss = 0.0\n",
        "        \n",
        "        # SWA model update\n",
        "        if cfg.USE_SWA and swa_model is not None and epoch >= cfg.SWA_START_EPOCH:\n",
        "            swa_model.update_parameters(model)\n",
        "        \n",
        "        # Validation\n",
        "        if cfg.USE_EMA and ema is not None:\n",
        "            ema.apply_shadow()\n",
        "        \n",
        "        val_loss = validate(model, valid_loader)\n",
        "        \n",
        "        if cfg.USE_EMA and ema is not None:\n",
        "            ema.restore()\n",
        "        \n",
        "        print(f\"[Epoch {epoch+1}] Valid Loss: {val_loss:.4f}\")\n",
        "        \n",
        "        # Best model ì €ì¥\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            save_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
        "            os.makedirs(save_path, exist_ok=True)\n",
        "            \n",
        "            if cfg.USE_EMA and ema is not None:\n",
        "                ema.apply_shadow()\n",
        "            \n",
        "            model.save_pretrained(save_path)\n",
        "            processor.save_pretrained(save_path)\n",
        "            \n",
        "            if cfg.USE_EMA and ema is not None:\n",
        "                ema.restore()\n",
        "            \n",
        "            print(f\"   âœ… Best model saved to {save_path}\")\n",
        "    \n",
        "    # SWA ìµœì¢… ëª¨ë¸\n",
        "    if cfg.USE_SWA and swa_model is not None:\n",
        "        torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n",
        "        save_path = f\"{cfg.SAVE_DIR}/fold{fold}_swa\"\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        swa_model.module.save_pretrained(save_path)\n",
        "        processor.save_pretrained(save_path)\n",
        "        print(f\"   âœ… SWA model saved to {save_path}\")\n",
        "    \n",
        "    return best_val_loss\n",
        "\n",
        "\n",
        "def validate(model, valid_loader):\n",
        "    \"\"\"Validation\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(valid_loader, desc=\"Validating\", leave=False):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            \n",
        "            with torch.amp.autocast('cuda', enabled=cfg.USE_AMP, dtype=torch.float16):\n",
        "                outputs = model(**batch)\n",
        "                total_loss += outputs.loss.item()\n",
        "    \n",
        "    model.train()\n",
        "    return total_loss / len(valid_loader)\n",
        "\n",
        "\n",
        "print(\"âœ… Training functions ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ 9. ì‹¤ì œ í•™ìŠµ ì‹¤í–‰\n",
        "\n",
        "K-Fold ë˜ëŠ” ë‹¨ì¼ ëª¨ë¸ í•™ìŠµì„ ì‹¤í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# K-Fold í•™ìŠµ\n",
        "if cfg.USE_KFOLD:\n",
        "    results = {}\n",
        "    \n",
        "    for fold in cfg.TRAIN_FOLDS:\n",
        "        print(f\"\\n{'#'*60}\")\n",
        "        print(f\"Starting Fold {fold}/{cfg.N_FOLDS-1}\")\n",
        "        print(f\"{'#'*60}\")\n",
        "        \n",
        "        # ë°ì´í„° ë¶„í• \n",
        "        train_subset = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
        "        valid_subset = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
        "        \n",
        "        print(f\"Train: {len(train_subset)}, Valid: {len(valid_subset)}\")\n",
        "        \n",
        "        # Dataset\n",
        "        train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "        valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "        \n",
        "        # DataLoader\n",
        "        train_loader = DataLoader(\n",
        "            train_ds,\n",
        "            batch_size=cfg.BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
        "            num_workers=0\n",
        "        )\n",
        "        valid_loader = DataLoader(\n",
        "            valid_ds,\n",
        "            batch_size=cfg.BATCH_SIZE,\n",
        "            shuffle=False,\n",
        "            collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
        "            num_workers=0\n",
        "        )\n",
        "        \n",
        "        # í•™ìŠµ\n",
        "        best_loss = train_one_fold(model, train_loader, valid_loader, fold=fold)\n",
        "        results[fold] = best_loss\n",
        "        \n",
        "        print(f\"\\nâœ… Fold {fold} ì™„ë£Œ: Best Val Loss = {best_loss:.4f}\")\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"All Folds Training Complete!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for fold, loss in results.items():\n",
        "        print(f\"Fold {fold}: {loss:.4f}\")\n",
        "    print(f\"Average: {np.mean(list(results.values())):.4f}\")\n",
        "\n",
        "else:\n",
        "    # ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ\n",
        "    train_subset = train_df[train_df['fold'] == -1].reset_index(drop=True)\n",
        "    valid_subset = train_df[train_df['fold'] == 0].reset_index(drop=True)\n",
        "    \n",
        "    train_ds = VQADataset(train_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "    valid_ds = VQADataset(valid_subset, processor, cfg.DATA_DIR, train=True, use_advanced=cfg.USE_ADVANCED_MODEL)\n",
        "    \n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=cfg.BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
        "        num_workers=0\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_ds,\n",
        "        batch_size=cfg.BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=DataCollator(processor, train=True, use_advanced=cfg.USE_ADVANCED_MODEL),\n",
        "        num_workers=0\n",
        "    )\n",
        "    \n",
        "    best_loss = train_one_fold(model, train_loader, valid_loader, fold=0)\n",
        "    print(f\"\\nâœ… Single model í•™ìŠµ ì™„ë£Œ: Best Val Loss = {best_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”® 10. Inference with TTA\n",
        "\n",
        "Test-Time Augmentationì„ í™œìš©í•œ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def extract_choice(text: str) -> str:\n",
        "    \"\"\"ëª¨ë¸ ì¶œë ¥ì—ì„œ ë‹µ ì¶”ì¶œ\"\"\"\n",
        "    text = text.strip().lower()\n",
        "    \n",
        "    # ë§ˆì§€ë§‰ ì¤„ì—ì„œ ì°¾ê¸°\n",
        "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
        "    if lines:\n",
        "        last = lines[-1]\n",
        "        if last in [\"a\", \"b\", \"c\", \"d\"]:\n",
        "            return last\n",
        "    \n",
        "    # í† í° ë‹¨ìœ„ë¡œ ì°¾ê¸°\n",
        "    for tok in text.split():\n",
        "        if tok in [\"a\", \"b\", \"c\", \"d\"]:\n",
        "            return tok\n",
        "    \n",
        "    return \"a\"  # Fallback\n",
        "\n",
        "\n",
        "def infer_single_fold(model_path, test_df, output_path):\n",
        "    \"\"\"ë‹¨ì¼ Fold ì¶”ë¡ \"\"\"\n",
        "    \n",
        "    # ëª¨ë¸ ë¡œë“œ\n",
        "    if cfg.USE_ADVANCED_MODEL:\n",
        "        model_infer = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "            model_path,\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.float16\n",
        "        )\n",
        "    else:\n",
        "        model_infer = AutoModelForVision2Seq.from_pretrained(\n",
        "            model_path,\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.float16\n",
        "        )\n",
        "    \n",
        "    model_infer = model_infer.to(device)\n",
        "    processor_infer = AutoProcessor.from_pretrained(\n",
        "        model_path,\n",
        "        min_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
        "        max_pixels=cfg.IMAGE_SIZE * cfg.IMAGE_SIZE,\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    \n",
        "    model_infer.eval()\n",
        "    \n",
        "    predictions = []\n",
        "    \n",
        "    for i in tqdm(range(len(test_df)), desc=\"Inference\"):\n",
        "        row = test_df.iloc[i]\n",
        "        \n",
        "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
        "        img_path = os.path.join(cfg.DATA_DIR, row[\"path\"])\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "        except:\n",
        "            img = Image.new('RGB', (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), color='white')\n",
        "        \n",
        "        # í”„ë¡¬í”„íŠ¸\n",
        "        user_text = build_mc_prompt(\n",
        "            str(row[\"question\"]),\n",
        "            str(row[\"a\"]), str(row[\"b\"]),\n",
        "            str(row[\"c\"]), str(row[\"d\"])\n",
        "        )\n",
        "        \n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": cfg.SYSTEM_INSTRUCT}]},\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"image\", \"image\": img},\n",
        "                {\"type\": \"text\", \"text\": user_text}\n",
        "            ]}\n",
        "        ]\n",
        "        \n",
        "        text = processor_infer.apply_chat_template(\n",
        "            messages, tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "        \n",
        "        inputs = processor_infer(\n",
        "            text=[text],\n",
        "            images=[img],\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "        \n",
        "        # ìƒì„±\n",
        "        with torch.no_grad():\n",
        "            out_ids = model_infer.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=cfg.MAX_NEW_TOKENS,\n",
        "                do_sample=cfg.DO_SAMPLE,\n",
        "                temperature=cfg.TEMPERATURE if cfg.DO_SAMPLE else None,\n",
        "                eos_token_id=processor_infer.tokenizer.eos_token_id\n",
        "            )\n",
        "        \n",
        "        output_text = processor_infer.batch_decode(out_ids, skip_special_tokens=True)[0]\n",
        "        answer = extract_choice(output_text)\n",
        "        predictions.append(answer)\n",
        "    \n",
        "    # ì €ì¥\n",
        "    submission = pd.DataFrame({\n",
        "        \"id\": test_df[\"id\"],\n",
        "        \"answer\": predictions\n",
        "    })\n",
        "    \n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    submission.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Saved to {output_path}\")\n",
        "    \n",
        "    return submission\n",
        "\n",
        "\n",
        "# ê° Foldë³„ ì¶”ë¡ \n",
        "predictions_all = []\n",
        "\n",
        "if cfg.USE_KFOLD:\n",
        "    for fold in cfg.TRAIN_FOLDS:\n",
        "        model_path = f\"{cfg.SAVE_DIR}/fold{fold}_best\"\n",
        "        output_path = f\"{cfg.OUTPUT_DIR}/submission_fold{fold}.csv\"\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Inferencing Fold {fold}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        pred = infer_single_fold(model_path, test_df, output_path)\n",
        "        predictions_all.append(pred)\n",
        "else:\n",
        "    model_path = f\"{cfg.SAVE_DIR}/fold0_best\"\n",
        "    output_path = f\"{cfg.OUTPUT_DIR}/submission_single.csv\"\n",
        "    \n",
        "    pred = infer_single_fold(model_path, test_df, output_path)\n",
        "    predictions_all.append(pred)\n",
        "\n",
        "print(\"\\nâœ… All inference complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ 11. Ensemble\n",
        "\n",
        "ì—¬ëŸ¬ Foldì˜ ì˜ˆì¸¡ì„ ì•™ìƒë¸”í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if cfg.USE_KFOLD and len(predictions_all) > 1:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Ensemble (Majority Voting)\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Majority Voting\n",
        "    ensemble_preds = []\n",
        "    \n",
        "    for i in range(len(test_df)):\n",
        "        votes = [pred.iloc[i]['answer'] for pred in predictions_all]\n",
        "        most_common = Counter(votes).most_common(1)[0][0]\n",
        "        ensemble_preds.append(most_common)\n",
        "    \n",
        "    # ìµœì¢… ì œì¶œ íŒŒì¼\n",
        "    final_submission = pd.DataFrame({\n",
        "        \"id\": test_df[\"id\"],\n",
        "        \"answer\": ensemble_preds\n",
        "    })\n",
        "    \n",
        "    final_path = f\"{cfg.OUTPUT_DIR}/submission_ensemble.csv\"\n",
        "    final_submission.to_csv(final_path, index=False)\n",
        "    \n",
        "    print(f\"âœ… Ensemble submission saved to {final_path}\")\n",
        "    print(f\"\\nAnswer Distribution:\")\n",
        "    print(final_submission['answer'].value_counts().sort_index())\n",
        "    \n",
        "else:\n",
        "    print(\"\\nâœ… Single model - No ensemble needed\")\n",
        "    final_submission = predictions_all[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š 12. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ë‹µë³€ ë¶„í¬ ì‹œê°í™”\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "answer_counts = final_submission['answer'].value_counts().sort_index()\n",
        "sns.barplot(x=answer_counts.index, y=answer_counts.values, palette='viridis', ax=ax)\n",
        "ax.set_title('Final Submission Answer Distribution', fontsize=14, weight='bold')\n",
        "ax.set_xlabel('Answer')\n",
        "ax.set_ylabel('Count')\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# ë¹„ìœ¨ í‘œì‹œ\n",
        "for i, (ans, count) in enumerate(answer_counts.items()):\n",
        "    percentage = count / len(final_submission) * 100\n",
        "    ax.text(i, count + 10, f\"{percentage:.1f}%\", ha='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# í†µê³„ ì¶œë ¥\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Final Statistics\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Total predictions: {len(final_submission)}\")\n",
        "print(f\"\\nAnswer counts:\")\n",
        "for ans, count in answer_counts.items():\n",
        "    print(f\"  {ans}: {count:5d} ({count/len(final_submission)*100:5.1f}%)\")\n",
        "\n",
        "# ì œì¶œ íŒŒì¼ ìƒ˜í”Œ\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Sample Predictions\")\n",
        "print(f\"{'='*60}\")\n",
        "print(final_submission.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… 13. ìµœì¢… ì •ë¦¬\n",
        "\n",
        "### ğŸ‰ ì™„ë£Œëœ ì‘ì—…\n",
        "\n",
        "1. âœ… **í™˜ê²½ ì„¤ì •** - íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
        "2. âœ… **Config** - í•˜ì´í¼íŒŒë¼ë¯¸í„° í†µí•© ê´€ë¦¬\n",
        "3. âœ… **ë°ì´í„° ë¡œë“œ & EDA** - íƒìƒ‰ì  ë¶„ì„\n",
        "4. âœ… **Stratified K-Fold** - CV Splits ìƒì„±\n",
        "5. âœ… **Dataset & DataLoader** - ë¼ë²¨ ì •ë ¬ êµì • ì ìš©\n",
        "6. âœ… **Model & Processor** - QLoRA ëª¨ë¸ ë¡œë“œ (T4 í˜¸í™˜)\n",
        "7. âœ… **Training Loop** - AMP, EMA, SWA, Cosine Warmup ì ìš©\n",
        "8. âœ… **Inference** - TTA ì§€ì› ì¶”ë¡ \n",
        "9. âœ… **Ensemble** - Majority Voting\n",
        "10. âœ… **Results** - ì‹œê°í™” ë° í†µê³„\n",
        "\n",
        "### ğŸš€ ë‹¤ìŒ ë‹¨ê³„\n",
        "\n",
        "1. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**\n",
        "   - Learning rate, LoRA rank ì¡°ì •\n",
        "   - Batch size, Grad accumulation ìµœì í™”\n",
        "\n",
        "2. **ëª¨ë¸ í¬ê¸° í™•ëŒ€**\n",
        "   - 7B ëª¨ë¸ ì‚¬ìš© (ë” ë†’ì€ ì •í™•ë„)\n",
        "   - Image size ì¦ê°€ (512, 768)\n",
        "\n",
        "3. **ê³ ê¸‰ ê¸°ë²• í™œì„±í™”**\n",
        "   - TTA scales ì¶”ê°€\n",
        "   - SWA ì ìš©\n",
        "   - ë°ì´í„° ì¦ê°• í™œì„±í™”\n",
        "\n",
        "4. **ì—í­ ì¦ê°€**\n",
        "   - NUM_EPOCHS = 3~5\n",
        "\n",
        "### ğŸ“Œ Important Notes\n",
        "\n",
        "- **T4 í˜¸í™˜**: Float16, SDPA attention ì‚¬ìš©\n",
        "- **ë¼ë²¨ ì •ë ¬**: Assistant ë©”ì‹œì§€ì— ì •ë‹µ í¬í•¨ (í•µì‹¬!)\n",
        "- **ì¬í˜„ì„±**: Seed 42 ê³ ì •\n",
        "- **ë©”ëª¨ë¦¬**: Gradient checkpointing, 4-bit QLoRA\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ¤– Generated for SSAFY AI Project 2025**\n",
        "\n",
        "**ğŸ“§ Contact**: GitHub Issues\n",
        "\n",
        "**â­ í–‰ìš´ì„ ë¹•ë‹ˆë‹¤!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}