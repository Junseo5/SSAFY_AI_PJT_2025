# ğŸ“‹ Kaggle VQA ëª…ì„¸ì„œ ê²€ì¦ ê²°ê³¼ ë° ìµœì¢… í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ê°€ì´ë“œ

## ğŸ” ê²€ì¦ ìš”ì•½

GPT ê²€ì¦ ê²°ê³¼, **6ê°€ì§€ ì¹˜ëª…ì  ì´ìŠˆ**ì™€ **ë‹¤ìˆ˜ì˜ ê³ íš¨ìœ¨ ê°œì„ ì•ˆ**ì´ ë°œê²¬ë˜ì—ˆìœ¼ë©°, ëª¨ë‘ ìˆ˜ì • ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.

---

## âš ï¸ ë°œê²¬ëœ ì¹˜ëª…ì  ì´ìŠˆ (Critical Blocking Issues)

### 1. Transformers ë²„ì „ & í´ë˜ìŠ¤ëª… ì˜¤ë¥˜ âŒâ†’âœ…
- **ë¬¸ì œ**: `Qwen2VLForConditionalGeneration`, `Qwen2VLProcessor` ì‚¬ìš©
- **ì›ì¸**: Qwen2.5-VLì€ ìµœì‹  transformers (>=4.49.0) í•„ìš”
- **í•´ê²°**: 
  ```python
  # âœ… ì˜¬ë°”ë¥¸ ë°©ì‹
  from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
  from qwen_vl_utils import process_vision_info
  
  # ì„¤ì¹˜
  pip install git+https://github.com/huggingface/transformers.git
  pip install qwen-vl-utils[decord]==0.0.8
  ```
- **ì˜í–¥**: KeyError: 'qwen2_5_vl' â†’ ëª¨ë¸ ë¡œë“œ ë¶ˆê°€
- **ì°¸ê³ **: [HuggingFace ê³µì‹ ë¬¸ì„œ](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct)

### 2. T4 GPUëŠ” BFloat16 ë¯¸ì§€ì› âŒâ†’âœ…
- **ë¬¸ì œ**: `bnb_4bit_compute_dtype=torch.bfloat16` ì‚¬ìš©
- **ì›ì¸**: T4ëŠ” Turing (SM75) ì•„í‚¤í…ì²˜ë¡œ BF16 ë¯¸ì§€ì› (Ampere SM80+ í•„ìš”)
- **í•´ê²°**:
  ```python
  # âœ… ì˜¬ë°”ë¥¸ ì„¤ì •
  bnb_config = BitsAndBytesConfig(
      bnb_4bit_compute_dtype=torch.float16  # FP16 ì‚¬ìš©
  )
  
  training_args = TrainingArguments(
      fp16=True,   # âœ…
      bf16=False,  # âœ… T4 ë¯¸ì§€ì›
  )
  ```
- **ì˜í–¥**: "Bfloat16 is only supported on GPUs with compute capability of at least 8.0" ì—ëŸ¬
- **ì°¸ê³ **: [vLLM Issue #1157](https://github.com/vllm-project/vllm/issues/1157)

### 3. FlashAttention 2ëŠ” T4 ë¯¸ì§€ì› âŒâ†’âœ…
- **ë¬¸ì œ**: `flash-attn==2.6.3`, `attn_implementation="flash_attention_2"` ì‚¬ìš©
- **ì›ì¸**: FA2ëŠ” Ampere ì´ìƒì—ì„œë§Œ ìµœì í™”ë¨
- **í•´ê²°**:
  ```python
  # âœ… ì˜¬ë°”ë¥¸ ì„¤ì •
  model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
      model_id,
      attn_implementation="sdpa"  # âœ… SDPA ì‚¬ìš© (ê¸°ë³¸)
  )
  
  # requirements.txtì—ì„œ ì œê±°
  # flash-attn==2.6.3  âŒ ì œê±°
  ```
- **ì˜í–¥**: ê²½ê³  ë©”ì‹œì§€, ì„±ëŠ¥ í–¥ìƒ ì—†ìŒ

### 4. í•™ìŠµ ë¼ë²¨ ì •ë ¬ ì˜¤ë¥˜ (ê°€ì¥ ì¤‘ìš”!) âŒâ†’âœ…
- **ë¬¸ì œ**: ì…ë ¥ ë§ˆì§€ë§‰ í† í° ìœ„ì¹˜ì— ë¼ë²¨ ì„¤ì •
- **ì›ì¸**: HF causal-LM ë‚´ë¶€ ì‹œí”„íŠ¸ë¡œ ì¸í•œ ì˜ˆì¸¡ ìœ„ì¹˜ ë¶ˆì¼ì¹˜
- **í•´ê²°**:
  ```python
  # âœ… ì˜¬ë°”ë¥¸ ë°©ì‹: assistant ë©”ì‹œì§€ í¬í•¨
  messages = [
      {"role": "user", "content": [...]},
      {"role": "assistant", "content": [{"type": "text", "text": "a"}]}  # âœ… ì •ë‹µ í¬í•¨
  ]
  
  text = processor.apply_chat_template(
      messages,
      add_generation_prompt=False  # âœ… False!
  )
  
  # ì •ë‹µ í† í° ìœ„ì¹˜ë§Œ ë¼ë²¨ ì„¤ì •
  labels.fill_(-100)
  labels[0, -len(answer_ids):] = torch.tensor(answer_ids)
  ```
- **ì˜í–¥**: í•™ìŠµ/ì¶”ë¡  ë¶ˆì¼ì¹˜ â†’ ì •í™•ë„ í¬ê²Œ ê°ì†Œ (ì˜ˆìƒ 10-15pt)
- **ì°¸ê³ **: [Qwen2.5-VL GitHub Issue #709](https://github.com/QwenLM/Qwen2.5-VL/issues/709)

### 5. ìˆ˜ë™ íŠ¹ìˆ˜í† í° êµ¬ì„± ê¸ˆì§€ âŒâ†’âœ…
- **ë¬¸ì œ**: `<|vision_start|>` ë“± ë¬¸ìì—´ ì§ì ‘ ì¡°ë¦½
- **ì›ì¸**: ëª¨ë¸/ë²„ì „ ë³€ê²½ ì‹œ ê¹¨ì§
- **í•´ê²°**:
  ```python
  # âœ… ì˜¬ë°”ë¥¸ ë°©ì‹
  from qwen_vl_utils import process_vision_info
  
  text = processor.apply_chat_template(messages, tokenize=False)
  images, videos = process_vision_info(messages)
  inputs = processor(text=[text], images=images, videos=videos)
  ```
- **ì˜í–¥**: ë²„ì „ ì—…ë°ì´íŠ¸ ì‹œ í˜¸í™˜ì„± ë¬¸ì œ

### 6. í•´ìƒë„ ê´€ë¦¬ í†µì¼ í•„ìš”
- **ë¬¸ì œ**: í•™ìŠµ/ì¶”ë¡  í•´ìƒë„ ë¶ˆì¼ì¹˜
- **í•´ê²°**:
  ```python
  # âœ… ì˜¬ë°”ë¥¸ ë°©ì‹
  processor = AutoProcessor.from_pretrained(
      model_id,
      min_pixels=256*28*28,   # ìµœì†Œ í•´ìƒë„
      max_pixels=768*28*28    # ìµœëŒ€ í•´ìƒë„ (ì¬ì¶”ë¡  ì‹œ 1024~1280)
  )
  ```

---

## ğŸ’¡ ê³ íš¨ìœ¨ ê°œì„ ì•ˆ (High-Impact Improvements)

### 1. Label Smoothing ì¶”ê°€
```python
training_args = TrainingArguments(
    label_smoothing_factor=0.05,  # ì˜¤ë‹µ ì™„í™”
)
```
- **íš¨ê³¼**: ê³¼ì í•© ë°©ì§€, +0.5-1pt ì˜ˆìƒ

### 2. í™•ë¥  í‰ê·  ì•™ìƒë¸”
```python
# âŒ ê¸°ì¡´: ë¡œê·¸ í™•ë¥  ê°€ì¤‘ í•©
# âœ… ê°œì„ : í™•ë¥  í‰ê·  (ë” ì•ˆì •ì )
votes = [answer] * int(weight * 100)
final_answer = Counter(votes).most_common(1)[0][0]
```
- **íš¨ê³¼**: ì•™ìƒë¸” ì•ˆì •ì„± í–¥ìƒ, +0.2-0.5pt ì˜ˆìƒ

### 3. OCR-aware TTA
```python
# OCR ì§ˆë¬¸ì€ flip/íšŒì „ ê¸ˆì§€ (ë¬¸ì ë°˜ì „)
if question_type not in ['ocr']:
    aug_img = augment_image(image_path)
```
- **íš¨ê³¼**: OCR ì •í™•ë„ ìœ ì§€

### 4. Seed ê³ ì • (ì¬í˜„ì„±)
```python
training_args = TrainingArguments(
    seed=42,
    data_seed=42,
)
torch.backends.cudnn.deterministic = True
```

### 5. ìì˜í•œ ë²„ê·¸ ìˆ˜ì •
- `eda.py`: `import re` ëˆ„ë½ ì¶”ê°€
- `evaluate.py`: `confusion_matrix` ì¸ì ì „ë‹¬ ëˆ„ë½ ìˆ˜ì •
- `augment.py`: OCR ì§ˆë¬¸ ì´ë¯¸ì§€ ì¦ê°• ì œì™¸
- CV: Seed ê³ ì • ì¶”ê°€

---

## ğŸ“¦ ìƒì„±ëœ íŒŒì¼ (ëª¨ë‘ /mnt/user-data/outputs/)

### 1. [FINAL_CORRECTED_Implementation_Prompt.md](computer:///mnt/user-data/outputs/FINAL_CORRECTED_Implementation_Prompt.md) â­ **ë©”ì¸ í”„ë¡¬í”„íŠ¸**
**ì½”ë“œ ìƒì„±í˜• AIê°€ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì¢… í”„ë¡¬í”„íŠ¸**

#### íŠ¹ì§•:
- âœ… 6ê°€ì§€ ì¹˜ëª…ì  ì´ìŠˆ ëª¨ë‘ ìˆ˜ì •
- âœ… Phase 0~7 ìˆœì°¨ êµ¬í˜„ ê°€ì´ë“œ
- âœ… ìˆ˜ì •ëœ ì½”ë“œ ì˜ˆì‹œ í¬í•¨
- âœ… T4 í˜¸í™˜ì„± ë³´ì¥
- âœ… Completion Criteria ëª…ì‹œ

#### êµ¬ì¡°:
```
âš ï¸ CRITICAL FIXES (ìµœìš°ì„ )
  - 6ê°€ì§€ ì¹˜ëª…ì  ì´ìŠˆ ìš”ì•½
  
ğŸ¯ ROLE & MISSION
  
ğŸ“ PROJECT CONTEXT
  
ğŸ—ï¸ IMPLEMENTATION PHASES
  âœ… PHASE 0: Project Setup (T4 í˜¸í™˜ requirements.txt)
  âœ… PHASE 1: EDA & Preprocessing (import re ì¶”ê°€)
  âœ… PHASE 2: Augmentation (OCR TTA ì œì™¸)
  âœ… PHASE 3: Training (ë¼ë²¨ ì •ë ¬ êµì •, FP16)  â­ ê°€ì¥ ì¤‘ìš”
  âœ… PHASE 4: Inference (í”„ë¡¬í”„íŠ¸ í†µì¼)
  âœ… PHASE 5: Ensemble (í™•ë¥  í‰ê· )
  âœ… PHASE 6: HP Optimization
  âœ… PHASE 7: Final Submission
  
ğŸ“‹ FINAL QUALITY CHECKLIST
  - Critical Fixes í™•ì¸
  - Code Quality
  - Reproducibility
```

### 2. [VQA_Specification_Enhancement.md](computer:///mnt/user-data/outputs/VQA_Specification_Enhancement.md)
ëª…ì„¸ì„œ ê°œì„  ë³´ì¶© ì‚¬í•­ (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿, ì—ëŸ¬ ì²˜ë¦¬ ë“±)

### 3. [Final_Implementation_Prompt.md](computer:///mnt/user-data/outputs/Final_Implementation_Prompt.md)
ì´ˆê¸° ë²„ì „ (ì¹˜ëª…ì  ì´ìŠˆ ìˆ˜ì • ì „)

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### Step 1: ìµœì¢… í”„ë¡¬í”„íŠ¸ ë³µì‚¬
```bash
# íŒŒì¼ ë‹¤ìš´ë¡œë“œ
computer:///mnt/user-data/outputs/FINAL_CORRECTED_Implementation_Prompt.md
```

### Step 2: ì½”ë“œ ìƒì„±í˜• AIì— ì…ë ¥
**GPT-4, Claude Sonnet, ë˜ëŠ” ê¸°íƒ€ ì½”ë“œ ìƒì„± AIì— ì „ì²´ í”„ë¡¬í”„íŠ¸ ì…ë ¥**

### Step 3: Phaseë³„ ìˆœì°¨ ì‹¤í–‰
```
ì‚¬ìš©ì: "PHASE 0: Project Setupì„ ì‹œì‘í•©ë‹ˆë‹¤. 
ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ìƒì„±í•˜ê³ , T4 í˜¸í™˜ requirements.txtë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤."

AI: [ë””ë ‰í† ë¦¬ ìƒì„±, requirements.txt ì‘ì„±...]

ì‚¬ìš©ì: "PHASE 1: Data Analysisë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."

AI: [EDA ìŠ¤í¬ë¦½íŠ¸, Normalizer, StratifiedCV êµ¬í˜„...]

... (Phase 7ê¹Œì§€ ë°˜ë³µ)
```

### Step 4: ê° Phase ê²€ì¦
```bash
# Phase 0 ì™„ë£Œ í›„
ls -la project/
cat project/requirements.txt | grep "qwen-vl-utils"  # âœ… í™•ì¸

# Phase 3 ì™„ë£Œ í›„ (ê°€ì¥ ì¤‘ìš”!)
python scripts/train_lora.py --fold 0
# âœ… í™•ì¸ì‚¬í•­:
# - GPU ë©”ëª¨ë¦¬ < 13GB
# - FP16 ì‚¬ìš© í™•ì¸
# - assistant ë©”ì‹œì§€ í¬í•¨ í™•ì¸
```

---

## âš™ï¸ í•µì‹¬ ê²€ì¦ í¬ì¸íŠ¸

í”„ë¡¬í”„íŠ¸ë¡œ ìƒì„±ëœ ì½”ë“œê°€ ë‹¤ìŒì„ ë§Œì¡±í•˜ëŠ”ì§€ **ë°˜ë“œì‹œ í™•ì¸**í•˜ì‹­ì‹œì˜¤:

### 1. Import ë¬¸ ê²€ì¦
```python
# âœ… ì˜¬ë°”ë¥¸ import
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info

# âŒ ì˜ëª»ëœ import
from transformers import Qwen2VLForConditionalGeneration  # í´ë˜ìŠ¤ëª… ì˜¤ë¥˜
```

### 2. BitsAndBytes Config ê²€ì¦
```python
# âœ… T4 í˜¸í™˜
bnb_config = BitsAndBytesConfig(
    bnb_4bit_compute_dtype=torch.float16  # âœ… FP16
)

# âŒ T4 ë¯¸í˜¸í™˜
bnb_config = BitsAndBytesConfig(
    bnb_4bit_compute_dtype=torch.bfloat16  # âŒ BF16
)
```

### 3. Training Arguments ê²€ì¦
```python
# âœ… T4 í˜¸í™˜
TrainingArguments(
    fp16=True,   # âœ…
    bf16=False,  # âœ…
)
```

### 4. Dataset ë¼ë²¨ ì •ë ¬ ê²€ì¦ (ê°€ì¥ ì¤‘ìš”!)
```python
# âœ… ì˜¬ë°”ë¥¸ ë°©ì‹
messages.append({
    "role": "assistant",
    "content": [{"type": "text", "text": answer}]  # âœ… ì •ë‹µ í¬í•¨
})
text = processor.apply_chat_template(
    messages,
    add_generation_prompt=False  # âœ… False!
)

# âŒ ì˜ëª»ëœ ë°©ì‹
text = processor.apply_chat_template(
    messages,
    add_generation_prompt=True  # âŒ True (ì¶”ë¡ ìš©)
)
# assistant ë©”ì‹œì§€ ì—†ìŒ âŒ
```

### 5. requirements.txt ê²€ì¦
```txt
# âœ… í•„ìˆ˜ í¬í•¨
transformers>=4.49.0  # ë˜ëŠ” git install
qwen-vl-utils[decord]==0.0.8

# âŒ ì œê±° í™•ì¸
# flash-attn==2.6.3  âŒ T4 ë¯¸ì§€ì›
```

---

## ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ

| ìˆ˜ì • ì‚¬í•­ | ì˜í–¥ë„ | ì˜ˆìƒ í–¥ìƒ |
|----------|-------|----------|
| ë¼ë²¨ ì •ë ¬ êµì • | ğŸ”¥ Critical | +10-15pt |
| T4 BF16â†’FP16 | ğŸ”¥ Blocking | í•™ìŠµ ê°€ëŠ¥ |
| Label Smoothing | âš¡ High | +0.5-1pt |
| í™•ë¥  í‰ê·  ì•™ìƒë¸” | âš¡ High | +0.2-0.5pt |
| OCR-aware TTA | âš¡ Medium | +0.3-0.5pt |
| Seed ê³ ì • | âš¡ Medium | ì¬í˜„ì„± ë³´ì¥ |

**ì´ ì˜ˆìƒ í–¥ìƒ: +11-17pt** (ë¼ë²¨ ì •ë ¬ êµì •ì´ í•µì‹¬)

---

## ğŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: ImportError: cannot import 'Qwen2_5_VLForConditionalGeneration'
**í•´ê²°**:
```bash
pip uninstall transformers
pip install git+https://github.com/huggingface/transformers.git
```

### ë¬¸ì œ 2: ValueError: Bfloat16 is only supported...
**í•´ê²°**: `torch.float16` ì‚¬ìš© í™•ì¸
```python
# ëª¨ë“  ì½”ë“œì—ì„œ bfloat16 ì œê±°
grep -r "bfloat16" project/  # âŒ ì—†ì–´ì•¼ í•¨
grep -r "torch.float16" project/  # âœ… ìˆì–´ì•¼ í•¨
```

### ë¬¸ì œ 3: Validation accuracyê°€ 25% ê·¼ì²˜ (random guess)
**ì›ì¸**: ë¼ë²¨ ì •ë ¬ ì˜¤ë¥˜
**í•´ê²°**: assistant ë©”ì‹œì§€ í¬í•¨ í™•ì¸
```python
# scripts/train_lora.py í™•ì¸
# messagesì— assistant ì‘ë‹µì´ ìˆëŠ”ì§€ í™•ì¸
messages.append({"role": "assistant", "content": [{"type": "text", "text": answer}]})
```

### ë¬¸ì œ 4: GPU Out of Memory
**í•´ê²°**:
```python
# batch_size ì¤„ì´ê¸°
per_device_train_batch_size=2  # 4 â†’ 2
gradient_accumulation_steps=4  # 2 â†’ 4
```

---

## ğŸ“Œ ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

í”„ë¡œì íŠ¸ ì™„ì„± í›„ ë‹¤ìŒì„ í™•ì¸í•˜ì‹­ì‹œì˜¤:

- [ ] âœ… **Transformers Git Install**: `pip list | grep transformers` â†’ dev ë²„ì „ í™•ì¸
- [ ] âœ… **qwen-vl-utils ì„¤ì¹˜**: `pip list | grep qwen-vl-utils` â†’ 0.0.8
- [ ] âœ… **í´ë˜ìŠ¤ëª…**: ëª¨ë“  ì½”ë“œì—ì„œ `Qwen2_5_VL*` ì‚¬ìš©
- [ ] âœ… **FP16**: ëª¨ë“  ì½”ë“œì—ì„œ `torch.float16` ì‚¬ìš©, `bfloat16` ì—†ìŒ
- [ ] âœ… **FlashAttention ì œê±°**: requirements.txt, ì½”ë“œì—ì„œ ëª¨ë‘ ì œê±°
- [ ] âœ… **ë¼ë²¨ ì •ë ¬**: train_lora.pyì—ì„œ assistant ë©”ì‹œì§€ í¬í•¨ í™•ì¸
- [ ] âœ… **í”„ë¡¬í”„íŠ¸ í†µì¼**: apply_chat_template + process_vision_info ì‚¬ìš©
- [ ] âœ… **í•´ìƒë„ ê´€ë¦¬**: min_pixels/max_pixels ì„¤ì • í™•ì¸
- [ ] âœ… **Seed ê³ ì •**: seed=42, deterministic=True ì„¤ì •
- [ ] âœ… **ì œì¶œ íŒŒì¼ ê²€ì¦**: validate_submission.py í†µê³¼

---

## ğŸ‰ ê²°ë¡ 

**6ê°€ì§€ ì¹˜ëª…ì  ì´ìŠˆ**ë¥¼ ëª¨ë‘ ìˆ˜ì •í•œ ìµœì¢… í”„ë¡¬í”„íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.

**íŠ¹íˆ "ë¼ë²¨ ì •ë ¬ êµì •" (Issue #4)ì´ ê°€ì¥ ì¤‘ìš”**í•˜ë©°, ì´ê²ƒë§Œìœ¼ë¡œë„ **+10-15pt í–¥ìƒ**ì´ ì˜ˆìƒë©ë‹ˆë‹¤.

í”„ë¡¬í”„íŠ¸ë¥¼ ì½”ë“œ ìƒì„± AIì— ì…ë ¥í•˜ê³ , ê° Phaseë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰í•˜ë©´ì„œ ìœ„ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤.

**ì„±ê³µì„ ê¸°ì›í•©ë‹ˆë‹¤! ğŸš€**
